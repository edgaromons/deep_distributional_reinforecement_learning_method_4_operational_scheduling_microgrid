# -*- coding: utf-8 -*-
"""Developing Our RL Model and Other Benchmarks-MAIN-TESTING.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oE0qfEfuW0RYSKB4VX6BfvgxWX1UjKRq


#**Developing Our RL Model and Other Benchmarks- MAIN For Obtaining The Performance on the TESTING Sets For All Models**

###**Mount the Google Drive**
"""

# Mount the Google Drive
from google.colab import drive
print(drive.mount('/content/gdrive'))

# Check if GPU is connected and display its Details
gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
  print('Not connected to a GPU')
else:
  print(gpu_info)

"""###**Install and Import Needed Packages**"""

import sys
IN_COLAB = "google.colab" in sys.modules

if IN_COLAB:
    from pyvirtualdisplay import Display

    # Start virtual display
    #dis = Display(visible=0, size=(400, 400))
    #dis.start()

import os
if IN_COLAB and not os.path.exists("segment_tree.py"):
    # download segment tree module
    #!wget https://raw.githubusercontent.com/curt-park/rainbow-is-all-you-need/master/segment_tree.py

from segment_tree import MinSegmentTree, SumSegmentTree

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
# %matplotlib inline
import matplotlib.pyplot as plt
import os.path
from matplotlib.lines import Line2D
import seaborn as sns
import shutil
import sys
import os.path
import copy
import gymnasium as gym
from gymnasium import Env
import gym
from gym import spaces
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import pickle
import os
from typing import Dict, List, Tuple
from IPython.display import clear_output
import numpy.random as rd
import datetime
from collections import defaultdict
from datetime import datetime, timedelta
import math
import csv
import warnings
from collections import deque
import time
from os import makedirs
from datetime import datetime
from datetime import date
import urllib.request
import inspect
import logging
import urllib
import zipfile
from tqdm.notebook import tqdm
from collections import OrderedDict
import csv
from scipy import stats
from tianshou.env import DummyVectorEnv, SubprocVectorEnv
import tianshou as ts
from tianshou.data import Collector, VectorReplayBuffer
from tianshou.env import DummyVectorEnv, SubprocVectorEnv
from torch.utils.tensorboard import SummaryWriter
from tianshou.utils import TensorboardLogger
from gymnasium.wrappers import TimeLimit
from gymnasium.envs.registration import register
from tianshou.data import (
    Collector,
    Batch,
    CachedReplayBuffer,
    HERReplayBuffer,
    HERVectorReplayBuffer,
    PrioritizedReplayBuffer,
    PrioritizedVectorReplayBuffer,
    ReplayBuffer,
    SegmentTree,
    VectorReplayBuffer,
)
from torch.nn.utils import clip_grad_norm_
import random
import pprint
from collections import namedtuple
import matplotlib.pyplot as plt
import matplotlib
from copy import deepcopy
import gurobipy as gp
from gurobipy import GRB
from gurobipy import *
import operator
from abc import ABC, abstractmethod
from torch.optim import Adam, RMSprop

matplotlib.rc('text', usetex=True)
pd.options.display.notebook_repr_html=False
def make_dir(directory, feature_change):
    cwd = f'{directory}/DRL_{feature_change}_plots'
    os.makedirs(cwd, exist_ok=True)
    return cwd
class PlotArgs():
    def __init__(self) -> None:
        self.cwd = None
        self.feature_change = None
        self.plot_on = None
def smooth(data, sm = 5):
        if sm > 1:
            smooth_data = []
            for n, d in enumerate(data):
                if n - sm + 1 >= 0:
                    y = np.mean(data[n - sm + 1: n])
                else:
                    y = np.mean(data[: n])
                smooth_data.append(y)
        return smooth_data

USE_CUDA = torch.cuda.is_available()
DEVICE = torch.device('cuda:0')
print("CUDA:", USE_CUDA, DEVICE)
# Get gpu if you can
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"Using {device}")

"""##**Data Collection - Year 2021**

By **National Grid Electricity System Operator - ESO**

The ESO is the electricity system operator for Great Britain.

**Historic Generation Mix & Carbon Intensity:**

This dataset contains data from the 1st of Jan 2009. It has seasonal decomposition applied to correct missing or irregular data points. The carbon intensity of electricity is a measure of how much Carbon dioxide emissions are produced per kilowatt hour of electricity consumed.

**Historic Demand Data:**

This section contains historic electricity demand, interconnector, hydro storage pumping, Non-BM Short Term Operating Reserve (STOR), wind and solar outturn data.

**Elexon BMRS System Electricity Price.**

###**Download the Datasets**

Download the systemSellPrice and	systemBuyPrice by Scraping the Elexon API, Upload other datasets, and Resample to Hourly timesteps.
"""

'''client = api.Client('86zln0egepotid1')
start_date = '2021-01-01'
end_date = '2021-01-31 23:30'
df = client.get_DERSYSDATA(start_date, end_date)
df.to_csv("/content/ESO_Enery_Price_2021_1.csv")
df'''

df_All_2021 = pd.read_csv('/content/gdrive/MyDrive/Energy_System_RL_Modeling_Data/ESO_Historic_Generation_Mix_GB_Demand_System_Prices_2021.csv')

df_All_2021['DATETIME'] = pd.to_datetime(df_All_2021['DATETIME'])
df_All_2021.set_index('DATETIME', inplace=True)
df_All_2021['systemSellPrice'].fillna(method='ffill', inplace=True)
df_All_2021['systemSellPrice'].fillna(method='bfill', inplace=True)
df_All_2021['systemBuyPrice'].fillna(method='ffill', inplace=True)
df_All_2021['systemBuyPrice'].fillna(method='bfill', inplace=True)
df_All_2021_hourly_ = df_All_2021.resample('H').mean()
df_All_2021_hourly_.reset_index(inplace=True)

"""**Create the WTPV 5% Environment**"""

'''onwind_percentage = 0.28
solar_percentage = 0.28
gas_percentage = 0.28

df_All_2021_hourly_['WIND'] *= onwind_percentage
df_All_2021_hourly_['SOLAR'] *= solar_percentage
df_All_2021_hourly_['GAS'] /= gas_percentage'''

"""**Create the WTPV 10% Environment**"""

'''onwind_percentage = 0.56
solar_percentage = 0.56
gas_percentage = 0.56

df_All_2021_hourly_['WIND'] *= onwind_percentage
df_All_2021_hourly_['SOLAR'] *= solar_percentage
df_All_2021_hourly_['GAS'] /= gas_percentage'''

"""**Create the WTPV 15% Environment**"""

'''onwind_percentage = 0.84
solar_percentage = 0.84
gas_percentage = 0.84

df_All_2021_hourly_['WIND'] *= onwind_percentage
df_All_2021_hourly_['SOLAR'] *= solar_percentage
df_All_2021_hourly_['GAS'] /= gas_percentage'''

"""**Using the REPD BEIS Datasets, we determine the percentage of installed wind technologies in the UK. We found that 43.284% wind offshore and 56.72% wind onshore are installed in Year 2021, and operational.**

**We use this to scale the Wind Data to obtain the corresponding onshore and offshore wind components.**

"""

onwind_percentage = 0.5672
offwind_percentage = 0.43284
df_All_2021_hourly_['onwind'] = df_All_2021_hourly_['WIND'] * onwind_percentage
df_All_2021_hourly_['offwind'] = df_All_2021_hourly_['WIND'] * offwind_percentage
df_All_2021_hourly_.columns

"""**Create the WTPV 0% Environment**"""

'''onwind_values = df_All_2021_hourly_['onwind']
offwind_values = df_All_2021_hourly_['offwind']
solar_values = df_All_2021_hourly_['SOLAR']
df_All_2021_hourly_['GAS'] += onwind_values + offwind_values + solar_values
df_All_2021_hourly_['onwind'] = 0
df_All_2021_hourly_['offwind'] = 0
df_All_2021_hourly_['SOLAR'] = 0'''

"""**Rescale the UK'S ESO Historical Generation and Demand Datasets to make it REALISTIC in a MicroGrid Case.**"""

df_All_2021_hourly = df_All_2021_hourly_.copy()
for column in df_All_2021_hourly.columns:
    if pd.api.types.is_numeric_dtype(df_All_2021_hourly[column]):
        df_All_2021_hourly[column] /= 10000

"""**Compute the Average Fuel Type Technology, Generation, Load Demand, and Energy Price for 2021**"""

print('===================================================================')
print('Average capacity of GAS is: {:.2f} MW'.format(df_All_2021_hourly.GAS.mean()))
print('===================================================================')
print('Average capacity of COAL is: {:.2f} MW'.format(df_All_2021_hourly.COAL.mean()))
print('===================================================================')
print('Average capacity of NUCLEAR is: {:.2f} MW'.format(df_All_2021_hourly.NUCLEAR.mean()))
print('===================================================================')
print('Average capacity of HYDRO is: {:.2f} MW'.format(df_All_2021_hourly.HYDRO.mean()))
print('===================================================================')
print('Average capacity of IMPORTS is: {:.2f} MW'.format(df_All_2021_hourly.IMPORTS.mean()))
print('===================================================================')
print('Average capacity of SOLAR is: {:.2f} MW'.format(df_All_2021_hourly.SOLAR.mean()))
print('===================================================================')
print('Average capacity of WIND is: {:.2f} MW'.format(df_All_2021_hourly.WIND.mean()))
print('===================================================================')
print('Average capacity of ONSHORE WIND is: {:.2f} MW'.format(df_All_2021_hourly.onwind.mean()))
print('===================================================================')
print('Average capacity of OFFSHORE WIND is: {:.2f} MW'.format(df_All_2021_hourly.offwind.mean()))
print('===================================================================')
print('Average capacity of STORAGE is: {:.2f} MW'.format(df_All_2021_hourly.STORAGE.mean()))
print('===================================================================')
print('Average capacity of GENERATION is: {:.2f} MW'.format(df_All_2021_hourly.GENERATION.mean()))
print('===================================================================')
print('Average capacity of LOAD DEMAND is: {:.2f} MW'.format(df_All_2021_hourly.ND.mean()))
print('===================================================================')
print('Average capacity of SYSTEM ENERGY SELLING PRICE is: {:.2f} £/MW'.format(df_All_2021_hourly.systemSellPrice.mean()))
print('===================================================================')

"""**Obtain the Maximum Capacity for all Generators - 2021**"""

print('=================================================')
gas_p_nom = df_All_2021_hourly.GAS.max()
print('GAS Maximum Capacity IS: {:.2f}'.format(gas_p_nom))
print('==================================================')
coal_p_nom = df_All_2021_hourly.COAL.max()
print('COAL Maximum Capacity IS: {:.2f}'.format(coal_p_nom))
print('==================================================')
nuclear_p_nom = df_All_2021_hourly.NUCLEAR.max()
print('NUCLEAR Maximum Capacity IS: {:.2f}'.format(nuclear_p_nom))
print('===================================================')
onwind_p_nom = df_All_2021_hourly.onwind.max()
print('ONSHORE WIND Maximum Capacity IS: {:.2f}'.format(onwind_p_nom))
print('===================================================')
offwind_p_nom = df_All_2021_hourly.offwind.max()
print('OFFSHORE WIND Maximum Capacity IS: {:.2f}'.format(offwind_p_nom))
print('===================================================')
hydro_p_nom = df_All_2021_hourly.HYDRO.max()
print('HYDRO Maximum Capacity IS: {:.2f}'.format(hydro_p_nom))
print('===================================================')
biomass_p_nom = df_All_2021_hourly.BIOMASS.max()
print('BIOMASS Maximum Capacity IS: {:.2f}'.format(biomass_p_nom))
print('===================================================')
solar_p_nom = df_All_2021_hourly.SOLAR.max()
print('SOLAR Maximum Capacity IS: {:.2f}'.format(solar_p_nom))
print('===================================================')
storage_p_nom = df_All_2021_hourly.STORAGE.max()
print('STORAGE Maximum Capacity IS: {:.2f}'.format(storage_p_nom))
print('===================================================')

"""**Visualize the Electricity Price Time Series by ESO - 2021**"""

plt.figure(figsize=(15, 9))
plt.gca().set_facecolor("white")
plt.gca().spines[['top', 'right']].set_visible(False)
df_All_2021_hourly['systemSellPrice'].plot(
    kind='line', color='gold', label='Electricity Price in £/MWh', linewidth=6.5, linestyle='-.')
#plt.title('Energy System Selling Price - 2021', size=28, fontweight='bold')
plt.xlabel('Time (Every Hour)', size=25, fontweight='bold')
plt.ylabel('£/MWh', size=25, fontweight='bold')
plt.xticks(rotation=0, size=15, fontweight='bold')
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')
#plt.yscale('log')
ax = plt.gca()
# Set linewidth and edge color for each spine
for spine in ax.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax.xaxis.grid(False)  # Remove x-axis grid lines
ax.yaxis.grid(False)
plt.legend(loc='best', ncol=1, frameon=True, fontsize='15',
           fancybox=True, framealpha=1, shadow=True, borderpad=2)
# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Energy_System_Selling_Price_2021.png')
plt.tight_layout()
plt.show()

"""**Remove Outliers From the Electricity Price Data Using Z-Score Method.**"""

def remove_outliers(series, threshold=1):
    """
    Remove outliers from a time series using the z-score method.
    Args:
    series (pd.Series): Time series data.
    threshold (float): Threshold value for outlier detection based on z-score.
    Returns:
    pd.Series: Time series with outliers removed.
    """
    z_scores = np.abs(stats.zscore(series))
    outlier_indices = np.where(z_scores >= threshold)[0]
    filtered_series = series.copy()
    filtered_series.iloc[outlier_indices] = np.nan
    return filtered_series.ffill().bfill()
original_series = df_All_2021_hourly['systemSellPrice']
filtered_electricity_price = remove_outliers(original_series)
# Check if the length is 8760, fill remaining NaN values
if len(filtered_electricity_price) < len(original_series):
    missing_indices = original_series.index.difference(filtered_electricity_price.index)
    filled_series = filtered_electricity_price.reindex(original_series.index)
    filled_series.loc[missing_indices] = original_series.loc[missing_indices]
    filtered_electricity_price = filled_series
print("Final length of filtered series:", len(filtered_electricity_price))
plt.figure(figsize=(15, 9))
plt.gca().set_facecolor("white")
plt.gca().spines[['top', 'right']].set_visible(False)
filtered_electricity_price.plot(kind='line', color='purple',
                                label='Electricity Price in £/MWh',
                                linewidth=2.5, linestyle='-.')
#plt.title('Energy System Selling Price - 2021', size=28, fontweight='bold')
plt.xlabel('Time (Every Hour)', size=25, fontweight='bold')
plt.ylabel('£/MWh', size=25, fontweight='bold')
plt.xticks(rotation=0, size=15, fontweight='bold')
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')
#plt.yscale('log')
ax = plt.gca()
# Set linewidth and edge color for each spine
for spine in ax.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax.xaxis.grid(False)  # Remove x-axis grid lines
ax.yaxis.grid(False)
plt.legend(loc='best', ncol=1, frameon=True, fontsize='15',
           fancybox=True, framealpha=1, shadow=True, borderpad=2)
# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Energy_System_Selling_Price_2021_filtered.png')
plt.tight_layout()
plt.show()

"""**Visualize the 2021 Total Load Demand Time Series by ESO Historical Demand**"""

from matplotlib.lines import Line2D
load_line = Line2D([0], [0], color='green', linestyle='-', linewidth=2, marker='s')
ax = df_All_2021_hourly[['ND']].plot(figsize=(15, 8), logy=False)
legend_labels = ['Load Demand']
ax.legend(legend_labels, loc="best", ncol=1, frameon=True, fontsize='18',
          fancybox=True, framealpha=1, shadow=True, borderpad=1)
for spine in ax.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax.xaxis.grid(False)
ax.yaxis.grid(True)
#plt.suptitle("ESO Historical Load Demand Input Time Series - 2021",
             #size=35, fontweight='bold', y=1.0)
ax.tick_params(axis='y', labelsize=16, labelcolor='red')
ax.tick_params(axis='x', labelsize=18, labelcolor='green')
plt.xlabel('Load Demand Time Series', size=25, fontweight='bold')
plt.ylabel('MW', size=25, fontweight='bold')
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Load_Demand_Time_Series_2021.png')
plt.tight_layout()
plt.show()

"""**Visualize the 2021 Net Load Demand Time Series by ESO Historical Demand**

Net load is the demand remaining after subtracting variable renewable generation
"""

from matplotlib.lines import Line2D
load_line = Line2D([0], [0], color='green', linestyle='-', linewidth=2, marker='s')
Netload = df_All_2021_hourly[['ND']] - \
df_All_2021_hourly['SOLAR'].values.reshape(-1, 1) - \
df_All_2021_hourly['offwind'].values.reshape(-1, 1) - \
df_All_2021_hourly['onwind'].values.reshape(-1, 1)
ax = Netload.plot(figsize=(15, 8), logy=False)
legend_labels = ['Netload']
ax.legend(legend_labels, loc="best", ncol=1, frameon=True, fontsize='18',
          fancybox=True, framealpha=1, shadow=True, borderpad=1)
for spine in ax.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax.xaxis.grid(False)
ax.yaxis.grid(True)
#plt.suptitle("ESO Historical Load Demand Input Time Series - 2021",
             #size=35, fontweight='bold', y=1.0)
ax.tick_params(axis='y', labelsize=16, labelcolor='red')
ax.tick_params(axis='x', labelsize=18, labelcolor='green')
plt.xlabel('NetLoad Time Series', size=25, fontweight='bold')
plt.ylabel('MW', size=25, fontweight='bold')
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/NetLoad_Demand_Time_Series_2021.png')
plt.tight_layout()
plt.show()

"""**Visualize Solar, Onshore and Offshore Wind Renewable Data**"""

plt.figure(figsize=(15, 9))
plt.gca().set_facecolor("white")
plt.gca().spines[['top', 'right']].set_visible(False)
df_All_2021_hourly['SOLAR'].plot(
    kind='line', color='blue', label='Solar PV', linewidth=3.5,
    linestyle='--')
df_All_2021_hourly['onwind'].plot(
    kind='line', color='red', label='Onshore Wind', linewidth=3.5)
df_All_2021_hourly['offwind'].plot(
    kind='line', color='green', label='Offshore Wind', linewidth=3.5)
#plt.title('Solar, Onshore, and Offshore Wind Input Time Series', size=35, fontweight='bold')
plt.xlabel('Every Hour (Year 2021)', size=25, fontweight='bold')
plt.ylabel('Power (MW)', size=25, fontweight='bold')
plt.xticks(rotation=30, size=15, fontweight='bold')
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')
ax = plt.gca()
# Set linewidth and edge color for each spine
for spine in ax.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax.xaxis.grid(False)  # Remove x-axis grid lines
ax.yaxis.grid(True)
plt.legend(loc='best', ncol=1, frameon=True, fontsize='15',
           fancybox=True, framealpha=1, shadow=True, borderpad=2)
# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Solar_and_Wind_Input_Data_2021.png')
plt.tight_layout()
plt.show()

"""**Visualize Other Energy Sources Data**"""

plt.figure(figsize=(15, 9))
plt.gca().set_facecolor("white")
plt.gca().spines[['top', 'right']].set_visible(False)
df_All_2021_hourly['HYDRO'].plot(
    kind='line', color='sienna', label='Hydro', linewidth=2.5, linestyle='-.')
df_All_2021_hourly['NUCLEAR'].plot(
    kind='line', color='navy', label='Nuclear', linewidth=2.5, linestyle='--')
df_All_2021_hourly['COAL'].plot(
    kind='line', color='navy', label='Coal', linewidth=2.5, linestyle='dashed')
df_All_2021_hourly['GAS'].plot(
    kind='line', color='purple', label='Gas', linewidth=2.5, linestyle='dashdot')
df_All_2021_hourly['BIOMASS'].plot(
    kind='line', color='green', label='Biomass', linewidth=2.5, linestyle=':')
plt.title('Hydro, Low and Zero-Carbon, and Fossil Energy Sources - 2021',
          size=28, fontweight='bold')
plt.xlabel('Time (Every Hour)', size=25, fontweight='bold')
plt.ylabel('MW', size=25, fontweight='bold')
plt.xticks(rotation=0, size=15, fontweight='bold')
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')
#plt.yscale('log')
ax = plt.gca()
# Set linewidth and edge color for each spine
for spine in ax.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax.xaxis.grid(False)  # Remove x-axis grid lines
ax.yaxis.grid(False)
plt.legend(loc='best', ncol=2, frameon=True, fontsize='14',
           fancybox=True, framealpha=1, shadow=True, borderpad=2)
# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Energy_System_other_sources_2021.png')
plt.tight_layout()
plt.show()

"""**Visualize the Energy Mix - WTPV - 18%**"""

from matplotlib.lines import Line2D
df_All_2021_hourly['SOLAR_AND_WIND_RENEWABLE'] = df_All_2021_hourly['SOLAR'] + df_All_2021_hourly['WIND']
df_All_2021_hourly['SOLAR_AND_WIND_RENEWABLE_perc'] = (df_All_2021_hourly['SOLAR_AND_WIND_RENEWABLE']/df_All_2021_hourly['GENERATION']) * 100
EnergyMix2021 = pd.DataFrame(columns=['Energy_Mix_2021'],
                            index=['solar','onwind', 'gas', 'coal', 'biomass', 'nuclear',
                                   'hydro', 'offwind'])
EnergyMix2021.at["solar", "Energy_Mix_2021"] = df_All_2021_hourly[['SOLAR']].max()
EnergyMix2021.at["onwind", "Energy_Mix_2021"] = df_All_2021_hourly[['onwind']].max()
EnergyMix2021.at["gas", "Energy_Mix_2021"] = df_All_2021_hourly[['GAS']].max()
EnergyMix2021.at["coal", "Energy_Mix_2021"] = df_All_2021_hourly[['COAL']].max()
EnergyMix2021.at["biomass", "Energy_Mix_2021"] = df_All_2021_hourly[['BIOMASS']].max()
EnergyMix2021.at["nuclear", "Energy_Mix_2021"] = df_All_2021_hourly[['NUCLEAR']].max()
EnergyMix2021.at["hydro", "Energy_Mix_2021"] = df_All_2021_hourly[['HYDRO']].max()
EnergyMix2021.at["offwind", "Energy_Mix_2021"] = df_All_2021_hourly[['offwind']].max()
Netload = df_All_2021_hourly[['ND']] - \
          df_All_2021_hourly['SOLAR'].values.reshape(-1, 1) - \
          df_All_2021_hourly['offwind'].values.reshape(-1, 1) - \
          df_All_2021_hourly['onwind'].values.reshape(-1, 1)
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
explode = (0.0, 0.0, 0.1, 0.2, 0.0, 0.3, 0.0, 0.2)
colors = ['#66b3ff', '#c2c2f0', 'maroon', 'sienna',
          'chocolate', 'purple', 'seagreen', 'darkgray']
ax1.pie(EnergyMix2021['Energy_Mix_2021'], labels=EnergyMix2021.index,
        autopct='%1.2f%%', startangle=140, explode=explode,
        textprops={'fontsize': 15, 'fontweight': 'bold'},
        colors=colors, shadow=True, rotatelabels=True)
ax1.axis('equal')
# Second Plot
total_capacity_text = 'Total capacity of this Mix is: \n {:.2f} MW'.format(df_All_2021_hourly['GENERATION'].max())
total_load = 'Total Load Demand of this Mix is: \n {:.2f} MW'.format(df_All_2021_hourly['ND'].max())
df_wind = ((df_All_2021_hourly['onwind'].mean() + df_All_2021_hourly['offwind'].mean()) / df_All_2021_hourly['ND'].max()) * 100
df_solar = (df_All_2021_hourly['SOLAR'].mean() / df_All_2021_hourly['ND'].max()) * 100
df_wind_solar = df_All_2021_hourly['SOLAR_AND_WIND_RENEWABLE_perc'].mean()
percentage_wind = 'Percentage of Wind in the Mix is: \n {:.2f}% % \u0025'.format(df_wind)
percentage_solar = 'Percentage of Solar in the Mix is: \n {:.2f}% % \u0025'.format(df_solar)
ax1.text(0.0, -1.35, percentage_wind, ha='center', va='center',
         fontsize=15, color='red')
ax1.text(0.0, -1.6, percentage_solar, ha='center', va='center',
         fontsize=15, color='purple')
#ax1.set_title("Great Britain's Energy Mix - 2021", size=20, fontweight='bold')
legend_labels = ['Netload']
Netload.plot(ax=ax2, logy=False, figsize=(15, 8))
ax2.legend(legend_labels, loc="best", ncol=1, frameon=True, fontsize='18',
          fancybox=True, framealpha=1, shadow=True, borderpad=1)
for spine in ax2.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax2.xaxis.grid(False)
ax2.yaxis.grid(True)
ax2.tick_params(axis='y', labelsize=16, labelcolor='red')
ax2.tick_params(axis='x', labelsize=18, labelcolor='green')
ax2.set_xlabel('NetLoad Time Series', size=20, fontweight='bold')
ax2.set_ylabel('MW', size=20, fontweight='bold')
#ax2.set_title("ESO Historical Load Demand Time Series - 2021", size=20, fontweight='bold')
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
output_file = os.path.join(output_dir, 'netload_18.csv')
Netload.to_csv(output_file, index=False)
plt.savefig(f'{output_dir}/Energy_Mix_and_NetLoad_2021.png')
plt.tight_layout()
plt.show()

"""**Visualize the Energy Mix - WTPV - 0%**"""

'''from matplotlib.lines import Line2D
df_All_2021_hourly['SOLAR_AND_WIND_RENEWABLE'] = df_All_2021_hourly['SOLAR'] + df_All_2021_hourly['WIND']
df_All_2021_hourly['SOLAR_AND_WIND_RENEWABLE_perc'] = (df_All_2021_hourly['SOLAR_AND_WIND_RENEWABLE']/df_All_2021_hourly['GENERATION']) * 100
EnergyMix2021 = pd.DataFrame(columns=['Energy_Mix_2021'],
                            index=['solar','onwind', 'gas', 'coal', 'biomass', 'nuclear',
                                   'hydro', 'offwind'])
EnergyMix2021.at["solar", "Energy_Mix_2021"] = df_All_2021_hourly[['SOLAR']].max()
EnergyMix2021.at["onwind", "Energy_Mix_2021"] = df_All_2021_hourly[['onwind']].max()
EnergyMix2021.at["gas", "Energy_Mix_2021"] = df_All_2021_hourly[['GAS']].max()
EnergyMix2021.at["coal", "Energy_Mix_2021"] = df_All_2021_hourly[['COAL']].max()
EnergyMix2021.at["biomass", "Energy_Mix_2021"] = df_All_2021_hourly[['BIOMASS']].max()
EnergyMix2021.at["nuclear", "Energy_Mix_2021"] = df_All_2021_hourly[['NUCLEAR']].max()
EnergyMix2021.at["hydro", "Energy_Mix_2021"] = df_All_2021_hourly[['HYDRO']].max()
EnergyMix2021.at["offwind", "Energy_Mix_2021"] = df_All_2021_hourly[['offwind']].max()
Netload = df_All_2021_hourly[['ND']] - \
          df_All_2021_hourly['SOLAR'].values.reshape(-1, 1) - \
          df_All_2021_hourly['offwind'].values.reshape(-1, 1) - \
          df_All_2021_hourly['onwind'].values.reshape(-1, 1)
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
explode = (0.0, 0.0, 0.1, 0.2, 0.0, 0.3, 0.0, 0.2)
colors = ['#66b3ff', '#c2c2f0', 'maroon', 'sienna',
          'chocolate', 'purple', 'seagreen', 'darkgray']
ax1.pie(EnergyMix2021['Energy_Mix_2021'], labels=EnergyMix2021.index,
        autopct='%1.2f%%', startangle=140, explode=explode,
        textprops={'fontsize': 15, 'fontweight': 'bold'},
        colors=colors, shadow=True, rotatelabels=True)
ax1.axis('equal')
# Second Plot
total_capacity_text = 'Total capacity of this Mix is: \n {:.2f} MW'.format(df_All_2021_hourly['GENERATION'].max())
total_load = 'Total Load Demand of this Mix is: \n {:.2f} MW'.format(df_All_2021_hourly['ND'].max())
df_wind = ((df_All_2021_hourly['onwind'].mean() + df_All_2021_hourly['offwind'].mean()) / df_All_2021_hourly['ND'].max()) * 100
df_solar = (df_All_2021_hourly['SOLAR'].mean() / df_All_2021_hourly['ND'].max()) * 100
df_wind_solar = df_All_2021_hourly['SOLAR_AND_WIND_RENEWABLE_perc'].mean()
percentage_wind = 'Percentage of Wind in the Mix is: \n {:.2f}% % \u0025'.format(df_wind)
percentage_solar = 'Percentage of Solar in the Mix is: \n {:.2f}% % \u0025'.format(df_solar)
ax1.text(0.0, -1.45, percentage_wind, ha='center', va='center',
         fontsize=15, color='red')
ax1.text(0.0, -1.65, percentage_solar, ha='center', va='center',
         fontsize=15, color='purple')
#ax1.set_title("Great Britain's Energy Mix - 2021", size=20, fontweight='bold')
legend_labels = ['Netload']
Netload.plot(ax=ax2, logy=False, figsize=(15, 8))
ax2.legend(legend_labels, loc="best", ncol=1, frameon=True, fontsize='18',
          fancybox=True, framealpha=1, shadow=True, borderpad=1)
for spine in ax2.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax2.xaxis.grid(False)
ax2.yaxis.grid(True)
ax2.tick_params(axis='y', labelsize=16, labelcolor='red')
ax2.tick_params(axis='x', labelsize=18, labelcolor='green')
ax2.set_xlabel('NetLoad Time Series', size=20, fontweight='bold')
ax2.set_ylabel('MW', size=20, fontweight='bold')
#ax2.set_title("ESO Historical Load Demand Time Series - 2021", size=20, fontweight='bold')
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
output_file = os.path.join(output_dir, 'netload_0.csv')
Netload.to_csv(output_file, index=False)
plt.savefig(f'{output_dir}/Energy_Mix_and_NetLoad_2021.png')
plt.tight_layout()
plt.show()'''

"""**Visualize the Energy Mix - WTPV - 5 %**"""

'''from matplotlib.lines import Line2D
df_All_2021_hourly['SOLAR_AND_WIND_RENEWABLE'] = df_All_2021_hourly['SOLAR'] + df_All_2021_hourly['WIND']
df_All_2021_hourly['SOLAR_AND_WIND_RENEWABLE_perc'] = (df_All_2021_hourly['SOLAR_AND_WIND_RENEWABLE']/df_All_2021_hourly['GENERATION']) * 100
EnergyMix2021 = pd.DataFrame(columns=['Energy_Mix_2021'],
                            index=['solar','onwind', 'gas', 'coal', 'biomass', 'nuclear',
                                   'hydro', 'offwind'])
EnergyMix2021.at["solar", "Energy_Mix_2021"] = df_All_2021_hourly[['SOLAR']].max()
EnergyMix2021.at["onwind", "Energy_Mix_2021"] = df_All_2021_hourly[['onwind']].max()
EnergyMix2021.at["gas", "Energy_Mix_2021"] = df_All_2021_hourly[['GAS']].max()
EnergyMix2021.at["coal", "Energy_Mix_2021"] = df_All_2021_hourly[['COAL']].max()
EnergyMix2021.at["biomass", "Energy_Mix_2021"] = df_All_2021_hourly[['BIOMASS']].max()
EnergyMix2021.at["nuclear", "Energy_Mix_2021"] = df_All_2021_hourly[['NUCLEAR']].max()
EnergyMix2021.at["hydro", "Energy_Mix_2021"] = df_All_2021_hourly[['HYDRO']].max()
EnergyMix2021.at["offwind", "Energy_Mix_2021"] = df_All_2021_hourly[['offwind']].max()
Netload = df_All_2021_hourly[['ND']] - \
          df_All_2021_hourly['SOLAR'].values.reshape(-1, 1) - \
          df_All_2021_hourly['offwind'].values.reshape(-1, 1) - \
          df_All_2021_hourly['onwind'].values.reshape(-1, 1)
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
explode = (0.0, 0.0, 0.1, 0.2, 0.0, 0.3, 0.0, 0.2)
colors = ['#66b3ff', '#c2c2f0', 'maroon', 'sienna',
          'chocolate', 'purple', 'seagreen', 'darkgray']
ax1.pie(EnergyMix2021['Energy_Mix_2021'], labels=EnergyMix2021.index,
        autopct='%1.2f%%', startangle=140, explode=explode,
        textprops={'fontsize': 15, 'fontweight': 'bold'},
        colors=colors, shadow=True, rotatelabels=True)
ax1.axis('equal')
# Second Plot
total_capacity_text = 'Total capacity of this Mix is: \n {:.2f} MW'.format(df_All_2021_hourly['GENERATION'].max())
total_load = 'Total Load Demand of this Mix is: \n {:.2f} MW'.format(df_All_2021_hourly['ND'].max())
df_wind = ((df_All_2021_hourly['onwind'].mean() + df_All_2021_hourly['offwind'].mean()) / df_All_2021_hourly['ND'].max()) * 100
df_solar = (df_All_2021_hourly['SOLAR'].mean() / df_All_2021_hourly['ND'].max()) * 100
df_wind_solar = df_All_2021_hourly['SOLAR_AND_WIND_RENEWABLE_perc'].mean()
percentage_wind = 'Percentage of Wind in the Mix is: \n {:.2f}% % \u0025'.format(df_wind)
percentage_solar = 'Percentage of Solar in the Mix is: \n {:.2f}% % \u0025'.format(df_solar)
ax1.text(0.0, -1.35, percentage_wind, ha='center', va='center',
         fontsize=15, color='red')
ax1.text(0.0, -1.6, percentage_solar, ha='center', va='center',
         fontsize=15, color='purple')
#ax1.set_title("Great Britain's Energy Mix - 2021", size=20, fontweight='bold')
legend_labels = ['Netload']
Netload.plot(ax=ax2, logy=False, figsize=(15, 8))
ax2.legend(legend_labels, loc="best", ncol=1, frameon=True, fontsize='18',
          fancybox=True, framealpha=1, shadow=True, borderpad=1)
for spine in ax2.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax2.xaxis.grid(False)
ax2.yaxis.grid(True)
ax2.tick_params(axis='y', labelsize=16, labelcolor='red')
ax2.tick_params(axis='x', labelsize=18, labelcolor='green')
ax2.set_xlabel('NetLoad Time Series', size=20, fontweight='bold')
ax2.set_ylabel('MW', size=20, fontweight='bold')
#ax2.set_title("ESO Historical Load Demand Time Series - 2021", size=20, fontweight='bold')
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
output_file = os.path.join(output_dir, 'netload_5.csv')
Netload.to_csv(output_file, index=False)
plt.savefig(f'{output_dir}/Energy_Mix_and_NetLoad_2021.png')
plt.tight_layout()
plt.show()'''

"""**Visualize the Energy Mix - WTPV - 10 %**"""

'''from matplotlib.lines import Line2D
df_All_2021_hourly['SOLAR_AND_WIND_RENEWABLE'] = df_All_2021_hourly['SOLAR'] + df_All_2021_hourly['WIND']
df_All_2021_hourly['SOLAR_AND_WIND_RENEWABLE_perc'] = (df_All_2021_hourly['SOLAR_AND_WIND_RENEWABLE']/df_All_2021_hourly['GENERATION']) * 100
EnergyMix2021 = pd.DataFrame(columns=['Energy_Mix_2021'],
                            index=['solar','onwind', 'gas', 'coal', 'biomass', 'nuclear',
                                   'hydro', 'offwind'])
EnergyMix2021.at["solar", "Energy_Mix_2021"] = df_All_2021_hourly[['SOLAR']].max()
EnergyMix2021.at["onwind", "Energy_Mix_2021"] = df_All_2021_hourly[['onwind']].max()
EnergyMix2021.at["gas", "Energy_Mix_2021"] = df_All_2021_hourly[['GAS']].max()
EnergyMix2021.at["coal", "Energy_Mix_2021"] = df_All_2021_hourly[['COAL']].max()
EnergyMix2021.at["biomass", "Energy_Mix_2021"] = df_All_2021_hourly[['BIOMASS']].max()
EnergyMix2021.at["nuclear", "Energy_Mix_2021"] = df_All_2021_hourly[['NUCLEAR']].max()
EnergyMix2021.at["hydro", "Energy_Mix_2021"] = df_All_2021_hourly[['HYDRO']].max()
EnergyMix2021.at["offwind", "Energy_Mix_2021"] = df_All_2021_hourly[['offwind']].max()
Netload = df_All_2021_hourly[['ND']] - \
          df_All_2021_hourly['SOLAR'].values.reshape(-1, 1) - \
          df_All_2021_hourly['offwind'].values.reshape(-1, 1) - \
          df_All_2021_hourly['onwind'].values.reshape(-1, 1)
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
explode = (0.0, 0.0, 0.1, 0.2, 0.0, 0.3, 0.0, 0.2)
colors = ['#66b3ff', '#c2c2f0', 'maroon', 'sienna',
          'chocolate', 'purple', 'seagreen', 'darkgray']
ax1.pie(EnergyMix2021['Energy_Mix_2021'], labels=EnergyMix2021.index,
        autopct='%1.2f%%', startangle=140, explode=explode,
        textprops={'fontsize': 15, 'fontweight': 'bold'},
        colors=colors, shadow=True, rotatelabels=True)
ax1.axis('equal')
# Second Plot
total_capacity_text = 'Total capacity of this Mix is: \n {:.2f} MW'.format(df_All_2021_hourly['GENERATION'].max())
total_load = 'Total Load Demand of this Mix is: \n {:.2f} MW'.format(df_All_2021_hourly['ND'].max())
df_wind = ((df_All_2021_hourly['onwind'].mean() + df_All_2021_hourly['offwind'].mean()) / df_All_2021_hourly['ND'].max()) * 100
df_solar = (df_All_2021_hourly['SOLAR'].mean() / df_All_2021_hourly['ND'].max()) * 100
df_wind_solar = df_All_2021_hourly['SOLAR_AND_WIND_RENEWABLE_perc'].mean()
percentage_wind = 'Percentage of Wind in the Mix is: \n {:.2f}% % \u0025'.format(df_wind)
percentage_solar = 'Percentage of Solar in the Mix is: \n {:.2f}% % \u0025'.format(df_solar)
ax1.text(0.0, -1.35, percentage_wind, ha='center', va='center',
         fontsize=15, color='red')
ax1.text(0.0, -1.6, percentage_solar, ha='center', va='center',
         fontsize=15, color='purple')
#ax1.set_title("Great Britain's Energy Mix - 2021", size=20, fontweight='bold')
legend_labels = ['Netload']
Netload.plot(ax=ax2, logy=False, figsize=(15, 8))
ax2.legend(legend_labels, loc="best", ncol=1, frameon=True, fontsize='18',
          fancybox=True, framealpha=1, shadow=True, borderpad=1)
for spine in ax2.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax2.xaxis.grid(False)
ax2.yaxis.grid(True)
ax2.tick_params(axis='y', labelsize=16, labelcolor='red')
ax2.tick_params(axis='x', labelsize=18, labelcolor='green')
ax2.set_xlabel('NetLoad Time Series', size=20, fontweight='bold')
ax2.set_ylabel('MW', size=20, fontweight='bold')
#ax2.set_title("ESO Historical Load Demand Time Series - 2021", size=20, fontweight='bold')
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
output_file = os.path.join(output_dir, 'netload_10.csv')
Netload.to_csv(output_file, index=False)
plt.savefig(f'{output_dir}/Energy_Mix_and_NetLoad_2021.png')
plt.tight_layout()
plt.show()'''

"""**Visualize the Energy Mix - WTPV - 15 %**"""

'''from matplotlib.lines import Line2D
df_All_2021_hourly['SOLAR_AND_WIND_RENEWABLE'] = df_All_2021_hourly['SOLAR'] + df_All_2021_hourly['WIND']
df_All_2021_hourly['SOLAR_AND_WIND_RENEWABLE_perc'] = (df_All_2021_hourly['SOLAR_AND_WIND_RENEWABLE']/df_All_2021_hourly['GENERATION']) * 100
EnergyMix2021 = pd.DataFrame(columns=['Energy_Mix_2021'],
                            index=['solar','onwind', 'gas', 'coal', 'biomass', 'nuclear',
                                   'hydro', 'offwind'])
EnergyMix2021.at["solar", "Energy_Mix_2021"] = df_All_2021_hourly[['SOLAR']].max()
EnergyMix2021.at["onwind", "Energy_Mix_2021"] = df_All_2021_hourly[['onwind']].max()
EnergyMix2021.at["gas", "Energy_Mix_2021"] = df_All_2021_hourly[['GAS']].max()
EnergyMix2021.at["coal", "Energy_Mix_2021"] = df_All_2021_hourly[['COAL']].max()
EnergyMix2021.at["biomass", "Energy_Mix_2021"] = df_All_2021_hourly[['BIOMASS']].max()
EnergyMix2021.at["nuclear", "Energy_Mix_2021"] = df_All_2021_hourly[['NUCLEAR']].max()
EnergyMix2021.at["hydro", "Energy_Mix_2021"] = df_All_2021_hourly[['HYDRO']].max()
EnergyMix2021.at["offwind", "Energy_Mix_2021"] = df_All_2021_hourly[['offwind']].max()
Netload = df_All_2021_hourly[['ND']] - \
          df_All_2021_hourly['SOLAR'].values.reshape(-1, 1) - \
          df_All_2021_hourly['offwind'].values.reshape(-1, 1) - \
          df_All_2021_hourly['onwind'].values.reshape(-1, 1)
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
explode = (0.0, 0.0, 0.1, 0.2, 0.0, 0.3, 0.0, 0.2)
colors = ['#66b3ff', '#c2c2f0', 'maroon', 'sienna',
          'chocolate', 'purple', 'seagreen', 'darkgray']
ax1.pie(EnergyMix2021['Energy_Mix_2021'], labels=EnergyMix2021.index,
        autopct='%1.2f%%', startangle=140, explode=explode,
        textprops={'fontsize': 15, 'fontweight': 'bold'},
        colors=colors, shadow=True, rotatelabels=True)
ax1.axis('equal')
# Second Plot
total_capacity_text = 'Total capacity of this Mix is: \n {:.2f} MW'.format(df_All_2021_hourly['GENERATION'].max())
total_load = 'Total Load Demand of this Mix is: \n {:.2f} MW'.format(df_All_2021_hourly['ND'].max())
df_wind = ((df_All_2021_hourly['onwind'].mean() + df_All_2021_hourly['offwind'].mean()) / df_All_2021_hourly['ND'].max()) * 100
df_solar = (df_All_2021_hourly['SOLAR'].mean() / df_All_2021_hourly['ND'].max()) * 100
df_wind_solar = df_All_2021_hourly['SOLAR_AND_WIND_RENEWABLE_perc'].mean()
percentage_wind = 'Percentage of Wind in the Mix is: \n {:.2f}% % \u0025'.format(df_wind)
percentage_solar = 'Percentage of Solar in the Mix is: \n {:.2f}% % \u0025'.format(df_solar)
ax1.text(0.0, -1.35, percentage_wind, ha='center', va='center',
         fontsize=15, color='red')
ax1.text(0.0, -1.6, percentage_solar, ha='center', va='center',
         fontsize=15, color='purple')
#ax1.set_title("Great Britain's Energy Mix - 2021", size=20, fontweight='bold')
legend_labels = ['Netload']
Netload.plot(ax=ax2, logy=False, figsize=(15, 8))
ax2.legend(legend_labels, loc="best", ncol=1, frameon=True, fontsize='18',
          fancybox=True, framealpha=1, shadow=True, borderpad=1)
for spine in ax2.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax2.xaxis.grid(False)
ax2.yaxis.grid(True)
ax2.tick_params(axis='y', labelsize=16, labelcolor='red')
ax2.tick_params(axis='x', labelsize=18, labelcolor='green')
ax2.set_xlabel('NetLoad Time Series', size=20, fontweight='bold')
ax2.set_ylabel('MW', size=20, fontweight='bold')
#ax2.set_title("ESO Historical Load Demand Time Series - 2021", size=20, fontweight='bold')
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
output_file = os.path.join(output_dir, 'netload_15.csv')
Netload.to_csv(output_file, index=False)
plt.savefig(f'{output_dir}/Energy_Mix_and_NetLoad_2021.png')
plt.tight_layout()
plt.show()'''

"""**Visulaize The Variability of the Netload of the Entire Scenarios**"""

from matplotlib.lines import Line2D
load_line = Line2D([0], [0], color='green', linestyle='-', linewidth=2, marker='s')
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
output_file = os.path.join(output_dir, 'netload_18.csv')
Netload_18 = pd.read_csv(output_file)
output_file = os.path.join(output_dir, 'netload_0.csv')
Netload_0 = pd.read_csv(output_file)
output_file = os.path.join(output_dir, 'netload_5.csv')
Netload_5 = pd.read_csv(output_file)
output_file = os.path.join(output_dir, 'netload_10.csv')
Netload_10 = pd.read_csv(output_file)
output_file = os.path.join(output_dir, 'netload_15.csv')
Netload_15 = pd.read_csv(output_file)
ax = Netload_18.plot(figsize=(15, 8), logy=False, color='green',
                     linestyle='-', linewidth=2, marker = 's')
Netload_0.plot(ax=ax, color='skyblue', linestyle='-', linewidth=2)
Netload_5.plot(ax=ax, color='red', linestyle='-', linewidth=2)  # New plot
Netload_10.plot(ax=ax, color='navy', linestyle='-', linewidth=2)
Netload_15.plot(ax=ax, color='purple', linestyle='-', linewidth=2)
legend_labels = ['Netload-WTPV-18', 'Netload-WTPV-0', 'Netload-WTPV-5', 'Netload-WTPV-10', 'Netload-WTPV-15']
ax.legend(legend_labels, loc="best", ncol=1, frameon=True, fontsize='18',
          fancybox=True, framealpha=1, shadow=True, borderpad=1)
for spine in ax.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax.xaxis.grid(False)
ax.yaxis.grid(True)
ax.tick_params(axis='y', labelsize=16, labelcolor='red')
ax.tick_params(axis='x', labelsize=18, labelcolor='green')
plt.xlabel('NetLoad Time Series', size=25, fontweight='bold')
plt.ylabel('MW', size=25, fontweight='bold')
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Variabilit_of_the_NetLoad_Demand_Time_Series_2021.png')
plt.tight_layout()
plt.show()

"""**Obtain the Generators Cost Assumption Data**

Assuming Projects Commissioning in 2025,
3.5% Discount Rate,

Use 0.86 to convert from Euro to £ (Pounds)
"""

assumptions = pd.DataFrame(
    columns=["FOM", "discount rate", "efficiency", "investment", "lifetime",
             "fuel cost", "VOM"],
    index=["onwind", "solar", "ccgt", "nuclear", "hydro", "coal", "offwind",
           "biomass"],
)
assumptions.at["onwind", "FOM"] = 1.2347 # %/year
assumptions.at["onwind", "discount rate"] = 0.035 # 3.5%
assumptions.at["onwind", "lifetime"] = 28.5 # Years
assumptions.at["onwind", "investment"] = 1077.1681 * 1000 * 0.86 # EUR/kW
assumptions.at["onwind", "efficiency"] = 1.0 # per unit
assumptions.at["onwind", "fuel cost"] = 0 * 0.86 # EUR/MWhth
assumptions.at["onwind", "VOM"] = 1.425 * 0.86 # EUR/MWh

assumptions.at["solar", "FOM"] = 1.7275
assumptions.at["solar", "discount rate"] = 0.035 # 3.5%
assumptions.at["solar", "lifetime"] = 37.5
assumptions.at["solar", "investment"] = 612.7906 * 1000 * 0.86
assumptions.at["solar", "efficiency"] = 1.0 # per unit
assumptions.at["solar", "fuel cost"] = 0 * 0.86 # EUR/MWhth
assumptions.at["solar", "VOM"] = 0.01 * 0.86

assumptions.at["ccgt", "FOM"] = 3.3392
assumptions.at["ccgt", "discount rate"] = 0.035 # 3.5%
assumptions.at["ccgt", "lifetime"] = 25
assumptions.at["ccgt", "investment"] = 855 * 1000 * 0.86
assumptions.at["ccgt", "efficiency"] = 0.57
assumptions.at["ccgt", "fuel cost"] = 23.8481 * 0.86
assumptions.at["ccgt", "VOM"] = 4.3 * 0.86

assumptions.at["nuclear", "FOM"] = 1.27
assumptions.at["nuclear", "discount rate"] = 0.035 # 3.5%
assumptions.at["nuclear", "lifetime"] = 40
assumptions.at["nuclear", "investment"] = 8769.6136 * 1000 * 0.86
assumptions.at["nuclear", "efficiency"] = 0.326
assumptions.at["nuclear", "fuel cost"] = 3.3122 * 0.86
assumptions.at["nuclear", "VOM"] = 3.6188 * 0.86

assumptions.at["hydro", "FOM"] = 1.0
assumptions.at["hydro", "discount rate"] = 0.035 # 3.5%
assumptions.at["hydro", "lifetime"] = 80
assumptions.at["hydro", "investment"] = 2208.1616 * 1000 * 0.86
assumptions.at["hydro", "efficiency"] = 0.9
assumptions.at["hydro", "fuel cost"] = 0 * 0.86
assumptions.at["hydro", "VOM"] = 0

assumptions.at["coal", "FOM"] = 1.31
assumptions.at["coal", "discount rate"] = 0.035 # 3.5%
assumptions.at["coal", "lifetime"] = 40
assumptions.at["coal", "investment"] = 3905.3074 * 1000 * 0.86
assumptions.at["coal", "efficiency"] = 0.33
assumptions.at["coal", "fuel cost"] = 9.2743 * 0.86
assumptions.at["coal", "VOM"] = 3.3278 * 0.86

assumptions.at["offwind", "FOM"] = 2.3741
assumptions.at["offwind", "discount rate"] = 0.035 # 3.5%
assumptions.at["offwind", "lifetime"] = 30
assumptions.at["offwind", "investment"] = 1602.3439 * 1000 * 0.86
assumptions.at["offwind", "efficiency"] = 1.0 # per unit
assumptions.at["offwind", "fuel cost"] = 0 * 0.86 # EUR/MWhth
assumptions.at["offwind", "VOM"] = 0.02 * 0.86

assumptions.at["biomass", "FOM"] = 4.5269
assumptions.at["biomass", "discount rate"] = 0.035 # 3.5%
assumptions.at["biomass", "lifetime"] = 30
assumptions.at["biomass", "investment"] = 2209 * 1000 * 0.86
assumptions.at["biomass", "efficiency"] = 0.468
assumptions.at["biomass", "fuel cost"] = 7.0 * 0.86
assumptions.at["biomass", "VOM"] = 10

def annuity(lifetime, rate):
    if rate == 0.0:
        return 1 / lifetime
    else:
        return rate / (1.0 - 1.0 / (1.0 + rate) ** lifetime)
#  Compute Capital Cost by annualising investment costs, and add FOM
assumptions["Capital_cost"] = [
    (annuity(v["lifetime"], v["discount rate"]) + v["FOM"] / 100.0) * v["investment"]
    for i, v in assumptions.iterrows()
]
#  Compute Marginal Cost by adding VOM costs and Adjusted Fuel Cost
assumptions["Marginal_cost"] = [
    (v["VOM"] + v["fuel cost"] ) for i, v in assumptions.iterrows()
    ]
assumptions

"""**Obtain the Maximum Capacities of Generators and Storage**"""

ccgt_max_cap_dg = df_All_2021_hourly.GAS.max()
biomass_max_cap_dg = df_All_2021_hourly.BIOMASS.max()
coal_max_cap_dg = df_All_2021_hourly.COAL.max()
nuclear_max_cap_dg = df_All_2021_hourly.NUCLEAR.max()
solar_max_cap = df_All_2021_hourly.SOLAR.max()
onwind_max_cap = df_All_2021_hourly.onwind.max()
offwind_max_cap = df_All_2021_hourly.offwind.max()
hydro_max_cap_dg = df_All_2021_hourly.HYDRO.max()
storage_max_cap = df_All_2021_hourly.STORAGE.max()

"""**Obtain the Minimum Capacity of Generators and Storage**"""

ccgt_min_cap_dg = df_All_2021_hourly.GAS.min()
biomass_min_cap_dg = df_All_2021_hourly.BIOMASS.min()
coal_min_cap_dg = df_All_2021_hourly.COAL.min()
nuclear_min_cap_dg = df_All_2021_hourly.NUCLEAR.min()
solar_min_cap = df_All_2021_hourly.SOLAR.min()
onwind_min_cap = df_All_2021_hourly.onwind.min()
offwind_min_cap = df_All_2021_hourly.offwind.min()
hydro_min_cap_dg = df_All_2021_hourly.HYDRO.min()
storage_min_cap = df_All_2021_hourly.STORAGE.min()

"""**Visualize Renewable Generators Input Time Series**"""

# Create Line2D objects for each generator
solar_line = Line2D([0], [0], color='blue', linestyle='-', linewidth=2, marker='o')
onwind_line = Line2D([0], [0], color='orange', linestyle='-.', linewidth=2, marker='^')
offshore_wind_line = Line2D([0], [0], color='green', linestyle='--', linewidth=2, marker='s')

# Create subplots for each generator
fig, axs = plt.subplots(3, 1, figsize=(15, 18))

# Plot data for each generator on its respective subplot
generators_data = ['SOLAR', 'onwind', 'offwind']
legend_labels = ['Solar', 'Onshore Wind', 'Offshore Wind']
legend_lines = [solar_line, onwind_line, offshore_wind_line]  # Updated
colors = ['blue', 'orange', 'green']

for idx, generator in enumerate(generators_data):
    ax = axs[idx]
    ax.plot(df_All_2021_hourly.index, df_All_2021_hourly[generator],
            color=colors[idx], linewidth=2)
    ax.set_ylabel('MW', size=14)
    ax.set_title(f'{legend_labels[idx]} Renewable Generator Input Time Series - 2021', size=16, fontweight='bold')
    ax.legend([legend_lines[idx]], [legend_labels[idx]], loc="best", fontsize='14',
              fancybox=True, framealpha=1, shadow=True, borderpad=1)  # Updated
    ax.tick_params(axis='both', labelsize=12)
    ax.xaxis.grid(False)
    ax.yaxis.grid(True)
    for spine in ax.spines.values():
        spine.set_linewidth(2)
        spine.set_edgecolor('black')

# Adjust layout and save the figure
#plt.suptitle("Generators Input Time Series - 2021",
             #size=30, fontweight='bold', y=1.02)
plt.xlabel('Time Series', size=16, fontweight='bold')
plt.tight_layout()
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Renewable_Generators_Input_Time_Series.png')
plt.show()

"""**Create a DF of the Generators, and Storage's Fueltype, Maximum Capacity, Capital Cost, Marginal Cost, Efficiency, Initial_SOC, Max_SOC, Min_SOC, Degradation, Max_Charge, and Max_Discharge.**"""

data_scenario_df = pd.DataFrame(columns=['Name', 'Fueltype', 'Capacity', 'Operating_Capital_Cost',
                                         'Operating_Marginal_Cost', 'Efficiency',
                                         'Initial_SOC', 'Max_SOC', 'Min_SOC', 'Max_Charge',
                                         'Max_Discharge', 'Degradation'],
                            index=['solar','onwind', 'ccgt', 'coal', 'biomass', 'nuclear',
                                   'hydro', 'offwind', 'BESS'])
data_scenario_df.at["solar", "Name"] = 'solar'
data_scenario_df.at["onwind", "Name"] = 'onwind'
data_scenario_df.at["ccgt", "Name"] = 'ccgt'
data_scenario_df.at["coal", "Name"] = 'coal'
data_scenario_df.at["biomass", "Name"] = 'biomass'
data_scenario_df.at["nuclear", "Name"] = 'nuclear'
data_scenario_df.at["hydro", "Name"] = 'hydro'
data_scenario_df.at["offwind", "Name"] = 'offwind'
data_scenario_df.at["BESS", "Name"] = 'BESS'
data_scenario_df.at["solar", "Capacity"] = solar_max_cap
data_scenario_df.at["onwind", "Capacity"] = onwind_max_cap
data_scenario_df.at["ccgt", "Capacity"] = ccgt_max_cap_dg
data_scenario_df.at["coal", "Capacity"] = coal_max_cap_dg
data_scenario_df.at["biomass", "Capacity"] = biomass_max_cap_dg
data_scenario_df.at["nuclear", "Capacity"] = nuclear_max_cap_dg
data_scenario_df.at["hydro", "Capacity"] = hydro_max_cap_dg
data_scenario_df.at["offwind", "Capacity"] = offwind_max_cap
data_scenario_df.at["BESS", "Capacity"] = 0.50 # MW OR 500 KW
data_scenario_df.at["solar", "Fueltype"] = 'SOLAR'
data_scenario_df.at["onwind", "Fueltype"] = 'ONSHORE WIND'
data_scenario_df.at["ccgt", "Fueltype"] = 'GAS'
data_scenario_df.at["coal", "Fueltype"] = 'COAL'
data_scenario_df.at["biomass", "Fueltype"] = 'BIOMASS'
data_scenario_df.at["nuclear", "Fueltype"] = 'NUCLEAR'
data_scenario_df.at["hydro", "Fueltype"] = 'HYDRO'
data_scenario_df.at["offwind", "Fueltype"] = 'OFFSHORE WIND'
data_scenario_df.at["BESS", "Fueltype"] = 'Battery'
data_scenario_df.at["solar", "Operating_Capital_Cost"] = assumptions.loc['solar', 'Capital_cost']
data_scenario_df.at["onwind", "Operating_Capital_Cost"] = assumptions.loc['onwind', 'Capital_cost']
data_scenario_df.at["ccgt", "Operating_Capital_Cost"] = assumptions.loc['ccgt', 'Capital_cost']
data_scenario_df.at["coal", "Operating_Capital_Cost"] = assumptions.loc['coal', 'Capital_cost']
data_scenario_df.at["biomass", "Operating_Capital_Cost"] = assumptions.loc['biomass', 'Capital_cost']
data_scenario_df.at["nuclear", "Operating_Capital_Cost"] = assumptions.loc['nuclear', 'Capital_cost']
data_scenario_df.at["hydro", "Operating_Capital_Cost"] = assumptions.loc['hydro', 'Capital_cost']
data_scenario_df.at["offwind", "Operating_Capital_Cost"] = assumptions.loc['offwind', 'Capital_cost']
data_scenario_df.at["BESS", "Operating_Capital_Cost"] = 365000 # £/Year - 2020 Projections
data_scenario_df.at["solar", "Operating_Marginal_Cost"] = assumptions.loc['solar', 'Marginal_cost']
data_scenario_df.at["onwind", "Operating_Marginal_Cost"] = assumptions.loc['onwind', 'Marginal_cost']
data_scenario_df.at["ccgt", "Operating_Marginal_Cost"] = assumptions.loc['ccgt', 'Marginal_cost']
data_scenario_df.at["coal", "Operating_Marginal_Cost"] = assumptions.loc['coal', 'Marginal_cost']
data_scenario_df.at["biomass", "Operating_Marginal_Cost"] = assumptions.loc['biomass', 'Marginal_cost']
data_scenario_df.at["nuclear", "Operating_Marginal_Cost"] = assumptions.loc['nuclear', 'Marginal_cost']
data_scenario_df.at["hydro", "Operating_Marginal_Cost"] = assumptions.loc['hydro', 'Marginal_cost']
data_scenario_df.at["offwind", "Operating_Marginal_Cost"] = assumptions.loc['offwind', 'Marginal_cost']
data_scenario_df.at["BESS", "Operating_Marginal_Cost"] = 0 # £/MWh
data_scenario_df.at["solar", "Efficiency"] = assumptions.loc['solar', 'efficiency']
data_scenario_df.at["onwind", "Efficiency"] = assumptions.loc['onwind', 'efficiency']
data_scenario_df.at["ccgt", "Efficiency"] = assumptions.loc['ccgt', 'efficiency']
data_scenario_df.at["coal", "Efficiency"] = assumptions.loc['coal', 'efficiency']
data_scenario_df.at["biomass", "Efficiency"] = assumptions.loc['biomass', 'efficiency']
data_scenario_df.at["nuclear", "Efficiency"] = assumptions.loc['nuclear', 'efficiency']
data_scenario_df.at["hydro", "Efficiency"] = assumptions.loc['hydro', 'efficiency']
data_scenario_df.at["offwind", "Efficiency"] = assumptions.loc['offwind', 'efficiency']
data_scenario_df.at["BESS", "Efficiency"] = 0.95
data_scenario_df.at["solar", "Initial_SOC"] = ''
data_scenario_df.at["onwind", "Initial_SOC"] = ''
data_scenario_df.at["ccgt", "Initial_SOC"] = ''
data_scenario_df.at["coal", "Initial_SOC"] = ''
data_scenario_df.at["biomass", "Initial_SOC"] = ''
data_scenario_df.at["nuclear", "Initial_SOC"] = ''
data_scenario_df.at["hydro", "Initial_SOC"] = ''
data_scenario_df.at["offwind", "Initial_SOC"] = ''
data_scenario_df.at["BESS", "Initial_SOC"] = 0.0
data_scenario_df.at["solar", "Max_SOC"] = ''
data_scenario_df.at["onwind", "Max_SOC"] = ''
data_scenario_df.at["ccgt", "Max_SOC"] = ''
data_scenario_df.at["coal", "Max_SOC"] = ''
data_scenario_df.at["biomass", "Max_SOC"] = ''
data_scenario_df.at["nuclear", "Max_SOC"] = ''
data_scenario_df.at["hydro", "Max_SOC"] = ''
data_scenario_df.at["offwind", "Max_SOC"] = ''
data_scenario_df.at["BESS", "Max_SOC"] = 0.80 # %
data_scenario_df.at["solar", "Min_SOC"] = ''
data_scenario_df.at["onwind", "Min_SOC"] = ''
data_scenario_df.at["ccgt", "Min_SOC"] = ''
data_scenario_df.at["coal", "Min_SOC"] = ''
data_scenario_df.at["biomass", "Min_SOC"] = ''
data_scenario_df.at["nuclear", "Min_SOC"] = ''
data_scenario_df.at["hydro", "Min_SOC"] = ''
data_scenario_df.at["offwind", "Min_SOC"] = ''
data_scenario_df.at["BESS", "Min_SOC"] = 0.20 # %
data_scenario_df.at["solar", "Max_Charge"] = ''
data_scenario_df.at["onwind", "Max_Charge"] = ''
data_scenario_df.at["ccgt", "Max_Charge"] = ''
data_scenario_df.at["coal", "Max_Charge"] = ''
data_scenario_df.at["biomass", "Max_Charge"] = ''
data_scenario_df.at["nuclear", "Max_Charge"] = ''
data_scenario_df.at["hydro", "Max_Charge"] = ''
data_scenario_df.at["offwind", "Max_Charge"] = ''
data_scenario_df.at["BESS", "Max_Charge"] = 0.1 # MW
data_scenario_df.at["solar", "Max_Discharge"] = ''
data_scenario_df.at["onwind", "Max_Discharge"] = ''
data_scenario_df.at["ccgt", "Max_Discharge"] = ''
data_scenario_df.at["coal", "Max_Discharge"] = ''
data_scenario_df.at["biomass", "Max_Discharge"] = ''
data_scenario_df.at["nuclear", "Max_Discharge"] = ''
data_scenario_df.at["hydro", "Max_Discharge"] = ''
data_scenario_df.at["offwind", "Max_Discharge"] = ''
data_scenario_df.at["BESS", "Max_Discharge"] = 0.1 # MW
data_scenario_df.at["solar", "Degradation"] = ''
data_scenario_df.at["onwind", "Degradation"] = ''
data_scenario_df.at["ccgt", "Degradation"] = ''
data_scenario_df.at["coal", "Degradation"] = ''
data_scenario_df.at["biomass", "Degradation"] = ''
data_scenario_df.at["nuclear", "Degradation"] = ''
data_scenario_df.at["hydro", "Degradation"] = ''
data_scenario_df.at["offwind", "Degradation"] = ''
data_scenario_df.at["BESS", "Degradation"] = 0
data_scenario_df

"""**Visualize the Operational Capital Costs of the DGs, Renewable Generators, and Storage BESS**"""

plt.figure(figsize=(15, 9))
plt.gca().set_facecolor("white")
plt.gca().spines[['top', 'right']].set_visible(False)
df_operating_cost = data_scenario_df[['Fueltype', 'Operating_Capital_Cost']]
bar_width = 0.7
bar_positions1 = range(len(df_operating_cost['Fueltype']))
#plt.bar(bar_positions1, df_operating_cost['Operating_Capital_Cost'],
        #width=bar_width, label='Operating Capital Cost')
df_marginal_cost = data_scenario_df[['Fueltype', 'Operating_Marginal_Cost']]
bar_positions2 = [p + bar_width for p in bar_positions1]
plt.bar(bar_positions2, df_marginal_cost['Operating_Marginal_Cost'],
        width=bar_width, label='Operating Marginal Cost', color = 'orange')
plt.yscale('log')
plt.xlabel('Plant Carrier', size=25, weight='bold')
plt.xticks([p + bar_width / 2 for p in bar_positions1],
           df_operating_cost['Fueltype'], rotation=45, size=15, fontweight='bold')
plt.ylabel('£/MWh', size=22, weight='bold')
#plt.title('Operating Capital Cost and Marginal Cost', size=28, fontweight='bold')
plt.legend(loc='best', fontsize='large', fancybox=True, framealpha=1, shadow=True, borderpad=1)
plt.xticks(size=15, fontweight='bold')
plt.yticks(ha='right', size=15, fontweight='bold')
ax = plt.gca()
# Set linewidth and edge color for each spine
for spine in ax.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax.xaxis.grid(False)  # Remove x-axis grid lines
ax.yaxis.grid(False)
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Energy_System_Operational_Marginal_Cost.png')
plt.tight_layout()
plt.show()

"""##**Data Manager**

**Power Plant Data**
"""

df_plant_info = data_scenario_df[['Name', 'Fueltype', 'Capacity']]
desired_fuels = ['GAS', 'COAL', 'HYDRO', 'NUCLEAR', 'BIOMASS']
df_plant_info = df_plant_info[df_plant_info['Fueltype'].isin(desired_fuels)]
P = set(df_plant_info['Name'].unique())# set of all power plants
plant_type = df_plant_info.set_index('Name').Fueltype.to_dict() # plant type for each plant
fuel_type = df_plant_info.set_index('Name').Fueltype.to_dict() # fuel type for each plant
P_NG = set([i for i in P if plant_type[i]=='GAS'])
P_HC = set([i for i in P if plant_type[i]=='COAL'])
P_hyd = set([i for i in P if plant_type[i]=='HYDRO'])
P_Nuc = set([i for i in P if plant_type[i]=='NUCLEAR'])
P_Bio = set([i for i in P if plant_type[i]=='BIOMASS'])
P_W = set([i for i in P if plant_type[i]=='ONWIND'])
P_S = set([i for i in P if plant_type[i]=='SOLAR'])
P_Ofw = set([i for i in P if plant_type[i]=='OFFSHORE WIND'])
fuel_type

"""**Plant Capacities and Limits**

The overall goal is to determine the amount of power to generate from each plant. This amount must be within the plant's minimum and maximum production limits (in MWh). See below for a visualization of the maximum production limits for the plants.
"""

fanciful_palette = ["sienna", "#40E0D0", "#FFD700", "#9370DB", "#ffcc99", 'red']
df_plant_info['capacity'] = df_plant_info['Capacity']
c = df_plant_info.set_index('Name').capacity.to_dict() # generation capacity
fig, ax = plt.subplots(figsize=(20, 12))
plt.gca().set_facecolor("white")
plt.gca().spines[['top', 'right']].set_visible(False)
capacity_plot = sns.barplot(x=list(c.keys()), y=[c[k] for k in c],
                            palette=fanciful_palette)
capacity_plot.set_xticklabels(capacity_plot.get_xticklabels(), rotation=90);
capacity_plot.set(xlabel='Plant', ylabel='Capacity (MWh)');
#plt.title('Maximum Production Limits for the Power Plants', size=45, fontweight='bold')
plt.ylabel('Capacity (MW)', size=40, fontweight='bold')
plt.xlabel('Non-Renewable Generators', size=40, fontweight='bold')
plt.xticks(rotation=0, size=26, fontweight='bold')
plt.yticks(rotation=0, ha='right', size=25, fontweight='bold')
ax = plt.gca()
# Set linewidth and edge color for each spine
for spine in ax.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax.xaxis.grid(False)  # Remove x-axis grid lines
ax.yaxis.grid(True)
# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/maximum_production_limits_for_the_plants_scenario.png')
plt.tight_layout()
plt.show()

"""**Maximum Power Plant Capacity**"""

power_output_max = df_plant_info.set_index('Name').capacity.to_dict()
power_output_max

"""**For all the plants, we set the minimum production limit to 1%.**"""

min_p = {i: 0.01 if i in P_NG else 0.01 if i in P_HC else 0.01 if i in P_hyd else 0.01 if i in P_Bio else 0.01 if i in P_Nuc else 1 for i in fuel_type} # min % generation when on
min_p

"""**Minimum Power Plant Capacity**"""

power_output_min = {key: c[key] * min_p[key] for key in c}
print(power_output_min)

"""**Ramp Up and Ramp Down**

Additionally, we also have a limit on how much the power generation schedule can **ramp up or ramp down** the power generation between successive hours. This limit ensures that the plants are not forced to make drastic changes to their generation schedule.

We set this speed limit 20% for nuclear plants, and 25% for coal plants. In other words, a coal plant cannot be ramped up or ramped down within an hour by more than 25% of its total capacity. We set the speed limit to be 100% for all other plants thereby imposing no limit on the speed.
"""

r = {i: 1 if i in P_NG else 0.20 if i in P_Nuc else 0.25 if i in P_HC else 1 for i in fuel_type} # ramp up/down speed
r

"""**Ramping Up**"""

ramping_up = {key: c[key] * r[key] for key in c}
print(ramping_up)

"""**Ramping Down**"""

ramping_down = {key: c[key] * r[key] for key in c}
print(ramping_down)

"""**Operating Capital Cost Data**"""

df_Op_Cap_Cost = data_scenario_df[['Name', 'Fueltype', 'Operating_Capital_Cost']]
desired_fuels = ['GAS', 'COAL', 'HYDRO', 'NUCLEAR', 'BIOMASS']
df_Op_Cap_Cost = df_Op_Cap_Cost[df_Op_Cap_Cost['Fueltype'].isin(desired_fuels)]
df_Op_Cap_Cost = df_Op_Cap_Cost.set_index('Name').Operating_Capital_Cost.to_dict()
df_Op_Cap_Cost

"""**Operating Marginal Cost Data**"""

df_Op_Marg_Cost = data_scenario_df[['Name', 'Fueltype', 'Operating_Marginal_Cost']]
desired_fuels = ['GAS', 'COAL', 'HYDRO', 'NUCLEAR', 'BIOMASS']
df_Op_Marg_Cost = df_Op_Marg_Cost[df_Op_Marg_Cost['Fueltype'].isin(desired_fuels)]
df_Op_Marg_Cost = df_Op_Marg_Cost.set_index('Name').Operating_Marginal_Cost.to_dict()
df_Op_Marg_Cost

class Constant:
	MONTHS_LEN = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]
	MAX_STEP_HOURS = 24 * 30
class DataManager():
    def __init__(self) -> None:
        self.PV_Generation = []
        self.Wind_Generation = []
        self.OffWind_Generation = []
        self.Prices = []
        self.Electricity_Consumption = []
    def add_pv_element(self, element):self.PV_Generation.append(element)
    def add_wind_element(self, element):self.Wind_Generation.append(element)
    def add_offwind_element(self, element):self.OffWind_Generation.append(element)
    def add_price_element(self, element):self.Prices.append(element)
    def add_electricity_element(
        self, element):self.Electricity_Consumption.append(element)
    def get_pv_data(self, month, day, day_time):return self.PV_Generation[(
        sum(Constant.MONTHS_LEN[:month-1]) + day-1) * 24 + day_time]
    def get_wind_data(self, month, day, day_time):return self.Wind_Generation[(
        sum(Constant.MONTHS_LEN[:month-1]) + day-1) * 24 + day_time]
    def get_offwind_data(self, month, day, day_time):return self.OffWind_Generation[(
        sum(Constant.MONTHS_LEN[:month-1]) + day-1) * 24 + day_time]
    def get_price_data(self, month, day, day_time):return self.Prices[(
        sum(Constant.MONTHS_LEN[:month-1]) + day-1) * 24 + day_time]
    def get_electricity_cons_data(self, month, day, day_time):return self.Electricity_Consumption[(
        sum(Constant.MONTHS_LEN[:month-1]) + day-1) * 24 + day_time]
    def get_series_pv_data(self, month, day):return self.PV_Generation[(
        sum(Constant.MONTHS_LEN[:month-1]) + day-1) * 24:(
            sum(Constant.MONTHS_LEN[:month-1]) + day-1) * 24 + 24]
    def get_series_wind_data(self, month, day):return self.Wind_Generation[(
        sum(Constant.MONTHS_LEN[:month-1]) + day-1) * 24:(
            sum(Constant.MONTHS_LEN[:month-1]) + day-1) * 24 + 24]
    def get_series_offwind_data(self, month, day):return self.OffWind_Generation[(
        sum(Constant.MONTHS_LEN[:month-1]) + day-1) * 24:(
            sum(Constant.MONTHS_LEN[:month-1]) + day-1) * 24 + 24]
    def get_series_price_data(self, month, day):return self.Prices[(
        sum(Constant.MONTHS_LEN[:month-1]) + day-1) * 24:(
            sum(Constant.MONTHS_LEN[:month-1]) + day-1) * 24 + 24]
    def get_series_electricity_cons_data(self, month, day):return self.Electricity_Consumption[(
        sum(Constant.MONTHS_LEN[:month-1]) + day-1) * 24:(
            sum(Constant.MONTHS_LEN[:month-1]) + day-1) * 24 + 24]

"""**Visualize Historical Wind, Solar, and Price Data for Modelling**"""

price_df = remove_outliers(df_All_2021_hourly['systemSellPrice'])
price_df = pd.DataFrame({'Price': filtered_electricity_price})
price_df['Datetime'] = pd.date_range(start='2021-01-01', periods=len(price_df), freq='H')
price_df.set_index('Datetime', inplace=True)
cleaned_prices = []
for val in price_df['Price']:
    if isinstance(val, (int, float)):
        cleaned_prices.append(val)  # Keep float values unchanged
    elif isinstance(val, str):
        try:
            cleaned_prices.append(float(val))  # Convert strings to float if possible
        except ValueError:
            cleaned_prices.append(np.nan)  # Handle invalid strings as NaN or handle them as needed
    else:
        cleaned_prices.append(np.nan)  # Handle other types as NaN or handle them as needed
price = np.array(cleaned_prices, dtype=float)

"""##**Distributed Generators Module**

Only Marginal Cost of Generators are used
"""

class DG():
    def __init__(self, parameters):

        self.name = parameters.keys()
        self.DG_Cost = parameters['dg_marg_cost']
        self.power_output_max = parameters['power_output_max']
        self.power_output_min = parameters['power_output_min']
        self.ramping_up = parameters['ramping_up']
        self.ramping_down = parameters['ramping_down']
        self.last_step_output = None

    def step(self, action_gen):
        output_change = action_gen * self.ramping_up # constrain the output_change with ramping up boundary
        output = self.current_output + output_change
        if output > 0:
            output = max(self.power_output_min,
                         min(self.power_output_max, output))# meet the constrain
        else:
            output=0
        self.current_output = output

    def _get_cost(self, output):
        if output <= 0:
            cost = 0
        else:
            cost = self.DG_Cost
        print(cost)
        return cost

    def reset(self):
        self.current_output = 0

dg_parameters_RL = {}
generators = ['ccgt', 'coal', 'biomass', 'nuclear', 'hydro']
for generator in generators:
    dg_parameters_RL[generator] = {
        'dg_cap_cost': df_Op_Cap_Cost[generator],
        'dg_marg_cost': df_Op_Marg_Cost[generator],
        'power_output_max': power_output_max[generator],
        'power_output_min': power_output_min[generator],
        'ramping_up': ramping_up[generator],
        'ramping_down': ramping_down[generator]
    }
print(dg_parameters_RL)

"""###**Battery Simulation Module**

Only Marginal Cost of ESS is used
"""

class Battery():
    '''simulate the battery here'''
    def __init__(self, parameters):
        self.BESS_Cost = parameters['bess_marg_cost']
        self.capacity = parameters['capacity']#
        self.max_soc = parameters['max_soc']# max soc 0.8
        self.initial_capacity = parameters['initial_capacity']# initial soc 0.4
        self.min_soc = parameters['min_soc']# 0.2
        self.degradation = parameters['degradation']# degradation cost 0，
        self.max_charge = parameters['max_charge']# max charge ability
        self.max_discharge = parameters['max_discharge']# max discharge ability
        self.efficiency = parameters['efficiency']# charge and discharge efficiency
    def step(self, action_battery):
        energy = action_battery * self.max_charge
        updated_capacity = max(self.min_soc, min(self.max_soc,
         (self.current_capacity * self.capacity + energy) / self.capacity))
        self.energy_change = (updated_capacity-self.current_capacity) * self.capacity# if charge, positive, if discharge, negative
        self.current_capacity = updated_capacity # update capacity to current condition
    def _get_cost(self, energy):# calculate the cost depends on the energy change
        cost = energy**2*self.degradation + self.BESS_Cost
        return cost
    def SOC(self):
        return self.current_capacity
    def reset(self):
        self.current_capacity = np.random.uniform(self.min_soc, self.max_soc)

battery_parameters = {
'bess_cap_cost': data_scenario_df.loc["BESS", "Operating_Capital_Cost"],
'bess_marg_cost': data_scenario_df.loc["BESS", "Operating_Marginal_Cost"],
'capacity': data_scenario_df.loc["BESS", "Capacity"], # MW
'max_charge': data_scenario_df.loc["BESS", "Max_Charge"], # MW
'max_discharge': data_scenario_df.loc["BESS", "Max_Discharge"], # MW
'efficiency': data_scenario_df.loc["BESS", "Efficiency"],
'degradation': data_scenario_df.loc["BESS", "Degradation"], # £/kw
'max_soc': data_scenario_df.loc["BESS", "Max_SOC"],
'min_soc': data_scenario_df.loc["BESS", "Min_SOC"],
'initial_capacity': data_scenario_df.loc["BESS", "Initial_SOC"]}
print(battery_parameters)

"""###**Grid Module**"""

class Grid():
    def __init__(self):
        self.on = True
        if self.on:
            self.exchange_ability = 0.50 # assume that the network’s maximum export
                                       # /import limit is defined as 0.50 MW or 500 KW
        else:
            self.exchange_ability = 0
    def _get_cost(self, current_price, energy_exchange): # energy if charge, will be positive, if discharge will be negative
        return current_price * energy_exchange
    def retrive_past_price(self):
        result = []
        if self.day < 1:
            past_price = self.past_price # self.past price is fixed as the last days price
        else:
            past_price = self.price[24 * (self.day-1):24 * self.day] # get the price data of previous day
        for item in past_price[(self.time-24)::]:# here if current time_step is 10, then the 10th data of past price is extrated to the result as the  first value
            result.append(item)
        for item in self.price[24*self.day:(24*self.day+self.time)]:# continue to retrive data from the past and attend it to the result. as past price is change everytime.
            result.append(item)
        return result

"""#**Build The Energy Storage System (ESS) Environment Module**

The agent learns to charge with low price and then discharge at high price, in this way, it could get benefits.
"""

class ESSEnv(gym.Env):
    def __init__(self, **kwargs):
        super(ESSEnv, self).__init__()
        #parameters
        self.data_manager = DataManager()
        self._load_year_data()
        self.episode_length = kwargs.get('episode_length', 24)
        self.month = None
        self.day = None
        # Control training set and validation set with reset function
        self.TRAIN = True
        self.current_time = None
        self.battery_parameters = kwargs.get('battery_parameters', battery_parameters)
        self.dg_parameters = kwargs.get('dg_parameters', dg_parameters_RL)
        self.penalty_coefficient = 20 # control soft penalty constrain
        self.sell_coefficient = 0.5 # control sell benefits
        # instantiate the components of the environment
        self.grid = Grid()
        # Use Only 1 Battery for now
        self.battery1 = Battery(self.battery_parameters)
        self.dgccgt = DG(self.dg_parameters['ccgt'])
        self.dgcoal = DG(self.dg_parameters['coal'])
        self.dgbiomass = DG(self.dg_parameters['biomass'])
        self.dgnuclear = DG(self.dg_parameters['nuclear'])
        self.dghydro = DG(self.dg_parameters['hydro'])
        # Define Normalized Action Space
        # action space here is [output of gen1, output of gen2, output of gen3,
        # charge/discharge of battery]
        self.action_space = spaces.Box(low=-1, high=1, shape=(6,), dtype=np.float32)# seems here doesn't used
        # state is [time_step, netload, dg_output_last_step] # this time no prive
        self.state_space = spaces.Box(low=0, high=1, shape=(12,), dtype=np.float32)
        self.env_num = 10
        # set state related normalization reference
        self.Length_max = 24
        self.Price_max = max(self.data_manager.Prices)
        self.PV_Generation_max = max(self.data_manager.PV_Generation)
        self.Wind_Generation_max = max(self.data_manager.Wind_Generation)
        self.OffWind_Generation_max = max(self.data_manager.OffWind_Generation)
        #self.Netload_max = max(self.data_manager.Electricity_Consumption) - \
        #max(self.data_manager.PV_Generation) - max(self.data_manager.Wind_Generation) - \
        #max(self.data_manager.OffWindAC_Generation) - max(self.data_manager.OffWindDC_Generation)
        self.Netload_max = max(self.data_manager.Electricity_Consumption)
        self.SOC_max = self.battery1.max_soc
        self.dgccgt_max = self.dgccgt.power_output_max
        self.dgcoal_max = self.dgcoal.power_output_max
        self.dgbiomass_max = self.dgbiomass.power_output_max
        self.dgnuclear_max = self.dgnuclear.power_output_max
        self.dghydro_max = self.dghydro.power_output_max

    def reset(self):
        '''reset is used to initialize the environment, decide the day of month.'''
        #'''We Train with the First Day of December, 2021 and Test with the 31st Day of December, 2021'''
        self.month = np.random.randint(1, 13)# here we choose 12 month
        #self.month = 12
        if self.TRAIN:
            self.day = np.random.randint(1, 21) # Use the first 3 weeks of each Month - Train
            #self.day = 1
        else:
            self.day = np.random.randint(21, Constant.MONTHS_LEN[self.month-1]) # Test Data
            #self.day = 28
        self.current_time = 0
        self.battery1.reset()
        self.dgccgt.reset()
        self.dgcoal.reset()
        self.dgbiomass.reset()
        self.dgnuclear.reset()
        self.dghydro.reset()
        return self._build_state()

    def _build_state(self):
        #we put all original information into state and then transfer it into normalized state
        soc = self.battery1.SOC() / self.SOC_max
        dgccgt_output = self.dgccgt.current_output / self.dgccgt_max
        dgcoal_output = self.dgcoal.current_output / self.dgcoal_max
        dgbiomass_output = self.dgbiomass.current_output / self.dgbiomass_max
        dgnuclear_output = self.dgnuclear.current_output / self.dgnuclear_max
        dghydro_output = self.dghydro.current_output / self.dghydro_max
        time_step = self.current_time / (self.Length_max-1)
        electricity_demand = self.data_manager.get_electricity_cons_data(
            self.month, self.day, self.current_time)
        pv_generation = self.data_manager.get_pv_data(self.month, self.day,
                                                      self.current_time)
        wind_generation = self.data_manager.get_wind_data(self.month, self.day,
                                                      self.current_time)
        offwind_generation = self.data_manager.get_offwind_data(self.month, self.day,
                                                      self.current_time)
        price = self.data_manager.get_price_data(self.month, self.day,
                                                 self.current_time) / self.Price_max
        #gen_sum = pv_generation + wind_generation
        net_load = (electricity_demand - pv_generation - wind_generation - offwind_generation) / self.Netload_max
        obs = np.concatenate((np.float32(time_step), np.float32(price),
                              np.float32(soc), np.float32(net_load),
                              np.float32(pv_generation), np.float32(wind_generation),
                              np.float32(offwind_generation),
                              np.float32(dgccgt_output), np.float32(dgcoal_output),
                              np.float32(dgbiomass_output), np.float32(dgnuclear_output),
                              np.float32(dghydro_output)), axis=None)
        return obs

     # Designing the Actions
     # Since we have defined the states, let's try to define the actions that
     # our agent need to perform to maximize the reward.
     # These are the four actions that we are suggesting
     # action 0: battery_charge/battery_discharge
     # action 1: grid_import
     # action 2: grid_export
    def step(self, action):# state transition here current_obs--take_action--get reward-- get_finish--next_obs
        ## here we want to put take action into each components
        current_obs = self._build_state()
        self.battery1.step(action[0])# here execute the state-transition part, battery.current_capacity also changed
        self.dgccgt.step(action[1])
        self.dgcoal.step(action[2])
        self.dgbiomass.step(action[3])
        self.dgnuclear.step(action[4])
        self.dghydro.step(action[5])

        current_output = np.array((self.dgccgt.current_output, self.dgcoal.current_output,
                                   self.dgbiomass.current_output, self.dgnuclear.current_output,
                                   self.dghydro.current_output, -self.battery1.energy_change))
        self.current_output = current_output
        actual_production = sum(current_output)
        # transfer to normal_state
        netload = current_obs[3] * self.Netload_max
        price = current_obs[1] * self.Price_max
        pv = current_obs[4] * self.PV_Generation_max
        onwind = current_obs[5] * self.Wind_Generation_max
        offwind = current_obs[6] * self.OffWind_Generation_max
        time_step = current_obs[0] * (self.Length_max-1)
        self.netload = netload
        self.price = price
        self.time_step = time_step
        self.pv = pv
        self.onwind = onwind
        self.offwind = offwind
        unbalance = actual_production - netload
        reward = 0
        excess_penalty = 0
        deficient_penalty = 0
        sell_benefit = 0
        buy_cost = 0
        self.excess = 0
        self.shedding = 0
        # logic here is: if unbalance > 0 then it is production excess, so the
        # excess output should be sold to power grid to get benefits
        if unbalance >= 0: # it is now in excess condition
            if unbalance <= self.grid.exchange_ability:
                sell_benefit = self.grid._get_cost(
                    price, unbalance) * self.sell_coefficient
                    #sell money to grid is little [0.029, 0.1]
            else:
                sell_benefit = self.grid._get_cost(
                    price, self.grid.exchange_ability) * self.sell_coefficient
                #real unbalance that even grid could not meet
                self.excess = unbalance-self.grid.exchange_ability
                excess_penalty = self.excess * self.penalty_coefficient
        else:# unbalance <0, its load shedding model, in this case, deficient penalty is used
            if abs(unbalance) <= self.grid.exchange_ability:
                buy_cost = self.grid._get_cost(price, abs(unbalance))
            else:
                buy_cost = self.grid._get_cost(price, self.grid.exchange_ability)
                self.shedding = abs(unbalance)-self.grid.exchange_ability
                deficient_penalty = self.shedding * self.penalty_coefficient
        battery1_cost = self.battery1._get_cost(self.battery1.energy_change)# we set it as 0 this time
        #battery2_cost = self.battery2._get_cost(self.battery2.energy_change)
        #battery3_cost = self.battery3._get_cost(self.battery3.energy_change)
        dgccgt_cost = self.dgccgt._get_cost(self.dgccgt.current_output)
        dgcoal_cost = self.dgcoal._get_cost(self.dgcoal.current_output)
        dgbiomass_cost = self.dgbiomass._get_cost(self.dgbiomass.current_output)
        dgnuclear_cost = self.dgnuclear._get_cost(self.dgnuclear.current_output)
        dghydro_cost = self.dghydro._get_cost(self.dghydro.current_output)

        # Normalized Using the Net Load
        reward = -(
            battery1_cost + dgccgt_cost + dgcoal_cost + dgbiomass_cost + dgnuclear_cost + dghydro_cost +\
            excess_penalty + deficient_penalty - sell_benefit + buy_cost) / self.netload

        self.operation_cost = battery1_cost + dgccgt_cost + dgcoal_cost + dgbiomass_cost +\
        dgnuclear_cost + dghydro_cost + \
        buy_cost - sell_benefit + (self.shedding + self.excess) * self.penalty_coefficient

        self.unbalance = unbalance
        self.real_unbalance = self.shedding + self.excess
        '''here we also need to store the final step outputs for the final steps
         including, soc, output of units for seeing the final states'''
        final_step_outputs = [self.dgccgt.current_output, self.dgcoal.current_output,
                              self.dgbiomass.current_output, self.dgnuclear.current_output,
                              self.dghydro.current_output, self.battery1.current_capacity]
        self.current_time += 1
        finish = (self.current_time==self.episode_length)
        if finish:
            self.final_step_outputs = final_step_outputs
            self.current_time = 0
            next_obs = self.reset()
        else:
            next_obs = self._build_state()
        return current_obs, next_obs, float(reward), finish

    def render(self, current_obs, next_obs, reward, finish):
        print('day={}, hour={:2d}, state={}, next_state={}, reward={:.4f}, terminal={}\n'.format(
            self.day, self.current_time, current_obs, next_obs, reward, finish))

    def _load_year_data(self):
        '''this private function is used to load the electricity consumption,
        Renewable generation and related prices in a year as one hour resolution,
        with the cooperation of class DataProcesser and then all these data are
        stored in data processor'''
        pv_df = df_All_2021_hourly[['SOLAR']]
        pv_df['Datetime'] = pd.date_range(start='2021-01-01', periods=len(pv_df), freq='H')
        pv_df.set_index('Datetime', inplace=True)
        onwind_df = df_All_2021_hourly[['onwind']]
        onwind_df['Datetime'] = pd.date_range(start='2021-01-01', periods=len(onwind_df), freq='H')
        onwind_df.set_index('Datetime', inplace=True)
        offwind_df = df_All_2021_hourly[['offwind']]
        offwind_df['Datetime'] = pd.date_range(start='2021-01-01', periods=len(offwind_df), freq='H')
        offwind_df.set_index('Datetime', inplace=True)
        price_df = filtered_electricity_price
        price_df = pd.DataFrame({'Price': price_df})
        price_df['Datetime'] = pd.date_range(start='2021-01-01', periods=len(price_df), freq='H')
        price_df.set_index('Datetime', inplace=True)
        electricity_df = df_All_2021_hourly[['ND']]
        electricity_df['Datetime'] = pd.date_range(start='2021-01-01', periods=len(electricity_df), freq='H')
        electricity_df.set_index('Datetime', inplace=True)
        pv_data = pv_df['SOLAR'].to_numpy(dtype=float)
        onwind_data = onwind_df['onwind'].to_numpy(dtype=float)
        offwind_data = offwind_df['offwind'].to_numpy(dtype=float)
        cleaned_prices = []
        for val in price_df['Price']:
            if isinstance(val, (int, float)):
                cleaned_prices.append(val)  # Keep float values unchanged
            elif isinstance(val, str):
                try:
                    cleaned_prices.append(float(val))  # Convert strings to float if possible
                except ValueError:
                    cleaned_prices.append(np.nan)  # Handle invalid strings as NaN or handle them as needed
            else:
                cleaned_prices.append(np.nan)  # Handle other types as NaN or handle them as needed
        price = np.array(cleaned_prices, dtype=float)
        electricity = electricity_df['ND'].to_numpy(dtype=float)
        netload = electricity - pv_data - onwind_data - offwind_data
        for element in pv_data:
            self.data_manager.add_pv_element(element)
        for element in onwind_data:
            self.data_manager.add_wind_element(element)
        for element in offwind_data:
            self.data_manager.add_offwind_element(element)
        for element in price:
            self.data_manager.add_price_element(element)
        for element in electricity:
            self.data_manager.add_electricity_element(element)
        return pv_data, onwind_data, offwind_data, price, electricity
env = ESSEnv()

"""###**Test the ESSEnv Environment**"""

env = ESSEnv()
env.TRAIN = True
observation = env.reset()
rewards = []
#tem_action = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1]
print('==================================================================')
print(observation)
print('==================================================================')
for _ in range(48):
    print(f'current month is {env.month}, current day is {env.day}, \
    current time is {env.current_time}')
    action = env.action_space.sample()
    print(f'Sampled Action{action}')
    current_obs, next_obs, reward, finish = env.step(action)
    env.render(current_obs, next_obs, reward, finish)
    current_obs = next_obs
    rewards.append(reward)
print(f'total reward{sum(rewards)}')
print('==================================================================')

"""**Define the Arguments for the environment, training, evaluation, etc**"""

class Arguments:
    def __init__(self, agent=None, env_RL=None):
        self.agent = agent  # Deep Reinforcement Learning algorithm
        self.env_RL = env_RL  # the environment for training
        self.cwd = None  # current work directory. None means set automatically
        self.if_remove = False  # remove the cwd folder? (True, False, None:ask me)
        self.visible_gpu = '0'  # for example: os.environ['CUDA_VISIBLE_DEVICES'] = '0, 2,'
        self.worker_num = 2  # rollout workers number pre GPU (adjust it to get high GPU usage)
        self.num_threads = 8  # cpu_num for evaluate model, torch.set_num_threads(self.num_threads)
        #self._if_per_or_gae = False
        '''Arguments for training'''
        self.num_episode = 500 #200 #3000 #2000
        self.gamma = 0.995  # discount factor of future rewards
        self.learning_rate = 1e-4 #~= 6e-5
        #self.soft_update_tau = 2 ** -8 #~= 5e-3
        self.net_dim = 128  # the network width 128
        #self.n_quantiles = 32
        self.batch_size = 8 # 4096  # num of transitions sampled from replay buffer.
        #self.repeat_times = 2 ** 3  # repeatedly update network to keep critic's loss small
        self.target_step = 512 #4096 #1000 # collect target_step experiences , then update network, 1024
        self.max_memo = 5000000  # capacity of replay buffer
        self.num_episode = 500
        ## arguments for controlling exploration
        #self.explorate_decay = 0.99
        #self.explorate_min = 0.3
        '''Arguments for evaluate'''
        self.random_seed_list = [1234, 2234, 3234, 4234, 5234]
        #self.random_seed_list = [2234]
        self.run_name = 'DRL_Experiments'
        '''Arguments for save and Plot'''
        self.train = True
        self.update_training_data = True
        self.save_network = True
        self.test_network=True
        self.save_test_data=True
        self.compare_with_pyomo=True
        self.plot_on=True

    def init_before_training(self, if_main):
        if self.cwd is None:
            agent_name = self.agent.__class__.__name__
            self.cwd = f'/content/gdrive/MyDrive/RL_Results/{agent_name}/{self.run_name}'
        if if_main:
            import shutil  # remove history according to bool(if_remove)
            if self.if_remove is None:
                self.if_remove = bool(input(f"| PRESS 'y' to REMOVE: {self.cwd}? ") == 'y')
            elif self.if_remove:
                shutil.rmtree(self.cwd, ignore_errors=True)
                print(f"| Remove cwd: {self.cwd}")
            os.makedirs(self.cwd, exist_ok=True)
        np.random.seed(self.random_seed)
        torch.manual_seed(self.random_seed)
        torch.set_num_threads(self.num_threads)
        torch.set_default_dtype(torch.float32)
        os.environ['CUDA_VISIBLE_DEVICES'] = str(self.visible_gpu)# control how many GPU is used

def weight_init(layers):
    for layer in layers:
        torch.nn.init.kaiming_normal_(layer.weight, nonlinearity='relu')

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print("Using ", device)

# ESS Environment
#np.random.seed(seed)
env = ESSEnv()
#env.seed(seed)
action_size = env.action_space.shape[0]
state_size = env.state_space.shape[0]
print('=============================')
print(f'Action Size is: {action_size}')
print('=============================')
print(f'Observation State Size is: {state_size}')
print('=============================')

"""##**Build the Rainbow DQN Algorithm Based on Combining Improvements in DRL - PyTorch Implementation**

**Rainbow DQN Combines the following improvements in DRL Algorithms:**

1. Double DQN (DDQN; van Hasselt, Guez, and Silver 2016) addresses an overestimation bias of Q-learning (van Hasselt 2010), by decoupling selection and evaluation of the bootstrap action.
2. Prioritized experience replay (Schaul et al. 2015) improves data efficiency, by replaying more often transitions from which there is more to learn.
3. The dueling network architecture (Wang et al. 2016) helps to generalize across actions by separately representing state values and action advantages.
4. Learning from multi-step bootstrap targets (Sutton 1988; Sutton and Barto 1998), as used in A3C (Mnih et al. 2016), shifts the bias-variance tradeoff and helps to propagate newly observed rewards faster to earlier visited states.
5. Distributional Q-learning (Bellemare, Dabney, and Munos 2017) learns a categorical distribution of discounted returns, instead of estimating the mean
6. Noisy DQN (Fortunato et al. 2017) uses stochastic network layers for exploration.
This list is, of course, far from exhaustive.

Each of these algorithms enables substantial performance improvements in isolation. Since they do so by addressing radically different issues, and since they build on a shared framework, they could plausibly be combined into a single integrated agent, which is called **Rainbow.**

##**1. Build the DQN Algorithm Module - Base Network**

Implementation according to:

V. Mnih et al., "Human-level control through deep reinforcement learning." Nature, 518 (7540):529–533, 2015.

**A. Build the Replay Buffer**

Implement a replay buffer using numpy.ndarray.
"""

class ReplayBuffer:
    """A simple numpy replay buffer."""

    def __init__(self, obs_dim: int, size: int, batch_size: int = 32):
        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)
        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)
        self.acts_buf = np.zeros([size], dtype=np.float32)
        self.rews_buf = np.zeros([size], dtype=np.float32)
        self.done_buf = np.zeros(size, dtype=np.float32)
        self.max_size, self.batch_size = size, batch_size
        self.ptr, self.size, = 0, 0

    def store(
        self,
        obs: np.ndarray,
        act: np.ndarray,
        rew: float,
        next_obs: np.ndarray,
        done: bool,
    ):
        self.obs_buf[self.ptr] = obs
        self.next_obs_buf[self.ptr] = next_obs
        self.acts_buf[self.ptr] = act
        self.rews_buf[self.ptr] = rew
        self.done_buf[self.ptr] = done
        self.ptr = (self.ptr + 1) % self.max_size
        self.size = min(self.size + 1, self.max_size)

    def sample_batch(self) -> Dict[str, np.ndarray]:
        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)
        return dict(obs=self.obs_buf[idxs],
                    next_obs=self.next_obs_buf[idxs],
                    acts=self.acts_buf[idxs],
                    rews=self.rews_buf[idxs],
                    done=self.done_buf[idxs])

    def __len__(self) -> int:
        return self.size

"""**B. Build the Network Module**

We are going to use a simple network architecture with four fully connected layers and three non-linearity functions (ReLU).

"""

class Network(nn.Module):
    def __init__(self, in_dim: int, out_dim: int):
        """Initialization."""
        super(Network, self).__init__()

        self.layers = nn.Sequential(
            nn.Linear(in_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.Linear(256, out_dim)
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """Forward method implementation."""
        return self.layers(x)

"""**C. Build the DQN Agent**

To:

*   select an action from the input state.
*   take an action and return the response of the env.
*   return dqn loss
*   update the model by gradient descent.
*   hard update from the local model to the target model.
*   train the agent during num_frames
*   test the agent (1 episode)
*   plot the training progresses.
"""

class DQNAgent:
    """DQN Agent interacting with environment.

    Attribute:
        env (gym.Env): openAI Gym environment
        memory (ReplayBuffer): replay memory to store transitions
        batch_size (int): batch size for sampling
        epsilon (float): parameter for epsilon greedy policy
        epsilon_decay (float): step size to decrease epsilon
        max_epsilon (float): max value of epsilon
        min_epsilon (float): min value of epsilon
        target_update (int): period for target model's hard update
        gamma (float): discount factor
        dqn (Network): model to train and select actions
        dqn_target (Network): target model to update
        optimizer (torch.optim): optimizer for training dqn
        transition (list): transition information including
                           state, action, reward, next_state, done
    """

    def __init__(
        self,
        env: gym.Env,
        memory_size: int,
        batch_size: int,
        target_update: int,
        epsilon_decay: float,
        seed: int,
        max_epsilon: float = 1.0,
        min_epsilon: float = 0.1, #0.1,
        gamma: float = 0.995, # 0.99
    ):
        """Initialization.

        Args:
            env (gym.Env): openAI Gym environment
            memory_size (int): length of memory
            batch_size (int): batch size for sampling
            target_update (int): period for target model's hard update
            epsilon_decay (float): step size to decrease epsilon
            lr (float): learning rate
            max_epsilon (float): max value of epsilon
            min_epsilon (float): min value of epsilon
            gamma (float): discount factor
        """
        obs_dim = env.state_space.shape[0]
        action_dim = env.action_space.shape[0]

        self.env = env
        self.memory = ReplayBuffer(obs_dim, memory_size, batch_size)
        self.batch_size = batch_size
        self.epsilon = max_epsilon
        self.epsilon_decay = epsilon_decay
        self.seed = seed
        self.max_epsilon = max_epsilon
        self.min_epsilon = min_epsilon
        self.target_update = target_update
        self.gamma = gamma

        # device: cpu / gpu
        self.device = torch.device(
            "cuda" if torch.cuda.is_available() else "cpu"
        )
        print(self.device)

        # networks: dqn, dqn_target
        self.dqn = Network(obs_dim, action_dim).to(self.device)
        self.dqn_target = Network(obs_dim, action_dim).to(self.device)
        self.dqn_target.load_state_dict(self.dqn.state_dict())
        self.dqn_target.eval() # set the model in evaluation mode

        # optimizer
        self.optimizer = optim.Adam(self.dqn.parameters())

        # transition to store in memory
        self.transition = list()

        # mode: train / test
        self.is_test = False

    def select_action(self, state: np.ndarray) -> np.ndarray:
        """Select an action from the input state."""
        # epsilon greedy policy
        if self.epsilon > np.random.random():
            selected_action = self.env.action_space.sample()
        else:
            #selected_action = self.dqn(
                #torch.FloatTensor(state).to(self.device)
            #).argmax()
            selected_action = self.dqn(
                torch.FloatTensor(state)[0].to(self.device)
            )
            selected_action = selected_action.detach().cpu().numpy()

        if not self.is_test:
            self.transition = [state, selected_action]

        return selected_action

    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:
        """Take an action and return the response of the env."""
        #next_state, reward, terminated, truncated, _ = self.env.step(action)
        state, next_state, reward, done, = self.env.step(action)
        #done = terminated or truncated

        if not self.is_test:
            self.transition += [reward, next_state, done]
            self.memory.store(*self.transition)

        return next_state, reward, done

    def update_model(self) -> torch.Tensor:
        """Update the model by gradient descent."""
        samples = self.memory.sample_batch()

        loss = self._compute_dqn_loss(samples)

        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()

        return loss.item()

    def train(self, num_frames: int):
        """Train the agent."""
        self.env.TRAIN = True

        state = self.env.reset()
        update_cnt = 0
        epsilons = []
        losses = []
        scores = []
        unbalance_list = []
        operation_cost_list = []
        score = 0
        episode_unbalance = 0.0
        episode_operation_cost = 0.0

        # Use 6,048 to cover 252 days of hourly data
        for frame_idx in range(1, num_frames + 1):
            action = self.select_action(state)
            state, next_state, reward, done, = self.env.step(action)

            state = next_state
            score += reward
            episode_unbalance += self.env.real_unbalance
            episode_operation_cost += self.env.operation_cost

            # if episode ends
            if done:
                state = self.env.reset()
                scores.append(score)
                unbalance_list.append(episode_unbalance)
                operation_cost_list.append(episode_operation_cost)
                score = 0
                episode_unbalance = 0.0
                episode_operation_cost = 0.0

            # if training is ready
            if len(self.memory) >= self.batch_size:
                loss = self.update_model()
                losses.append(loss)
                update_cnt += 1

                # linearly decrease epsilon
                self.epsilon = max(
                    self.min_epsilon, self.epsilon - (
                        self.max_epsilon - self.min_epsilon
                    ) * self.epsilon_decay
                )
                epsilons.append(self.epsilon)

                # if hard update is needed
                if update_cnt % self.target_update == 0:
                    self._target_hard_update()

        return score, episode_unbalance, episode_operation_cost

    def test(self) -> None:
        """Test the agent."""

        record_state = []
        record_action = []
        record_reward = []
        record_output = []
        record_cost = []
        record_unbalance = []
        record_system_info = []
        record_init_info = []

        #self.is_test = True
        self.env.TRAIN = False
        #self.env = ESSEnv()
        state = self.env.reset()
        done = False
        score = 0
        episode_unbalance = 0.0
        episode_operation_cost = 0.0

        record_init_info.append([self.env.month, self.env.day, self.env.current_time,
                                 self.env.battery1.current_capacity])
        print(
            f'current testing month is {self.env.month}, day is {self.env.day}, initial_soc is {self.env.battery1.current_capacity}' )

        for i in range(24):
            action = self.select_action(state)
            real_action = action
            state, next_state, reward, done, = self.env.step(action)

            record_system_info.append([state[0], self.env.price, self.env.netload,
                                       self.env.pv, self.env.onwind, self.env.offwind,
                                       action, real_action, self.env.battery1.SOC(),
                                       self.env.battery1.energy_change,
                                       #env.battery2.SOC(), env.battery2.energy_change,
                                       #env.battery3.SOC(), env.battery3.energy_change,
                                       next_state[7], next_state[8], next_state[9],
                                       next_state[10], next_state[11],
                                       self.env.unbalance, self.env.operation_cost,
                                       ])
            record_state.append(state)
            record_action.append(real_action)
            record_reward.append(reward)
            record_output.append(self.env.current_output)
            record_unbalance.append(self.env.unbalance)

            state = next_state
            score += reward
            episode_unbalance += self.env.real_unbalance
            episode_operation_cost += self.env.operation_cost

        record_system_info[-1][7:12] = [self.env.final_step_outputs[0], self.env.final_step_outputs[1],
                                  self.env.final_step_outputs[2], self.env.final_step_outputs[3],
                                     self.env.final_step_outputs[4]]
        ## add information of last step soc
        record_system_info[-1][5] = self.env.final_step_outputs[5]
        record = {'init_info':record_init_info, 'information':record_system_info,
                  'state':record_state, 'action':record_action, 'reward':record_reward,
                  'cost':record_cost, 'unbalance':record_unbalance,
                  'record_output':record_output}

        print("score: ", score)
        print("Unbalance: ", episode_unbalance)
        print("Operation Cost: ", episode_operation_cost)

        return record

    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray]) -> torch.Tensor:
        """Return dqn loss."""
        device = self.device  # for shortening the following lines
        state = torch.FloatTensor(samples["obs"]).to(device)
        next_state = torch.FloatTensor(samples["next_obs"]).to(device)
        action = torch.LongTensor(samples["acts"].reshape(-1, 1)).to(device)
        reward = torch.FloatTensor(samples["rews"].reshape(-1, 1)).to(device)
        done = torch.FloatTensor(samples["done"].reshape(-1, 1)).to(device)

        # G_t   = r + gamma * v(s_{t+1})  if state != Terminal
        #       = r                       otherwise
        curr_q_value = self.dqn(state).gather(1, action)
        next_q_value = self.dqn_target(next_state).max(dim=1, keepdim=True
                                                       )[0].detach()
        mask = 1 - done
        target = (reward + self.gamma * next_q_value * mask).to(self.device)

        # calculate dqn loss
        loss = F.smooth_l1_loss(curr_q_value, target)

        return loss

    def _target_hard_update(self):
        """Hard update: target <- local."""
        self.dqn_target.load_state_dict(self.dqn.state_dict())

    def get_episode_return(self):
        """Train the agent."""
        self.env.TRAIN = True
        state = self.env.reset()
        episode_return = 0
        episode_unbalance = 0.0
        episode_operation_cost = 0.0

        for i in range(24):
            action = self.select_action(state)
            state, next_state, reward, done, = self.env.step(action)

            state = next_state
            episode_return += reward
            episode_unbalance += self.env.real_unbalance
            episode_operation_cost += self.env.operation_cost

            # if episode ends
            if done:
                break
        return episode_return, episode_unbalance, episode_operation_cost

"""**Test the DQN Model on the ESS Environment**"""

cwd = None
if_remove = False
visible_gpu = '0'
worker_num = 2
num_threads = 8
_if_per_or_gae = False
run_name = 'DQN_2_experiments'

def init_before_training(if_main):
    global cwd
    if cwd is None:
        agent_name = agent.__class__.__name__
        cwd = f'/content/gdrive/MyDrive/RL_Results/{agent_name}/{run_name}'
    if if_main:
        import shutil  # remove history according to bool(if_remove)
        global if_remove
        if if_remove is None:
            if_remove = bool(input(f"| PRESS 'y' to REMOVE: {cwd}? ") == 'y')
        elif if_remove:
            shutil.rmtree(cwd, ignore_errors=True)
            print(f"| Remove cwd: {cwd}")
        os.makedirs(cwd, exist_ok=True)
    np.random.seed(random_seed)
    torch.manual_seed(random_seed)
    torch.set_num_threads(num_threads)
    torch.set_default_dtype(torch.float32)
    os.environ['CUDA_VISIBLE_DEVICES'] = str(visible_gpu)

reward_record = {'episode': [], 'steps': [], 'mean_episode_reward': [], 'unbalance': [],
                  'episode_operation_cost': []}

save_network=True
test_network= True
save_test_data=True
update_training_data = True
compare_with_pyomo=True

# random_seed_list = [2234]
random_seed_list = [1234, 2234, 3234, 4234, 5234]

for seed in random_seed_list:
    random_seed = seed
    # parameters
    num_frames = 6048 #200 # 10000
    num_episode = 500
    memory_size = 5000000 # 1000
    batch_size = 8 # 32
    target_update = 512 #4096 # 100
    epsilon_decay = 1 / 2000

    save_network=True
    test_network= True
    save_test_data=True
    update_training_data = True
    compare_with_pyomo=True
    # set different seed
    agent = DQNAgent(env, memory_size, batch_size, target_update,
                     epsilon_decay, seed)
    agent_name = f'{agent.__class__.__name__}'
    env = ESSEnv()
    init_before_training(if_main=True)

    # Train
    agent.train(num_frames)
    reward_record = {'mean_episode_reward': [], 'unbalance': [], 'episode_operation_cost': []}

    # Get One Episode
    for i_episode in range(num_episode):
        with torch.no_grad():
            episode_reward, episode_unbalance, episode_operation_cost = agent.get_episode_return()
            reward_record['mean_episode_reward'].append(episode_reward)
            reward_record['unbalance'].append(episode_unbalance)
            reward_record['episode_operation_cost'].append(episode_operation_cost)
        print(
            f'current episode is {i_episode}, reward:{episode_reward}, unbalance:{episode_unbalance}, Operation Cost:{episode_operation_cost}, Memory Size:{agent.memory.__len__}')

    if update_training_data:
        #reward_record_path = f'{cwd}/reward_data_DQN_2.pkl'
        reward_record_path = f'/content/gdrive/MyDrive/RL_Results/DQNAgent/DQN_2_experiments/reward_data_DQN_2_seed_{seed}.pkl'
        with open(reward_record_path, 'wb') as tf:
            pickle.dump(reward_record, tf)

    act_save_path = f'/content/gdrive/MyDrive/RL_Results/DQNAgent/DQN_2_experiments/actor_DQN_2_seed_{seed}.pth'
    print('training data have been saved')
    if save_network:
        torch.save(agent.dqn.state_dict(), act_save_path)
        print('training finished and actor parameters have been saved')

    '''if test_network:
        cwd = agent_name
        agent.dqn.load_state_dict(torch.load(act_save_path))
        print('parameters have been reloaded and testing')
        record = agent.test()
        eval_data_DQN = pd.DataFrame(record['information'])
        eval_data_DQN.columns = ['time_step', 'price', 'netload', 'action', 'real_action',
                              'soc', 'battery1', 'ccgt', 'coal', 'biomass', 'nuclear', 'hydro',
                                  'unbalance', 'operation_cost']'''

    if test_network:
        cwd = agent_name
        agent.dqn.load_state_dict(torch.load(act_save_path))
        print('parameters have been reloaded and testing')
        all_records = []
        days_list = [22, 23, 24, 25, 26, 27, 28]

        for day in days_list:
            # Reset the environment
            all_records = []
            env.reset()
            env.month = 12
            env.day = day
            print(f'Testing for day {day}')
            record = agent.test()
            all_records.append(record['information'])

            eval_data_DQN = pd.concat(
                [pd.DataFrame(record) for record in all_records], ignore_index=True)
            eval_data_DQN.columns = ['time_step', 'price', 'netload', 'pv', 'onwind', 'offwind',
                                 'action', 'real_action','soc', 'battery1', 'ccgt', 'coal',
                                 'biomass', 'nuclear', 'hydro', 'unbalance', 'operation_cost']

            eval_data_DQN.to_csv(
                f'/content/gdrive/MyDrive/RL_Results/DQNAgent/DQN_2_experiments/eval_data_DQN_{seed}_{day}.csv', index=False)

    if save_test_data:
        test_data_save_path = f'/content/gdrive/MyDrive/RL_Results/DQNAgent/DQN_2_experiments/test_data_DQN_2_seed_{seed}.pkl'
        with open(test_data_save_path, 'wb') as tf:
            pickle.dump(all_records, tf)

    '''compare with pyomo data and results'''
    if compare_with_pyomo:
        month = record['init_info'][0][0]
        day = record['init_info'][0][1]
        initial_soc = record['init_info'][0][3]
        print(initial_soc)

"""##**2. Build the Double DQN Algorithm Module**

Implementation according to:

van Hasselt et al., "Deep Reinforcement Learning with Double Q-learning." arXiv preprint arXiv:1509.06461, 2015.

The Difference Between DQN and Double DQN is:

1. In standard Q-learning and DQN, the max operator uses the same values both to select and to evaluate an action. This makes it more likely to select overestimated values, resulting in overoptimistic value estimates.

But in Double Q-learning, the idea is to reduce overestimations by decomposing the max operation in the target into action selection and action evaluation.
Two value functions are learned by assigning experiences randomly to update one of the two value functions, resulting in two sets of weights. For each update, one set of weights is used to determine the greedy policy and the other to determine its value.
"""

class DDQNAgent:
    """DQN Agent interacting with environment.

    Attribute:
        env (gym.Env): openAI Gym environment
        memory (ReplayBuffer): replay memory to store transitions
        batch_size (int): batch size for sampling
        epsilon (float): parameter for epsilon greedy policy
        epsilon_decay (float): step size to decrease epsilon
        max_epsilon (float): max value of epsilon
        min_epsilon (float): min value of epsilon
        target_update (int): period for target model's hard update
        gamma (float): discount factor
        dqn (Network): model to train and select actions
        dqn_target (Network): target model to update
        optimizer (torch.optim): optimizer for training dqn
        transition (list): transition information including
                           state, action, reward, next_state, done
    """

    def __init__(
        self,
        env: gym.Env,
        memory_size: int,
        batch_size: int,
        target_update: int,
        epsilon_decay: float,
        seed: int,
        max_epsilon: float = 1.0,
        min_epsilon: float = 0.1, #0.1,
        gamma: float = 0.995, # 0.99
    ):
        """Initialization.

        Args:
            env (gym.Env): openAI Gym environment
            memory_size (int): length of memory
            batch_size (int): batch size for sampling
            target_update (int): period for target model's hard update
            epsilon_decay (float): step size to decrease epsilon
            lr (float): learning rate
            max_epsilon (float): max value of epsilon
            min_epsilon (float): min value of epsilon
            gamma (float): discount factor
        """
        obs_dim = env.state_space.shape[0]
        action_dim = env.action_space.shape[0]

        self.env = env
        self.memory = ReplayBuffer(obs_dim, memory_size, batch_size)
        self.batch_size = batch_size
        self.epsilon = max_epsilon
        self.epsilon_decay = epsilon_decay
        self.seed = seed
        self.max_epsilon = max_epsilon
        self.min_epsilon = min_epsilon
        self.target_update = target_update
        self.gamma = gamma

        # device: cpu / gpu
        self.device = torch.device(
            "cuda" if torch.cuda.is_available() else "cpu"
        )
        print(self.device)

        # networks: dqn, dqn_target
        self.dqn = Network(obs_dim, action_dim).to(self.device)
        self.dqn_target = Network(obs_dim, action_dim).to(self.device)
        self.dqn_target.load_state_dict(self.dqn.state_dict())
        self.dqn_target.eval() # set the model in evaluation mode

        # optimizer
        self.optimizer = optim.Adam(self.dqn.parameters())

        # transition to store in memory
        self.transition = list()

        # mode: train / test
        self.is_test = False

    def select_action(self, state: np.ndarray) -> np.ndarray:
        """Select an action from the input state."""
        # epsilon greedy policy
        if self.epsilon > np.random.random():
            selected_action = self.env.action_space.sample()
        else:
            #selected_action = self.dqn(
                #torch.FloatTensor(state).to(self.device)
            #).argmax()
            selected_action = self.dqn(
                torch.FloatTensor(state)[0].to(self.device)
            )
            selected_action = selected_action.detach().cpu().numpy()

        if not self.is_test:
            self.transition = [state, selected_action]

        return selected_action

    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:
        """Take an action and return the response of the env."""
        #next_state, reward, terminated, truncated, _ = self.env.step(action)
        state, next_state, reward, done, = self.env.step(action)
        #done = terminated or truncated

        if not self.is_test:
            self.transition += [reward, next_state, done]
            self.memory.store(*self.transition)

        return next_state, reward, done

    def update_model(self) -> torch.Tensor:
        """Update the model by gradient descent."""
        samples = self.memory.sample_batch()

        loss = self._compute_dqn_loss(samples)

        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()

        return loss.item()

    def train(self, num_frames: int):
        """Train the agent."""
        self.env.TRAIN = True

        state = self.env.reset()
        update_cnt = 0
        epsilons = []
        losses = []
        scores = []
        unbalance_list = []
        operation_cost_list = []
        score = 0
        episode_unbalance = 0.0
        episode_operation_cost = 0.0

        for frame_idx in range(1, num_frames + 1):
            action = self.select_action(state)
            state, next_state, reward, done, = self.env.step(action)

            state = next_state
            score += reward
            episode_unbalance += self.env.real_unbalance
            episode_operation_cost += self.env.operation_cost

            # if episode ends
            if done:
                state = self.env.reset()
                scores.append(score)
                unbalance_list.append(episode_unbalance)
                operation_cost_list.append(episode_operation_cost)
                score = 0
                episode_unbalance = 0.0
                episode_operation_cost = 0.0

            # if training is ready
            if len(self.memory) >= self.batch_size:
                loss = self.update_model()
                losses.append(loss)
                update_cnt += 1

                # linearly decrease epsilon
                self.epsilon = max(
                    self.min_epsilon, self.epsilon - (
                        self.max_epsilon - self.min_epsilon
                    ) * self.epsilon_decay
                )
                epsilons.append(self.epsilon)

                # if hard update is needed
                if update_cnt % self.target_update == 0:
                    self._target_hard_update()

        return score, episode_unbalance, episode_operation_cost

    def test(self) -> None:
        """Test the agent."""

        record_state = []
        record_action = []
        record_reward = []
        record_output = []
        record_cost = []
        record_unbalance = []
        record_system_info = []
        record_init_info = []

        #self.is_test = True
        self.env.TRAIN = False
        #self.env = ESSEnv()
        state = self.env.reset()
        done = False
        score = 0
        episode_unbalance = 0.0
        episode_operation_cost = 0.0

        record_init_info.append([self.env.month, self.env.day, self.env.current_time,
                                 self.env.battery1.current_capacity])
        print(
            f'current testing month is {self.env.month}, day is {self.env.day}, initial_soc is {self.env.battery1.current_capacity}' )

        for i in range(24):
            action = self.select_action(state)
            real_action = action
            state, next_state, reward, done, = self.env.step(action)

            record_system_info.append([state[0], self.env.price, self.env.netload,
                                       self.env.pv, self.env.onwind, self.env.offwind,
                                       action, real_action, self.env.battery1.SOC(),
                                       self.env.battery1.energy_change,
                                       #env.battery2.SOC(), env.battery2.energy_change,
                                       #env.battery3.SOC(), env.battery3.energy_change,
                                       next_state[7], next_state[8], next_state[9],
                                       next_state[10], next_state[11],
                                       self.env.unbalance, self.env.operation_cost])
            record_state.append(state)
            record_action.append(real_action)
            record_reward.append(reward)
            record_output.append(self.env.current_output)
            record_unbalance.append(self.env.unbalance)

            state = next_state
            score += reward
            episode_unbalance += self.env.real_unbalance
            episode_operation_cost += self.env.operation_cost

        record_system_info[-1][7:12] = [self.env.final_step_outputs[0], self.env.final_step_outputs[1],
                                  self.env.final_step_outputs[2], self.env.final_step_outputs[3],
                                     self.env.final_step_outputs[4]]
        ## add information of last step soc
        record_system_info[-1][5] = self.env.final_step_outputs[5]
        record = {'init_info':record_init_info, 'information':record_system_info,
                  'state':record_state, 'action':record_action, 'reward':record_reward,
                  'cost':record_cost, 'unbalance':record_unbalance,
                  'record_output':record_output}

        print("score: ", score)
        print("Unbalance: ", episode_unbalance)
        print("Operation Cost: ", episode_operation_cost)

        return record

    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray]) -> torch.Tensor:
        """Return dqn loss."""
        device = self.device  # for shortening the following lines
        state = torch.FloatTensor(samples["obs"]).to(device)
        next_state = torch.FloatTensor(samples["next_obs"]).to(device)
        action = torch.LongTensor(samples["acts"].reshape(-1, 1)).to(device)
        reward = torch.FloatTensor(samples["rews"].reshape(-1, 1)).to(device)
        done = torch.FloatTensor(samples["done"].reshape(-1, 1)).to(device)

        # G_t   = r + gamma * v(s_{t+1})  if state != Terminal
        #       = r                       otherwise
        curr_q_value = self.dqn(state).gather(1, action)
        #next_q_value = self.dqn_target(next_state).max(dim=1, keepdim=True
                                                       #)[0].detach()
        # Double DQN
        next_q_value = self.dqn_target(next_state).gather(  # Double DQN
            1, self.dqn(next_state).argmax(dim=1, keepdim=True)
        ).detach()

        mask = 1 - done
        target = (reward + self.gamma * next_q_value * mask).to(self.device)

        # calculate dqn loss
        loss = F.smooth_l1_loss(curr_q_value, target)

        return loss

    def _target_hard_update(self):
        """Hard update: target <- local."""
        self.dqn_target.load_state_dict(self.dqn.state_dict())


    def get_episode_return(self):
        """Train the agent."""
        self.env.TRAIN = True
        state = self.env.reset()
        episode_return = 0
        episode_unbalance = 0.0
        episode_operation_cost = 0.0

        for i in range(24):
            action = self.select_action(state)
            state, next_state, reward, done, = self.env.step(action)

            state = next_state
            episode_return += reward
            episode_unbalance += self.env.real_unbalance
            episode_operation_cost += self.env.operation_cost

            # if episode ends
            if done:
                break
        return episode_return, episode_unbalance, episode_operation_cost

"""**Test the Double DQN Model on the ESS Environment**"""

cwd = None
if_remove = False
visible_gpu = '0'
worker_num = 2
num_threads = 8
_if_per_or_gae = False
run_name = 'DDQN_experiments'

def init_before_training(if_main):
    global cwd
    if cwd is None:
        agent_name = agent.__class__.__name__
        cwd = f'/content/gdrive/MyDrive/RL_Results/{agent_name}/{run_name}'
    if if_main:
        import shutil  # remove history according to bool(if_remove)
        global if_remove
        if if_remove is None:
            if_remove = bool(input(f"| PRESS 'y' to REMOVE: {cwd}? ") == 'y')
        elif if_remove:
            shutil.rmtree(cwd, ignore_errors=True)
            print(f"| Remove cwd: {cwd}")
        os.makedirs(cwd, exist_ok=True)
    np.random.seed(random_seed)
    torch.manual_seed(random_seed)
    torch.set_num_threads(num_threads)
    torch.set_default_dtype(torch.float32)
    os.environ['CUDA_VISIBLE_DEVICES'] = str(visible_gpu)

reward_record = {'episode': [], 'steps': [], 'mean_episode_reward': [], 'unbalance': [],
                  'episode_operation_cost': []}

save_network=True
test_network= True
save_test_data=True
update_training_data = True
compare_with_pyomo=True

#random_seed_list = [2234]
random_seed_list = [1234, 2234, 3234, 4234, 5234]

for seed in random_seed_list:
    random_seed = seed
    # parameters
    num_frames = 6048 #200 # 10000
    num_episode = 500
    memory_size = 5000000 # 1000
    batch_size = 8 # 32
    target_update = 512 #4096 # 100
    epsilon_decay = 1 / 2000

    save_network=True
    test_network= True
    save_test_data=True
    update_training_data = True
    compare_with_pyomo=True
    # set different seed
    agent = DDQNAgent(env, memory_size, batch_size, target_update,
                     epsilon_decay, seed)
    agent_name = f'{agent.__class__.__name__}'
    env = ESSEnv()
    init_before_training(if_main=True)

    # Train
    agent.train(num_frames)
    reward_record = {'mean_episode_reward': [], 'unbalance': [], 'episode_operation_cost': []}

    # Get One Episode
    for i_episode in range(num_episode):
        with torch.no_grad():
            episode_reward, episode_unbalance, episode_operation_cost = agent.get_episode_return()
            reward_record['mean_episode_reward'].append(episode_reward)
            reward_record['unbalance'].append(episode_unbalance)
            reward_record['episode_operation_cost'].append(episode_operation_cost)
        print(
            f'current episode is {i_episode}, reward:{episode_reward}, unbalance:{episode_unbalance}, Operation Cost:{episode_operation_cost}, Memory Size:{agent.memory.__len__}')

    if update_training_data:
        reward_record_path = f'/content/gdrive/MyDrive/RL_Results/DDQNAgent/DDQN_experiments/reward_data_DDQN_seed_{seed}.pkl'
        with open(reward_record_path, 'wb') as tf:
            pickle.dump(reward_record, tf)

    act_save_path = f'/content/gdrive/MyDrive/RL_Results/DDQNAgent/DDQN_experiments/actor_DDQN_seed_{seed}.pth'
    print('training data have been saved')
    if save_network:
        torch.save(agent.dqn.state_dict(), act_save_path)
        print('training finished and actor parameters have been saved')

    '''if test_network:
        cwd = agent_name
        agent.dqn.load_state_dict(torch.load(act_save_path))
        print('parameters have been reloaded and testing')
        record = agent.test()
        eval_data_DDQN = pd.DataFrame(record['information'])
        eval_data_DDQN.columns = ['time_step', 'price', 'netload', 'action', 'real_action',
                              'soc', 'battery1', 'ccgt', 'coal', 'biomass', 'nuclear', 'hydro',
                                  'unbalance', 'operation_cost']'''
    if test_network:
        cwd = agent_name
        agent.dqn.load_state_dict(torch.load(act_save_path))
        print('parameters have been reloaded and testing')
        all_records = []
        days_list = [22, 23, 24, 25, 26, 27, 28]

        for day in days_list:
            # Reset the environment
            all_records = []
            env.reset()
            env.month = 12
            env.day = day
            print(f'Testing for day {day}')
            record = agent.test()
            all_records.append(record['information'])

            eval_data_DDQN = pd.concat(
                [pd.DataFrame(record) for record in all_records], ignore_index=True)
            eval_data_DDQN.columns = ['time_step', 'price', 'netload', 'pv', 'onwind', 'offwind',
                                 'action', 'real_action','soc', 'battery1', 'ccgt', 'coal',
                                 'biomass', 'nuclear', 'hydro', 'unbalance', 'operation_cost']

            eval_data_DDQN.to_csv(
                f'/content/gdrive/MyDrive/RL_Results/DDQNAgent/DDQN_experiments/eval_data_DDQN_{seed}_{day}.csv', index=False)

    if save_test_data:
        test_data_save_path = f'/content/gdrive/MyDrive/RL_Results/DDQNAgent/DDQN_experiments/test_data_DDQN_seed_{seed}.pkl'
        with open(test_data_save_path, 'wb') as tf:
            pickle.dump(all_records, tf)

    '''compare with pyomo data and results'''
    if compare_with_pyomo:
        month = record['init_info'][0][0]
        day = record['init_info'][0][1]
        initial_soc = record['init_info'][0][3]
        print(initial_soc)

"""##**3. Build the DQN Algorithm With Prioritized Experience Replay (PER) Module**

Implementation according to:

T. Schaul et al., "Prioritized Experience Replay." arXiv preprint arXiv:1511.05952, 2015..

The central component of prioritized replay is the criterion by which the importance of each transition is measured.

A reasonable approach is to use the magnitude of a transition’s TD error, which indicates how ‘surprising’ or unexpected the transition is.

This algorithm stores the last encountered TD error along with each transition in the replay memory.

The transition with the largest absolute TD error is replayed from the memory.

A Q-learning update is applied to this transition, which updates the weights in proportion to the TD error.

One thing to note that new transitions arrive without a known TD-error, so it puts them at maximal priority in order to guarantee that all experience is seen at least once.

We might use 2 ideas to deal with TD-error:
1. greedy TD-error prioritization,
2. stochastic prioritization.

However, greedy TD-error prioritization has a severe drawback. Greedy prioritization focuses on a small subset of the experience: errors shrink slowly, especially when using function approximation, meaning that the initially high error transitions get replayed frequently. This lack of diversity that makes the system prone to over-fitting.

To overcome this issue, we will use a stochastic sampling method that interpolates between pure greedy prioritization and uniform random sampling.

Recall that in DQN Algorithm, to remove the correlation of observations, it uses uniformly random sampling from the replay buffer. Prioritized replay introduces bias because it doesn't sample experiences uniformly at random due to the sampling proportion correspoding to TD-error.

We can correct this bias by using importance-sampling (IS) weights that fully compensates for the non-uniform probabilities.

Lastly, in typical reinforcement learning scenarios, the unbiased nature of the updates is most important near convergence at the end of training. We therefore exploit the flexibility of annealing the amount of importance-sampling correction over time, by defining a schedule on the exponent that reaches 1 only at the end of learning.

###**Create the Prioritized Experience Replay (PER) Buffer Module for DQN + PER**

The key concept of PER's implementation is Segment Tree. It efficiently stores and samples transitions while managing the priorities of them.
"""

class PrioritizedReplayBuffer(ReplayBuffer):
    """Prioritized Replay buffer.
    Attributes:
        max_priority (float): max priority
        tree_ptr (int): next index of tree
        alpha (float): alpha parameter for prioritized replay buffer
        sum_tree (SumSegmentTree): sum tree for prior
        min_tree (MinSegmentTree): min tree for min prior to get max weight
    """

    def __init__(
        self,
        obs_dim: int,
        size: int,
        batch_size: int = 32,
        alpha: float = 0.6
    ):
        """Initialization."""
        assert alpha >= 0

        super(PrioritizedReplayBuffer, self).__init__(obs_dim, size, batch_size)
        self.max_priority, self.tree_ptr = 1.0, 0
        self.alpha = alpha

        # capacity must be positive and a power of 2.
        tree_capacity = 1
        while tree_capacity < self.max_size:
            tree_capacity *= 2

        self.sum_tree = SumSegmentTree(tree_capacity)
        self.min_tree = MinSegmentTree(tree_capacity)

    def store(
        self,
        obs: np.ndarray,
        act: int,
        rew: float,
        next_obs: np.ndarray,
        done: bool
    ):
        """Store experience and priority."""
        super().store(obs, act, rew, next_obs, done)

        self.sum_tree[self.tree_ptr] = self.max_priority ** self.alpha
        self.min_tree[self.tree_ptr] = self.max_priority ** self.alpha
        self.tree_ptr = (self.tree_ptr + 1) % self.max_size

    def sample_batch(self, beta: float = 0.4) -> Dict[str, np.ndarray]:
        """Sample a batch of experiences."""
        assert len(self) >= self.batch_size
        assert beta > 0

        indices = self._sample_proportional()

        obs = self.obs_buf[indices]
        next_obs = self.next_obs_buf[indices]
        acts = self.acts_buf[indices]
        rews = self.rews_buf[indices]
        done = self.done_buf[indices]
        weights = np.array([self._calculate_weight(i, beta) for i in indices])

        return dict(
            obs=obs,
            next_obs=next_obs,
            acts=acts,
            rews=rews,
            done=done,
            weights=weights,
            indices=indices,
        )

    def update_priorities(self, indices: List[int], priorities: np.ndarray):
        """Update priorities of sampled transitions."""
        assert len(indices) == len(priorities)

        for idx, priority in zip(indices, priorities):
            assert priority > 0
            assert 0 <= idx < len(self)

            self.sum_tree[idx] = priority ** self.alpha
            self.min_tree[idx] = priority ** self.alpha

            self.max_priority = max(self.max_priority, priority)

    def _sample_proportional(self) -> List[int]:
        """Sample indices based on proportions."""
        indices = []
        p_total = self.sum_tree.sum(0, len(self) - 1)
        segment = p_total / self.batch_size

        for i in range(self.batch_size):
            a = segment * i
            b = segment * (i + 1)
            upperbound = random.uniform(a, b)
            idx = self.sum_tree.retrieve(upperbound)
            indices.append(idx)

        return indices

    def _calculate_weight(self, idx: int, beta: float):
        """Calculate the weight of the experience at idx."""
        # get max weight
        p_min = self.min_tree.min() / self.sum_tree.sum()
        max_weight = (p_min * len(self)) ** (-beta)

        # calculate weights
        p_sample = self.sum_tree[idx] / self.sum_tree.sum()
        weight = (p_sample * len(self)) ** (-beta)
        weight = weight / max_weight

        return weight

"""**Build the DQN Agent for the DQN + PER Module**"""

class DQN_PER_Agent:
    """DQN Agent interacting with environment.

    Attribute:
        env (gym.Env): openAI Gym environment
        memory (ReplayBuffer): replay memory to store transitions
        batch_size (int): batch size for sampling
        epsilon (float): parameter for epsilon greedy policy
        epsilon_decay (float): step size to decrease epsilon
        max_epsilon (float): max value of epsilon
        min_epsilon (float): min value of epsilon
        target_update (int): period for target model's hard update
        gamma (float): discount factor
        dqn (Network): model to train and select actions
        dqn_target (Network): target model to update
        optimizer (torch.optim): optimizer for training dqn
        transition (list): transition information including
                           state, action, reward, next_state, done
        beta (float): determines how much importance sampling is used
        prior_eps (float): guarantees every transition can be sampled
    """

    def __init__(
        self,
        env: gym.Env,
        memory_size: int,
        batch_size: int,
        target_update: int,
        epsilon_decay: float,
        seed: int,
        max_epsilon: float = 1.0,
        min_epsilon: float = 0.1, #0.1,
        gamma: float = 0.995, # 0.99
        # PER parameters
        alpha: float = 0.2,
        beta: float = 0.6,
        prior_eps: float = 1e-6,
    ):
        """Initialization.

        Args:
            env (gym.Env): openAI Gym environment
            memory_size (int): length of memory
            batch_size (int): batch size for sampling
            target_update (int): period for target model's hard update
            epsilon_decay (float): step size to decrease epsilon
            lr (float): learning rate
            max_epsilon (float): max value of epsilon
            min_epsilon (float): min value of epsilon
            gamma (float): discount factor
            alpha (float): determines how much prioritization is used
            beta (float): determines how much importance sampling is used
            prior_eps (float): guarantees every transition can be sampled
        """
        obs_dim = env.state_space.shape[0]
        action_dim = env.action_space.shape[0]

        self.env = env
        #self.memory = ReplayBuffer(obs_dim, memory_size, batch_size)
        self.batch_size = batch_size
        self.epsilon = max_epsilon
        self.epsilon_decay = epsilon_decay
        self.seed = seed
        self.max_epsilon = max_epsilon
        self.min_epsilon = min_epsilon
        self.target_update = target_update
        self.gamma = gamma

        # device: cpu / gpu
        self.device = torch.device(
            "cuda" if torch.cuda.is_available() else "cpu"
        )
        print(self.device)

        # PER
        # In DQN, We used "ReplayBuffer(obs_dim, memory_size, batch_size)"
        self.beta = beta
        self.prior_eps = prior_eps
        self.memory = PrioritizedReplayBuffer(
            obs_dim, memory_size, batch_size, alpha
        )

        # networks: dqn, dqn_target
        self.dqn = Network(obs_dim, action_dim).to(self.device)
        self.dqn_target = Network(obs_dim, action_dim).to(self.device)
        self.dqn_target.load_state_dict(self.dqn.state_dict())
        self.dqn_target.eval() # set the model in evaluation mode

        # optimizer
        self.optimizer = optim.Adam(self.dqn.parameters())

        # transition to store in memory
        self.transition = list()

        # mode: train / test
        self.is_test = False

    def select_action(self, state: np.ndarray) -> np.ndarray:
        """Select an action from the input state."""
        # epsilon greedy policy
        if self.epsilon > np.random.random():
            selected_action = self.env.action_space.sample()
        else:
            #selected_action = self.dqn(
                #torch.FloatTensor(state).to(self.device)
            #).argmax()
            selected_action = self.dqn(
                torch.FloatTensor(state)[0].to(self.device)
            )
            selected_action = selected_action.detach().cpu().numpy()

        if not self.is_test:
            self.transition = [state, selected_action]

        return selected_action

    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:
        """Take an action and return the response of the env."""
        #next_state, reward, terminated, truncated, _ = self.env.step(action)
        state, next_state, reward, done, = self.env.step(action)
        #done = terminated or truncated

        if not self.is_test:
            self.transition += [reward, next_state, done]
            self.memory.store(*self.transition)

        return next_state, reward, done

    def update_model(self) -> torch.Tensor:
        """Update the model by gradient descent."""
        # PER needs beta to calculate weights
        samples = self.memory.sample_batch(self.beta)
        weights = torch.FloatTensor(
            samples["weights"].reshape(-1, 1)
        ).to(self.device)
        indices = samples["indices"]

        # PER: importance sampling before average
        elementwise_loss = self._compute_dqn_loss(samples)
        loss = torch.mean(elementwise_loss * weights)

        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()

        # PER: update priorities
        loss_for_prior = elementwise_loss.detach().cpu().numpy()
        new_priorities = loss_for_prior + self.prior_eps
        self.memory.update_priorities(indices, new_priorities)

        return loss.item()

    def train(self, num_frames: int):
        """Train the agent."""
        self.env.TRAIN = True

        state = self.env.reset()
        update_cnt = 0
        epsilons = []
        losses = []
        scores = []
        unbalance_list = []
        operation_cost_list = []
        score = 0
        episode_unbalance = 0.0
        episode_operation_cost = 0.0

        for frame_idx in range(1, num_frames + 1):
            action = self.select_action(state)
            state, next_state, reward, done, = self.env.step(action)

            state = next_state
            score += reward
            episode_unbalance += self.env.real_unbalance
            episode_operation_cost += self.env.operation_cost

            # PER: increase beta
            fraction = min(frame_idx / num_frames, 1.0)
            self.beta = self.beta + fraction * (1.0 - self.beta)

            # if episode ends
            if done:
                state = self.env.reset()
                scores.append(score)
                unbalance_list.append(episode_unbalance)
                operation_cost_list.append(episode_operation_cost)
                score = 0
                episode_unbalance = 0.0
                episode_operation_cost = 0.0

            # if training is ready
            if len(self.memory) >= self.batch_size:
                loss = self.update_model()
                losses.append(loss)
                update_cnt += 1

                # linearly decrease epsilon
                self.epsilon = max(
                    self.min_epsilon, self.epsilon - (
                        self.max_epsilon - self.min_epsilon
                    ) * self.epsilon_decay
                )
                epsilons.append(self.epsilon)

                # if hard update is needed
                if update_cnt % self.target_update == 0:
                    self._target_hard_update()

        return score, episode_unbalance, episode_operation_cost

    def test(self) -> None:
        """Test the agent."""

        record_state = []
        record_action = []
        record_reward = []
        record_output = []
        record_cost = []
        record_unbalance = []
        record_system_info = []
        record_init_info = []

        #self.is_test = True
        self.env.TRAIN = False
        #self.env = ESSEnv()
        state = self.env.reset()
        done = False
        score = 0
        episode_unbalance = 0.0
        episode_operation_cost = 0.0

        record_init_info.append([self.env.month, self.env.day, self.env.current_time,
                                 self.env.battery1.current_capacity])
        print(
            f'current testing month is {self.env.month}, day is {self.env.day}, initial_soc is {self.env.battery1.current_capacity}' )

        for i in range(24):
            action = self.select_action(state)
            real_action = action
            state, next_state, reward, done, = self.env.step(action)

            record_system_info.append([state[0], self.env.price, self.env.netload,
                                       self.env.pv, self.env.onwind, self.env.offwind,
                                       action, real_action, self.env.battery1.SOC(),
                                       self.env.battery1.energy_change,
                                       #env.battery2.SOC(), env.battery2.energy_change,
                                       #env.battery3.SOC(), env.battery3.energy_change,
                                       next_state[7], next_state[8], next_state[9],
                                       next_state[10], next_state[11],
                                       self.env.unbalance, self.env.operation_cost])
            record_state.append(state)
            record_action.append(real_action)
            record_reward.append(reward)
            record_output.append(self.env.current_output)
            record_unbalance.append(self.env.unbalance)

            state = next_state
            score += reward
            episode_unbalance += self.env.real_unbalance
            episode_operation_cost += self.env.operation_cost

        record_system_info[-1][7:12] = [self.env.final_step_outputs[0], self.env.final_step_outputs[1],
                                  self.env.final_step_outputs[2], self.env.final_step_outputs[3],
                                     self.env.final_step_outputs[4]]
        ## add information of last step soc
        record_system_info[-1][5] = self.env.final_step_outputs[5]
        record = {'init_info':record_init_info, 'information':record_system_info,
                  'state':record_state, 'action':record_action, 'reward':record_reward,
                  'cost':record_cost, 'unbalance':record_unbalance,
                  'record_output':record_output}

        print("score: ", score)
        print("Unbalance: ", episode_unbalance)
        print("Operation Cost: ", episode_operation_cost)

        return record

    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray]) -> torch.Tensor:
        """Return dqn loss."""
        device = self.device  # for shortening the following lines
        state = torch.FloatTensor(samples["obs"]).to(device)
        next_state = torch.FloatTensor(samples["next_obs"]).to(device)
        action = torch.LongTensor(samples["acts"].reshape(-1, 1)).to(device)
        reward = torch.FloatTensor(samples["rews"].reshape(-1, 1)).to(device)
        done = torch.FloatTensor(samples["done"].reshape(-1, 1)).to(device)

        # G_t   = r + gamma * v(s_{t+1})  if state != Terminal
        #       = r                       otherwise
        curr_q_value = self.dqn(state).gather(1, action)
        next_q_value = self.dqn_target(next_state).max(dim=1, keepdim=True
                                                       )[0].detach()
        mask = 1 - done
        target = (reward + self.gamma * next_q_value * mask).to(self.device)

        # calculate element-wise dqn loss
        elementwise_loss = F.smooth_l1_loss(curr_q_value, target, reduction="none")

        return elementwise_loss

    def _target_hard_update(self):
        """Hard update: target <- local."""
        self.dqn_target.load_state_dict(self.dqn.state_dict())

    def get_episode_return(self):
        """Train the agent."""
        self.env.TRAIN = True
        state = self.env.reset()
        episode_return = 0
        episode_unbalance = 0.0
        episode_operation_cost = 0.0

        for i in range(24):
            action = self.select_action(state)
            state, next_state, reward, done, = self.env.step(action)

            state = next_state
            episode_return += reward
            episode_unbalance += self.env.real_unbalance
            episode_operation_cost += self.env.operation_cost

            # if episode ends
            if done:
                break
        return episode_return, episode_unbalance, episode_operation_cost

"""**Test the DQN + PER Model on the ESS Environment**"""

cwd = None
if_remove = False
visible_gpu = '0'
worker_num = 2
num_threads = 8
_if_per_or_gae = False
run_name = 'DQN_PER_experiments'

def init_before_training(if_main):
    global cwd
    if cwd is None:
        agent_name = agent.__class__.__name__
        cwd = f'/content/gdrive/MyDrive/RL_Results/{agent_name}/{run_name}'
    if if_main:
        import shutil  # remove history according to bool(if_remove)
        global if_remove
        if if_remove is None:
            if_remove = bool(input(f"| PRESS 'y' to REMOVE: {cwd}? ") == 'y')
        elif if_remove:
            shutil.rmtree(cwd, ignore_errors=True)
            print(f"| Remove cwd: {cwd}")
        os.makedirs(cwd, exist_ok=True)
    np.random.seed(random_seed)
    torch.manual_seed(random_seed)
    torch.set_num_threads(num_threads)
    torch.set_default_dtype(torch.float32)
    os.environ['CUDA_VISIBLE_DEVICES'] = str(visible_gpu)

reward_record = {'episode': [], 'steps': [], 'mean_episode_reward': [], 'unbalance': [],
                  'episode_operation_cost': []}

save_network=True
test_network= True
save_test_data=True
update_training_data = True
compare_with_pyomo=True

#random_seed_list = [2234]
random_seed_list = [1234, 2234, 3234, 4234, 5234]

for seed in random_seed_list:
    random_seed = seed
    # parameters
    num_frames = 6048 #200 # 10000
    num_episode = 500
    memory_size = 5000000 # 1000
    batch_size = 8 # 32
    target_update = 512 #4096 # 100
    epsilon_decay = 1 / 2000

    save_network=True
    test_network= True
    save_test_data=True
    update_training_data = True
    compare_with_pyomo=True
    # set different seed
    agent = DQN_PER_Agent(env, memory_size, batch_size, target_update,
                     epsilon_decay, seed)
    agent_name = f'{agent.__class__.__name__}'
    env = ESSEnv()
    init_before_training(if_main=True)

    # Train
    agent.train(num_frames)
    reward_record = {'mean_episode_reward': [], 'unbalance': [], 'episode_operation_cost': []}

    # Get One Episode
    for i_episode in range(num_episode):
        with torch.no_grad():
            episode_reward, episode_unbalance, episode_operation_cost = agent.get_episode_return()
            reward_record['mean_episode_reward'].append(episode_reward)
            reward_record['unbalance'].append(episode_unbalance)
            reward_record['episode_operation_cost'].append(episode_operation_cost)
        print(
            f'current episode is {i_episode}, reward:{episode_reward}, unbalance:{episode_unbalance}, Operation Cost:{episode_operation_cost}, Memory Size:{agent.memory.__len__}')

    if update_training_data:
        reward_record_path = f'/content/gdrive/MyDrive/RL_Results/DQN_PER_Agent/DQN_PER_experiments/reward_data_DQN_PER_seed_{seed}.pkl'
        with open(reward_record_path, 'wb') as tf:
            pickle.dump(reward_record, tf)

    act_save_path = f'/content/gdrive/MyDrive/RL_Results/DQN_PER_Agent/DQN_PER_experiments/actor_DQN_PER_seed_{seed}.pth'
    print('training data have been saved')
    if save_network:
        torch.save(agent.dqn.state_dict(), act_save_path)
        print('training finished and actor parameters have been saved')

    '''if test_network:
        cwd = agent_name
        agent.dqn.load_state_dict(torch.load(act_save_path))
        print('parameters have been reloaded and testing')
        record = agent.test()
        eval_data_DQN = pd.DataFrame(record['information'])
        eval_data_DQN.columns = ['time_step', 'price', 'netload', 'action', 'real_action',
                              'soc', 'battery1', 'ccgt', 'coal', 'biomass', 'nuclear', 'hydro',
                                  'unbalance', 'operation_cost']'''

    if test_network:
        cwd = agent_name
        agent.dqn.load_state_dict(torch.load(act_save_path))
        print('parameters have been reloaded and testing')
        all_records = []
        days_list = [22, 23, 24, 25, 26, 27, 28]

        for day in days_list:
            # Reset the environment
            all_records = []
            env.reset()
            env.month = 12
            env.day = day
            print(f'Testing for day {day}')
            record = agent.test()
            all_records.append(record['information'])

            eval_data_DQN_PER = pd.concat(
                [pd.DataFrame(record) for record in all_records], ignore_index=True)
            eval_data_DQN_PER.columns = ['time_step', 'price', 'netload', 'pv', 'onwind', 'offwind',
                                 'action', 'real_action','soc', 'battery1', 'ccgt', 'coal',
                                 'biomass', 'nuclear', 'hydro', 'unbalance', 'operation_cost']

            eval_data_DQN_PER.to_csv(
                f'/content/gdrive/MyDrive/RL_Results/DQN_PER_Agent/DQN_PER_experiments/eval_data_DQN_PER_{seed}_{day}.csv', index=False)

    if save_test_data:
        test_data_save_path = f'/content/gdrive/MyDrive/RL_Results/DQN_PER_Agent/DQN_PER_experiments/test_data_DQN_PER_seed_{seed}.pkl'
        with open(test_data_save_path, 'wb') as tf:
            pickle.dump(all_records, tf)

    '''compare with pyomo data and results'''
    if compare_with_pyomo:
        month = record['init_info'][0][0]
        day = record['init_info'][0][1]
        initial_soc = record['init_info'][0][3]
        print(initial_soc)

"""##**4. Build the DQN + Dueling Network Algorithm Module (w/o Double-DQN & PER)**

Implementation according to:

Z. Wang et al., "Dueling Network Architectures for Deep Reinforcement Learning." arXiv preprint arXiv:1511.06581, 2015.

The proposed network architecture, which is named dueling architecture, explicitly separates the representation of state values and (state-dependent) action advantages.

The dueling network automatically produces separate estimates of the state value function and advantage function, without any extra supervision.

Intuitively, the dueling architecture can learn which states are (or are not) valuable, without having to learn the effect of each action for each state.

This is particularly useful in states where its actions do not affect the environment in any relevant way.

**A. Build the Dueling Network Module**

We are going to use a simple network architecture with four fully connected layers and three non-linearity functions (ReLU).

Note how the advantage and value layers are separated from the feature layer.
"""

class DuelingNetwork(nn.Module):
    def __init__(self, in_dim: int, out_dim: int):
        """Initialization."""
        super(DuelingNetwork, self).__init__()

        # set common feature layer
        self.feature_layer = nn.Sequential(
            nn.Linear(in_dim, 256),
            nn.ReLU(),
        )

        # set advantage layer
        self.advantage_layer = nn.Sequential(
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.Linear(256, out_dim),
        )

        # set value layer
        self.value_layer = nn.Sequential(
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.Linear(256, 1),
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """Forward method implementation."""
        feature = self.feature_layer(x)

        value = self.value_layer(feature)
        advantage = self.advantage_layer(feature)

        q = value + advantage - advantage.mean(dim=-1, keepdim=True)

        return q

"""**B. Build the DQN Agent for the DQN + DuelingNet Module**

There is only one difference between DQN_DuelingNet_Agent here and DQN_Agent and that is the usage of clip_grad_norm_ to prevent gradient exploding.
"""

class DQN_DuelingNet_Agent:
    """DQN Agent interacting with environment.

    Attribute:
        env (gym.Env): openAI Gym environment
        memory (ReplayBuffer): replay memory to store transitions
        batch_size (int): batch size for sampling
        epsilon (float): parameter for epsilon greedy policy
        epsilon_decay (float): step size to decrease epsilon
        max_epsilon (float): max value of epsilon
        min_epsilon (float): min value of epsilon
        target_update (int): period for target model's hard update
        gamma (float): discount factor
        dqn (Network): model to train and select actions
        dqn_target (Network): target model to update
        optimizer (torch.optim): optimizer for training dqn
        transition (list): transition information including
                           state, action, reward, next_state, done
    """

    def __init__(
        self,
        env: gym.Env,
        memory_size: int,
        batch_size: int,
        target_update: int,
        epsilon_decay: float,
        seed: int,
        max_epsilon: float = 1.0,
        min_epsilon: float = 0.1, #0.1,
        gamma: float = 0.995, # 0.99
    ):
        """Initialization.

        Args:
            env (gym.Env): openAI Gym environment
            memory_size (int): length of memory
            batch_size (int): batch size for sampling
            target_update (int): period for target model's hard update
            epsilon_decay (float): step size to decrease epsilon
            lr (float): learning rate
            max_epsilon (float): max value of epsilon
            min_epsilon (float): min value of epsilon
            gamma (float): discount factor
        """
        obs_dim = env.state_space.shape[0]
        action_dim = env.action_space.shape[0]

        self.env = env
        self.batch_size = batch_size
        self.epsilon = max_epsilon
        self.epsilon_decay = epsilon_decay
        self.seed = seed
        self.max_epsilon = max_epsilon
        self.min_epsilon = min_epsilon
        self.target_update = target_update
        self.gamma = gamma

        # device: cpu / gpu
        self.device = torch.device(
            "cuda" if torch.cuda.is_available() else "cpu"
        )
        print(self.device)

        self.memory = ReplayBuffer(obs_dim, memory_size, batch_size)

        # networks: dqn, dqn_target
        self.dqn = DuelingNetwork(obs_dim, action_dim).to(self.device)
        self.dqn_target = DuelingNetwork(obs_dim, action_dim).to(self.device)
        self.dqn_target.load_state_dict(self.dqn.state_dict())
        self.dqn_target.eval() # set the model in evaluation mode

        # optimizer
        self.optimizer = optim.Adam(self.dqn.parameters())

        # transition to store in memory
        self.transition = list()

        # mode: train / test
        self.is_test = False

    def select_action(self, state: np.ndarray) -> np.ndarray:
        """Select an action from the input state."""
        # epsilon greedy policy
        if self.epsilon > np.random.random():
            selected_action = self.env.action_space.sample()
        else:
            #selected_action = self.dqn(
                #torch.FloatTensor(state).to(self.device)
            #).argmax()
            selected_action = self.dqn(
                torch.FloatTensor(state)[0].to(self.device)
            )
            selected_action = selected_action.detach().cpu().numpy()

        if not self.is_test:
            self.transition = [state, selected_action]

        return selected_action

    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:
        """Take an action and return the response of the env."""
        #next_state, reward, terminated, truncated, _ = self.env.step(action)
        state, next_state, reward, done, = self.env.step(action)
        #done = terminated or truncated

        if not self.is_test:
            self.transition += [reward, next_state, done]
            self.memory.store(*self.transition)

        return next_state, reward, done

    def update_model(self) -> torch.Tensor:
        """Update the model by gradient descent."""
        samples = self.memory.sample_batch()

        loss = self._compute_dqn_loss(samples)

        self.optimizer.zero_grad()
        loss.backward()

        # DuelingNet: we clip the gradients to have their norm less than or
        # equal to 10.
        clip_grad_norm_(self.dqn.parameters(), 10.0)
        self.optimizer.step()

        return loss.item()

    def train(self, num_frames: int):
        """Train the agent."""
        self.env.TRAIN = True

        state = self.env.reset()
        update_cnt = 0
        epsilons = []
        losses = []
        scores = []
        unbalance_list = []
        operation_cost_list = []
        score = 0
        episode_unbalance = 0.0
        episode_operation_cost = 0.0

        for frame_idx in range(1, num_frames + 1):
            action = self.select_action(state)
            state, next_state, reward, done, = self.env.step(action)

            state = next_state
            score += reward
            episode_unbalance += self.env.real_unbalance
            episode_operation_cost += self.env.operation_cost

            # if episode ends
            if done:
                state = self.env.reset()
                scores.append(score)
                unbalance_list.append(episode_unbalance)
                operation_cost_list.append(episode_operation_cost)
                score = 0
                episode_unbalance = 0.0
                episode_operation_cost = 0.0

            # if training is ready
            if len(self.memory) >= self.batch_size:
                loss = self.update_model()
                losses.append(loss)
                update_cnt += 1

                # linearly decrease epsilon
                self.epsilon = max(
                    self.min_epsilon, self.epsilon - (
                        self.max_epsilon - self.min_epsilon
                    ) * self.epsilon_decay
                )
                epsilons.append(self.epsilon)

                # if hard update is needed
                if update_cnt % self.target_update == 0:
                    self._target_hard_update()

        return score, episode_unbalance, episode_operation_cost

    def test(self) -> None:
        """Test the agent."""

        record_state = []
        record_action = []
        record_reward = []
        record_output = []
        record_cost = []
        record_unbalance = []
        record_system_info = []
        record_init_info = []

        #self.is_test = True
        self.env.TRAIN = False
        #self.env = ESSEnv()
        state = self.env.reset()
        done = False
        score = 0
        episode_unbalance = 0.0
        episode_operation_cost = 0.0

        record_init_info.append([self.env.month, self.env.day, self.env.current_time,
                                 self.env.battery1.current_capacity])
        print(
            f'current testing month is {self.env.month}, day is {self.env.day}, initial_soc is {self.env.battery1.current_capacity}' )

        for i in range(24):
            action = self.select_action(state)
            real_action = action
            state, next_state, reward, done, = self.env.step(action)

            record_system_info.append([state[0], self.env.price, self.env.netload,
                                       self.env.pv, self.env.onwind, self.env.offwind,
                                       action, real_action, self.env.battery1.SOC(),
                                       self.env.battery1.energy_change,
                                       #env.battery2.SOC(), env.battery2.energy_change,
                                       #env.battery3.SOC(), env.battery3.energy_change,
                                       next_state[7], next_state[8], next_state[9],
                                       next_state[10], next_state[11],
                                       self.env.unbalance, self.env.operation_cost])
            record_state.append(state)
            record_action.append(real_action)
            record_reward.append(reward)
            record_output.append(self.env.current_output)
            record_unbalance.append(self.env.unbalance)

            state = next_state
            score += reward
            episode_unbalance += self.env.real_unbalance
            episode_operation_cost += self.env.operation_cost

        record_system_info[-1][7:12] = [self.env.final_step_outputs[0], self.env.final_step_outputs[1],
                                  self.env.final_step_outputs[2], self.env.final_step_outputs[3],
                                     self.env.final_step_outputs[4]]
        ## add information of last step soc
        record_system_info[-1][5] = self.env.final_step_outputs[5]
        record = {'init_info':record_init_info, 'information':record_system_info,
                  'state':record_state, 'action':record_action, 'reward':record_reward,
                  'cost':record_cost, 'unbalance':record_unbalance,
                  'record_output':record_output}

        print("score: ", score)
        print("Unbalance: ", episode_unbalance)
        print("Operation Cost: ", episode_operation_cost)

        return record

    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray]) -> torch.Tensor:
        """Return dqn loss."""
        device = self.device  # for shortening the following lines
        state = torch.FloatTensor(samples["obs"]).to(device)
        next_state = torch.FloatTensor(samples["next_obs"]).to(device)
        action = torch.LongTensor(samples["acts"].reshape(-1, 1)).to(device)
        reward = torch.FloatTensor(samples["rews"].reshape(-1, 1)).to(device)
        done = torch.FloatTensor(samples["done"].reshape(-1, 1)).to(device)

        # G_t   = r + gamma * v(s_{t+1})  if state != Terminal
        #       = r                       otherwise
        curr_q_value = self.dqn(state).gather(1, action)
        next_q_value = self.dqn_target(next_state).max(dim=1, keepdim=True
                                                       )[0].detach()
        mask = 1 - done
        target = (reward + self.gamma * next_q_value * mask).to(self.device)

        # calculate dqn loss
        loss = F.smooth_l1_loss(curr_q_value, target)

        return loss

    def _target_hard_update(self):
        """Hard update: target <- local."""
        self.dqn_target.load_state_dict(self.dqn.state_dict())

    def get_episode_return(self):
        """Train the agent."""
        self.env.TRAIN = True
        state = self.env.reset()
        episode_return = 0
        episode_unbalance = 0.0
        episode_operation_cost = 0.0

        for i in range(24):
            action = self.select_action(state)
            state, next_state, reward, done, = self.env.step(action)

            state = next_state
            episode_return += reward
            episode_unbalance += self.env.real_unbalance
            episode_operation_cost += self.env.operation_cost

            # if episode ends
            if done:
                break
        return episode_return, episode_unbalance, episode_operation_cost

"""**Test the DQN + DuelingNet Model on the ESS Environment**"""

cwd = None
if_remove = False
visible_gpu = '0'
worker_num = 2
num_threads = 8
_if_per_or_gae = False
run_name = 'DQN_DuelingNet_experiments'

def init_before_training(if_main):
    global cwd
    if cwd is None:
        agent_name = agent.__class__.__name__
        cwd = f'/content/gdrive/MyDrive/RL_Results/{agent_name}/{run_name}'
    if if_main:
        import shutil  # remove history according to bool(if_remove)
        global if_remove
        if if_remove is None:
            if_remove = bool(input(f"| PRESS 'y' to REMOVE: {cwd}? ") == 'y')
        elif if_remove:
            shutil.rmtree(cwd, ignore_errors=True)
            print(f"| Remove cwd: {cwd}")
        os.makedirs(cwd, exist_ok=True)
    np.random.seed(random_seed)
    torch.manual_seed(random_seed)
    torch.set_num_threads(num_threads)
    torch.set_default_dtype(torch.float32)
    os.environ['CUDA_VISIBLE_DEVICES'] = str(visible_gpu)

reward_record = {'episode': [], 'steps': [], 'mean_episode_reward': [], 'unbalance': [],
                  'episode_operation_cost': []}

save_network=True
test_network= True
save_test_data=True
update_training_data = True
compare_with_pyomo=True

#random_seed_list = [2234]
random_seed_list = [1234, 2234, 3234, 4234, 5234]

for seed in random_seed_list:
    random_seed = seed
    # parameters
    num_frames = 6048 #200 # 10000
    num_episode = 500
    memory_size = 5000000 # 1000
    batch_size = 8 # 32
    target_update = 512 #4096 # 100
    epsilon_decay = 1 / 2000

    save_network=True
    test_network= True
    save_test_data=True
    update_training_data = True
    compare_with_pyomo=True
    # set different seed
    agent = DQN_DuelingNet_Agent(env, memory_size, batch_size, target_update,
                     epsilon_decay, seed)
    agent_name = f'{agent.__class__.__name__}'
    env = ESSEnv()
    init_before_training(if_main=True)

    # Train
    agent.train(num_frames)
    reward_record = {'mean_episode_reward': [], 'unbalance': [], 'episode_operation_cost': []}

    # Get One Episode
    for i_episode in range(num_episode):
        with torch.no_grad():
            episode_reward, episode_unbalance, episode_operation_cost = agent.get_episode_return()
            reward_record['mean_episode_reward'].append(episode_reward)
            reward_record['unbalance'].append(episode_unbalance)
            reward_record['episode_operation_cost'].append(episode_operation_cost)
        print(
            f'current episode is {i_episode}, reward:{episode_reward}, unbalance:{episode_unbalance}, Operation Cost:{episode_operation_cost}, Memory Size:{agent.memory.__len__}')

    if update_training_data:
        reward_record_path = f'/content/gdrive/MyDrive/RL_Results/DQN_DuelingNet_Agent/DQN_DuelingNet_experiments/reward_data_DQN_DuelingNet_seed_{seed}.pkl'
        with open(reward_record_path, 'wb') as tf:
            pickle.dump(reward_record, tf)

    act_save_path = f'/content/gdrive/MyDrive/RL_Results/DQN_DuelingNet_Agent/DQN_DuelingNet_experiments/actor_DQN_DuelingNet_seed_{seed}.pth'
    print('training data have been saved')
    if save_network:
        torch.save(agent.dqn.state_dict(), act_save_path)
        print('training finished and actor parameters have been saved')

    '''if test_network:
        cwd = agent_name
        agent.dqn.load_state_dict(torch.load(act_save_path))
        print('parameters have been reloaded and testing')
        record = agent.test()
        eval_data_DQN_DuelingNet = pd.DataFrame(record['information'])
        eval_data_DQN_DuelingNet.columns = ['time_step', 'price', 'netload', 'action', 'real_action',
                              'soc', 'battery1', 'ccgt', 'coal', 'biomass', 'nuclear', 'hydro',
                                  'unbalance', 'operation_cost']'''
    if test_network:
        cwd = agent_name
        agent.dqn.load_state_dict(torch.load(act_save_path))
        print('parameters have been reloaded and testing')
        all_records = []
        days_list = [22, 23, 24, 25, 26, 27, 28]

        for day in days_list:
            # Reset the environment
            all_records = []
            env.reset()
            env.month = 12
            env.day = day
            print(f'Testing for day {day}')
            record = agent.test()
            all_records.append(record['information'])

            eval_data_DQN_DuelingNet = pd.concat(
                [pd.DataFrame(record) for record in all_records], ignore_index=True)
            eval_data_DQN_DuelingNet.columns = ['time_step', 'price', 'netload', 'pv', 'onwind', 'offwind',
                                 'action', 'real_action','soc', 'battery1', 'ccgt', 'coal',
                                 'biomass', 'nuclear', 'hydro', 'unbalance', 'operation_cost']

            eval_data_DQN_DuelingNet.to_csv(
                f'/content/gdrive/MyDrive/RL_Results/DQN_DuelingNet_Agent/DQN_DuelingNet_experiments/eval_data_DQN_DuelingNet_{seed}_{day}.csv', index=False)

    if save_test_data:
        test_data_save_path = f'/content/gdrive/MyDrive/RL_Results/DQN_DuelingNet_Agent/DQN_DuelingNet_experiments/test_data_DQN_DuelingNet_seed_{seed}.pkl'
        with open(test_data_save_path, 'wb') as tf:
            pickle.dump(all_records, tf)

    '''compare with pyomo data and results'''
    if compare_with_pyomo:
        month = record['init_info'][0][0]
        day = record['init_info'][0][1]
        initial_soc = record['init_info'][0][3]
        print(initial_soc)

"""##**5. Build the DQN + Noisy Network Algorithm Module (w/o DuelingNet)**

Noisy Networks for Exploration, Implementation according to:

M. Fortunato et al., "Noisy Networks for Exploration." arXiv preprint arXiv:1706.10295, 2017.

NoisyNet is an exploration method that learns perturbations of the network weights to drive exploration. The key insight is that a single change to the weight vector can induce a consistent, and potentially very complex, state-dependent change in policy over multiple time steps.

The noise random variables can be generated by one of the following two ways:

1. Independent Gaussian noise:
2. Factorised Gaussian noise: This is a more computationally efficient way, and its implemented here.

**A. Build the Noisy Layer Module for the DQN + NoisyNet Model**
"""

class NoisyLinear(nn.Module):
    """Noisy linear module for NoisyNet.
    Attributes:
        in_features (int): input size of linear module
        out_features (int): output size of linear module
        std_init (float): initial std value
        weight_mu (nn.Parameter): mean value weight parameter
        weight_sigma (nn.Parameter): std value weight parameter
        bias_mu (nn.Parameter): mean value bias parameter
        bias_sigma (nn.Parameter): std value bias parameter
    """

    def __init__(self, in_features: int, out_features: int, std_init: float = 0.5):
        """Initialization."""
        super(NoisyLinear, self).__init__()

        self.in_features = in_features
        self.out_features = out_features
        self.std_init = std_init

        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features))
        self.weight_sigma = nn.Parameter(
            torch.Tensor(out_features, in_features)
        )
        self.register_buffer(
            "weight_epsilon", torch.Tensor(out_features, in_features)
        )

        self.bias_mu = nn.Parameter(torch.Tensor(out_features))
        self.bias_sigma = nn.Parameter(torch.Tensor(out_features))
        self.register_buffer("bias_epsilon", torch.Tensor(out_features))

        self.reset_parameters()
        self.reset_noise()

    def reset_parameters(self):
        """Reset trainable network parameters (factorized gaussian noise)."""
        mu_range = 1 / math.sqrt(self.in_features)
        self.weight_mu.data.uniform_(-mu_range, mu_range)
        self.weight_sigma.data.fill_(
            self.std_init / math.sqrt(self.in_features)
        )
        self.bias_mu.data.uniform_(-mu_range, mu_range)
        self.bias_sigma.data.fill_(
            self.std_init / math.sqrt(self.out_features)
        )

    def reset_noise(self):
        """Make new noise."""
        epsilon_in = self.scale_noise(self.in_features)
        epsilon_out = self.scale_noise(self.out_features)

        # outer product
        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))
        self.bias_epsilon.copy_(epsilon_out)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """Forward method implementation.

        We don't use separate statements on train / eval mode.
        It doesn't show remarkable difference of performance.
        """
        return F.linear(
            x,
            self.weight_mu + self.weight_sigma * self.weight_epsilon,
            self.bias_mu + self.bias_sigma * self.bias_epsilon,
        )

    @staticmethod
    def scale_noise(size: int) -> torch.Tensor:
        """Set scale to make noise (factorized gaussian noise)."""
        x = torch.randn(size)

        return x.sign().mul(x.abs().sqrt())

"""**B. Build the Noisy Network Module for the DQN + NoisyNet Model**

We use NoisyLinear for the last three FC layers, and there is a method to reset noise at every step.
"""

class NoisyNetwork(nn.Module):
    def __init__(self, in_dim: int, out_dim: int):
        """Initialization."""
        super(NoisyNetwork, self).__init__()

        self.feature = nn.Linear(in_dim, 256)
        self.noisy_layer1 = NoisyLinear(256, 256)
        self.noisy_layer2 = NoisyLinear(256, 256)
        self.noisy_layer3 = NoisyLinear(256, out_dim)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """Forward method implementation."""
        feature = F.relu(self.feature(x))
        hidden1 = F.relu(self.noisy_layer1(feature))
        hidden2 = F.relu(self.noisy_layer2(hidden1))
        out = self.noisy_layer3(hidden2)

        return out

    def reset_noise(self):
        """Reset all noisy layers."""
        self.noisy_layer1.reset_noise()
        self.noisy_layer2.reset_noise()
        self.noisy_layer3.reset_noise()

"""**C. Build the DQN Agent for the DQN + NoisyNet Module**

One thing to note is that NoisyNet is an alternertive to e-greedy method, so all related lines are removed from the original DQN Agent Module
"""

class DQN_NoisyNet_Agent:
    """DQN Agent interacting with environment.

    Attribute:
        env (gym.Env): openAI Gym environment
        memory (ReplayBuffer): replay memory to store transitions
        batch_size (int): batch size for sampling
        target_update (int): period for target model's hard update
        gamma (float): discount factor
        dqn (Network): model to train and select actions
        dqn_target (Network): target model to update
        optimizer (torch.optim): optimizer for training dqn
        transition (list): transition information including
                           state, action, reward, next_state, done
    """

    def __init__(
        self,
        env: gym.Env,
        memory_size: int,
        batch_size: int,
        target_update: int,
        seed: int,
        gamma: float = 0.995, # 0.99
    ):
        """Initialization.

        Args:
            env (gym.Env): openAI Gym environment
            memory_size (int): length of memory
            batch_size (int): batch size for sampling
            target_update (int): period for target model's hard update
            gamma (float): discount factor
        """
        obs_dim = env.state_space.shape[0]
        action_dim = env.action_space.shape[0]

        self.env = env
        self.memory = ReplayBuffer(obs_dim, memory_size, batch_size)
        self.batch_size = batch_size
        self.seed = seed
        self.target_update = target_update
        self.gamma = gamma

        # device: cpu / gpu
        self.device = torch.device(
            "cuda" if torch.cuda.is_available() else "cpu"
        )
        print(self.device)

        # networks: dqn, dqn_target
        self.dqn = NoisyNetwork(obs_dim, action_dim).to(self.device)
        self.dqn_target = NoisyNetwork(obs_dim, action_dim).to(self.device)
        self.dqn_target.load_state_dict(self.dqn.state_dict())
        self.dqn_target.eval() # set the model in evaluation mode

        # optimizer
        self.optimizer = optim.Adam(self.dqn.parameters())

        # transition to store in memory
        self.transition = list()

        # mode: train / test
        self.is_test = False

    def select_action(self, state: np.ndarray) -> np.ndarray:
        """Select an action from the input state."""
        # NoisyNet: no epsilon greedy action selection
        #selected_action = self.dqn(
            #torch.FloatTensor(state)[0].to(self.device)
        #)
        selected_action = self.dqn(
            torch.FloatTensor(state).to(self.device)
        )
        print(selected_action)
        selected_action = selected_action.detach().cpu().numpy()

        if not self.is_test:
            self.transition = [state, selected_action]

        return selected_action

    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:
        """Take an action and return the response of the env."""
        state, next_state, reward, done, = self.env.step(action)

        if not self.is_test:
            self.transition += [reward, next_state, done]
            self.memory.store(*self.transition)

        return next_state, reward, done

    def update_model(self) -> torch.Tensor:
        """Update the model by gradient descent."""
        samples = self.memory.sample_batch()

        loss = self._compute_dqn_loss(samples)

        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()

        # NoisyNet: reset noise
        self.dqn.reset_noise()
        self.dqn_target.reset_noise()

        return loss.item()

    def train(self, num_frames: int):
        """Train the agent."""
        self.env.TRAIN = True

        state = self.env.reset()
        update_cnt = 0
        epsilons = []
        losses = []
        scores = []
        unbalance_list = []
        operation_cost_list = []
        score = 0
        episode_unbalance = 0.0
        episode_operation_cost = 0.0

        for frame_idx in range(1, num_frames + 1):
            action = self.select_action(state)
            state, next_state, reward, done, = self.env.step(action)

            state = next_state
            score += reward
            episode_unbalance += self.env.real_unbalance
            episode_operation_cost += self.env.operation_cost

            # NoisyNet: removed decrease of epsilon

            # if episode ends
            if done:
                state = self.env.reset()
                scores.append(score)
                unbalance_list.append(episode_unbalance)
                operation_cost_list.append(episode_operation_cost)
                score = 0
                episode_unbalance = 0.0
                episode_operation_cost = 0.0

            # if training is ready
            if len(self.memory) >= self.batch_size:
                loss = self.update_model()
                losses.append(loss)
                update_cnt += 1

                # if hard update is needed
                if update_cnt % self.target_update == 0:
                    self._target_hard_update()

        return score, episode_unbalance, episode_operation_cost

    def test(self) -> None:
        """Test the agent."""

        record_state = []
        record_action = []
        record_reward = []
        record_output = []
        record_cost = []
        record_unbalance = []
        record_system_info = []
        record_init_info = []

        #self.is_test = True
        self.env.TRAIN = False
        #self.env = ESSEnv()
        state = self.env.reset()
        done = False
        score = 0
        episode_unbalance = 0.0
        episode_operation_cost = 0.0

        record_init_info.append([self.env.month, self.env.day, self.env.current_time,
                                 self.env.battery1.current_capacity])
        print(
            f'current testing month is {self.env.month}, day is {self.env.day}, initial_soc is {self.env.battery1.current_capacity}' )

        for i in range(24):
            action = self.select_action(state)
            real_action = action
            state, next_state, reward, done, = self.env.step(action)

            record_system_info.append([state[0], self.env.price, self.env.netload,
                                       self.env.pv, self.env.onwind, self.env.offwind,
                                       action, real_action, self.env.battery1.SOC(),
                                       self.env.battery1.energy_change,
                                       #env.battery2.SOC(), env.battery2.energy_change,
                                       #env.battery3.SOC(), env.battery3.energy_change,
                                       next_state[7], next_state[8], next_state[9],
                                       next_state[10], next_state[11],
                                       self.env.unbalance, self.env.operation_cost])
            record_state.append(state)
            record_action.append(real_action)
            record_reward.append(reward)
            record_output.append(self.env.current_output)
            record_unbalance.append(self.env.unbalance)

            state = next_state
            score += reward
            episode_unbalance += self.env.real_unbalance
            episode_operation_cost += self.env.operation_cost

        record_system_info[-1][7:12] = [self.env.final_step_outputs[0], self.env.final_step_outputs[1],
                                  self.env.final_step_outputs[2], self.env.final_step_outputs[3],
                                     self.env.final_step_outputs[4]]
        ## add information of last step soc
        record_system_info[-1][5] = self.env.final_step_outputs[5]
        record = {'init_info':record_init_info, 'information':record_system_info,
                  'state':record_state, 'action':record_action, 'reward':record_reward,
                  'cost':record_cost, 'unbalance':record_unbalance,
                  'record_output':record_output}

        print("score: ", score)
        print("Unbalance: ", episode_unbalance)
        print("Operation Cost: ", episode_operation_cost)

        return record

    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray]) -> torch.Tensor:
        """Return dqn loss."""
        device = self.device  # for shortening the following lines
        state = torch.FloatTensor(samples["obs"]).to(device)
        next_state = torch.FloatTensor(samples["next_obs"]).to(device)
        action = torch.LongTensor(samples["acts"].reshape(-1, 1)).to(device)
        reward = torch.FloatTensor(samples["rews"].reshape(-1, 1)).to(device)
        done = torch.FloatTensor(samples["done"].reshape(-1, 1)).to(device)

        # G_t   = r + gamma * v(s_{t+1})  if state != Terminal
        #       = r                       otherwise
        curr_q_value = self.dqn(state).gather(1, action)
        next_q_value = self.dqn_target(next_state).max(dim=1, keepdim=True
                                                       )[0].detach()
        mask = 1 - done
        target = (reward + self.gamma * next_q_value * mask).to(self.device)

        # calculate dqn loss
        loss = F.smooth_l1_loss(curr_q_value, target)

        return loss

    def _target_hard_update(self):
        """Hard update: target <- local."""
        self.dqn_target.load_state_dict(self.dqn.state_dict())


    def get_episode_return(self):
        """Train the agent."""
        self.env.TRAIN = True
        state = self.env.reset()
        episode_return = 0
        episode_unbalance = 0.0
        episode_operation_cost = 0.0

        for i in range(24):
            action = self.select_action(state)
            state, next_state, reward, done, = self.env.step(action)

            state = next_state
            episode_return += reward
            episode_unbalance += self.env.real_unbalance
            episode_operation_cost += self.env.operation_cost

            # if episode ends
            if done:
                break
        return episode_return, episode_unbalance, episode_operation_cost

"""**Test the DQN + NoisyNet Model on the ESS Environment**"""

cwd = None
if_remove = False
visible_gpu = '0'
worker_num = 2
num_threads = 8
_if_per_or_gae = False
run_name = 'DQN_NoisyNet_experiments'

def init_before_training(if_main):
    global cwd
    if cwd is None:
        agent_name = agent.__class__.__name__
        cwd = f'/content/gdrive/MyDrive/RL_Results/{agent_name}/{run_name}'
    if if_main:
        import shutil  # remove history according to bool(if_remove)
        global if_remove
        if if_remove is None:
            if_remove = bool(input(f"| PRESS 'y' to REMOVE: {cwd}? ") == 'y')
        elif if_remove:
            shutil.rmtree(cwd, ignore_errors=True)
            print(f"| Remove cwd: {cwd}")
        os.makedirs(cwd, exist_ok=True)
    np.random.seed(random_seed)
    torch.manual_seed(random_seed)
    torch.set_num_threads(num_threads)
    torch.set_default_dtype(torch.float32)
    os.environ['CUDA_VISIBLE_DEVICES'] = str(visible_gpu)

reward_record = {'episode': [], 'steps': [], 'mean_episode_reward': [], 'unbalance': [],
                  'episode_operation_cost': []}

save_network=True
test_network= True
save_test_data=True
update_training_data = True
compare_with_pyomo=True

#random_seed_list = [2234]
random_seed_list = [1234, 2234, 3234, 4234, 5234]

for seed in random_seed_list:
    random_seed = seed
    # parameters
    num_frames = 6048 #200 # 10000
    num_episode = 500
    memory_size = 5000000 # 1000
    batch_size = 8 # 32
    target_update = 512 #4096 # 100

    save_network=True
    test_network= True
    save_test_data=True
    update_training_data = True
    compare_with_pyomo=True
    # set different seed
    agent = DQN_NoisyNet_Agent(env, memory_size, batch_size, target_update, seed)
    agent_name = f'{agent.__class__.__name__}'
    env = ESSEnv()
    init_before_training(if_main=True)

    # Train
    agent.train(num_frames)
    reward_record = {'mean_episode_reward': [], 'unbalance': [], 'episode_operation_cost': []}

    # Get One Episode
    for i_episode in range(num_episode):
        with torch.no_grad():
            episode_reward, episode_unbalance, episode_operation_cost = agent.get_episode_return()
            reward_record['mean_episode_reward'].append(episode_reward)
            reward_record['unbalance'].append(episode_unbalance)
            reward_record['episode_operation_cost'].append(episode_operation_cost)
        print(
            f'current episode is {i_episode}, reward:{episode_reward}, unbalance:{episode_unbalance}, Operation Cost:{episode_operation_cost}, Memory Size:{agent.memory.__len__}')

    if update_training_data:
        reward_record_path = f'/content/gdrive/MyDrive/RL_Results/DQN_NoisyNet_Agent/DQN_NoisyNet_experiments/reward_data_DQN_NoisyNet_seed_{seed}.pkl'
        with open(reward_record_path, 'wb') as tf:
            pickle.dump(reward_record, tf)

    act_save_path = f'/content/gdrive/MyDrive/RL_Results/DQN_NoisyNet_Agent/DQN_NoisyNet_experiments/actor_DQN_NoisyNet_seed_{seed}.pth'
    print('training data have been saved')
    if save_network:
        torch.save(agent.dqn.state_dict(), act_save_path)
        print('training finished and actor parameters have been saved')

    '''if test_network:
        cwd = agent_name
        agent.dqn.load_state_dict(torch.load(act_save_path))
        print('parameters have been reloaded and testing')
        record = agent.test()
        eval_data_DQN_NoisyNet = pd.DataFrame(record['information'])
        eval_data_DQN_NoisyNet.columns = ['time_step', 'price', 'netload', 'action', 'real_action',
                              'soc', 'battery1', 'ccgt', 'coal', 'biomass', 'nuclear', 'hydro',
                                  'unbalance', 'operation_cost']'''
    if test_network:
        cwd = agent_name
        agent.dqn.load_state_dict(torch.load(act_save_path))
        print('parameters have been reloaded and testing')
        all_records = []
        days_list = [22, 23, 24, 25, 26, 27, 28]

        for day in days_list:
            # Reset the environment
            all_records = []
            env.reset()
            env.month = 12
            env.day = day
            print(f'Testing for day {day}')
            record = agent.test()
            all_records.append(record['information'])

            eval_data_DQN_NoisyNet = pd.concat(
                [pd.DataFrame(record) for record in all_records], ignore_index=True)
            eval_data_DQN_NoisyNet.columns = ['time_step', 'price', 'netload', 'pv', 'onwind', 'offwind',
                                 'action', 'real_action','soc', 'battery1', 'ccgt', 'coal',
                                 'biomass', 'nuclear', 'hydro', 'unbalance', 'operation_cost']

            eval_data_DQN_NoisyNet.to_csv(
                f'/content/gdrive/MyDrive/RL_Results/DQN_NoisyNet_Agent/DQN_NoisyNet_experiments/eval_data_DQN_NoisyNet_{seed}_{day}.csv', index=False)

    if save_test_data:
        test_data_save_path = f'/content/gdrive/MyDrive/RL_Results/DQN_NoisyNet_Agent/DQN_NoisyNet_experiments/test_data_DQN_NoisyNet_seed_{seed}.pkl'
        with open(test_data_save_path, 'wb') as tf:
            pickle.dump(all_records, tf)

    '''compare with pyomo data and results'''
    if compare_with_pyomo:
        month = record['init_info'][0][0]
        day = record['init_info'][0][1]
        initial_soc = record['init_info'][0][3]
        print(initial_soc)

"""##**6. Build the Categorical DQN (C51)Module - A Distributional DRL Algorithm**

Implementation according to:

M. G. Bellemare et al., "A Distributional Perspective on Reinforcement Learning." arXiv preprint arXiv:1707.06887, 2017.

The authors argued the importance of learning the distribution of returns instead of the expected return, and they proposed to model such distributions with probability masses placed on a discrete support.

**A. Build the Network Module for the Categorical DQN Model**

The parametrized distribution can be represented by a neural network, as in DQN, but with atom_size x out_dim outputs. A softmax is applied independently for each action dimension of the output to ensure that the distribution for each action is appropriately normalized.
"""

class CategoricalDQNetwork(nn.Module):
    def __init__(
        self,
        in_dim: int,
        out_dim: int,
        atom_size: int,
        support: torch.Tensor
    ):
        """Initialization."""
        super(CategoricalDQNetwork, self).__init__()

        self.support = support
        self.out_dim = out_dim
        self.atom_size = atom_size

        self.layers = nn.Sequential(
            nn.Linear(in_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.Linear(256, out_dim * atom_size)
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """Forward method implementation."""
        dist = self.dist(x)
        q = torch.sum(dist * self.support, dim=2)

        return q

    def dist(self, x: torch.Tensor) -> torch.Tensor:
        """Get distribution for atoms."""
        q_atoms = self.layers(x).view(-1, self.out_dim, self.atom_size)
        dist = F.softmax(q_atoms, dim=-1)
        dist = dist.clamp(min=1e-3)  # for avoiding nans

        return dist

"""**B. Build the Categorical DQN Agent for the Categorical DQN Model**"""

class Categorical_DQN_Agent:
    """DQN Agent interacting with environment.

    Attribute:
        env (gym.Env): openAI Gym environment
        memory (ReplayBuffer): replay memory to store transitions
        batch_size (int): batch size for sampling
        epsilon (float): parameter for epsilon greedy policy
        epsilon_decay (float): step size to decrease epsilon
        max_epsilon (float): max value of epsilon
        min_epsilon (float): min value of epsilon
        target_update (int): period for target model's hard update
        gamma (float): discount factor
        dqn (Network): model to train and select actions
        dqn_target (Network): target model to update
        optimizer (torch.optim): optimizer for training dqn
        transition (list): transition information including
                           state, action, reward, next_state, done
        v_min (float): min value of support
        v_max (float): max value of support
        atom_size (int): the unit number of support
        support (torch.Tensor): support for categorical dqn
    """

    def __init__(
        self,
        env: gym.Env,
        memory_size: int,
        batch_size: int,
        target_update: int,
        epsilon_decay: float,
        seed: int,
        max_epsilon: float = 1.0,
        min_epsilon: float = 0.1, #0.1,
        gamma: float = 0.995, # 0.99
        # Categorical DQN parameters
        v_min: float = -300, # -10, # 0.0,
        v_max: float = 300, # 10, # 200.0,
        atom_size: int = 510, #51
    ):
        """Initialization.

        Args:
            env (gym.Env): openAI Gym environment
            memory_size (int): length of memory
            batch_size (int): batch size for sampling
            target_update (int): period for target model's hard update
            epsilon_decay (float): step size to decrease epsilon
            lr (float): learning rate
            max_epsilon (float): max value of epsilon
            min_epsilon (float): min value of epsilon
            gamma (float): discount factor
            v_min (float): min value of support
            v_max (float): max value of support
            atom_size (int): the unit number of support
        """
        obs_dim = env.state_space.shape[0]
        action_dim = env.action_space.shape[0]

        self.env = env
        self.memory = ReplayBuffer(obs_dim, memory_size, batch_size)
        self.batch_size = batch_size
        self.epsilon = max_epsilon
        self.epsilon_decay = epsilon_decay
        self.seed = seed
        self.max_epsilon = max_epsilon
        self.min_epsilon = min_epsilon
        self.target_update = target_update
        self.gamma = gamma

        # device: cpu / gpu
        self.device = torch.device(
            "cuda" if torch.cuda.is_available() else "cpu"
        )
        print(self.device)

        # Categorical DQN parameters
        self.v_min = v_min
        self.v_max = v_max
        self.atom_size = atom_size
        self.support = torch.linspace(
            self.v_min, self.v_max, self.atom_size
        ).to(self.device)

        # networks: dqn, dqn_target
        self.dqn = CategoricalDQNetwork(obs_dim, action_dim, atom_size,
                                        self.support).to(self.device)
        self.dqn_target = CategoricalDQNetwork(obs_dim, action_dim, atom_size,
                                        self.support).to(self.device)
        self.dqn_target.load_state_dict(self.dqn.state_dict())
        self.dqn_target.eval() # set the model in evaluation mode

        # optimizer
        self.optimizer = optim.Adam(self.dqn.parameters())

        # transition to store in memory
        self.transition = list()

        # mode: train / test
        self.is_test = False

    def select_action(self, state: np.ndarray) -> np.ndarray:
        """Select an action from the input state."""
        # epsilon greedy policy
        if self.epsilon > np.random.random():
            selected_action = self.env.action_space.sample()
            print(selected_action)
        else:
            selected_action = self.dqn(
                torch.FloatTensor(state)[0].to(self.device)
            )
            print(selected_action)
            selected_action = selected_action.detach().cpu().numpy()

        if not self.is_test:
            self.transition = [state, selected_action]

        return selected_action

    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:
        """Take an action and return the response of the env."""
        state, next_state, reward, done, = self.env.step(action)

        if not self.is_test:
            self.transition += [reward, next_state, done]
            self.memory.store(*self.transition)

        return next_state, reward, done

    def update_model(self) -> torch.Tensor:
        """Update the model by gradient descent."""
        samples = self.memory.sample_batch()

        loss = self._compute_dqn_loss(samples)

        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()

        return loss.item()

    def train(self, num_frames: int, plotting_interval: int = 200):
        """Train the agent."""
        self.env.TRAIN = True

        state = self.env.reset()
        update_cnt = 0
        epsilons = []
        losses = []
        scores = []
        unbalance_list = []
        operation_cost_list = []
        score = 0
        episode_unbalance = 0.0
        episode_operation_cost = 0.0

        for frame_idx in range(1, num_frames + 1):
            action = self.select_action(state)
            state, next_state, reward, done, = self.env.step(action)

            state = next_state
            score += reward
            episode_unbalance += self.env.real_unbalance
            episode_operation_cost += self.env.operation_cost

            # if episode ends
            if done:
                state = self.env.reset()
                scores.append(score)
                unbalance_list.append(episode_unbalance)
                operation_cost_list.append(episode_operation_cost)
                score = 0
                episode_unbalance = 0.0
                episode_operation_cost = 0.0

            # if training is ready
            if len(self.memory) >= self.batch_size:
                loss = self.update_model()
                losses.append(loss)
                update_cnt += 1

                # linearly decrease epsilon
                self.epsilon = max(
                    self.min_epsilon, self.epsilon - (
                        self.max_epsilon - self.min_epsilon
                    ) * self.epsilon_decay
                )
                epsilons.append(self.epsilon)

                # if hard update is needed
                if update_cnt % self.target_update == 0:
                    self._target_hard_update()

        return score, episode_unbalance, episode_operation_cost

    def test(self) -> None:
        """Test the agent."""

        record_state = []
        record_action = []
        record_reward = []
        record_output = []
        record_cost = []
        record_unbalance = []
        record_system_info = []
        record_init_info = []

        #self.is_test = True
        self.env.TRAIN = False
        #self.env = ESSEnv()
        state = self.env.reset()
        done = False
        score = 0
        episode_unbalance = 0.0
        episode_operation_cost = 0.0

        record_init_info.append([self.env.month, self.env.day, self.env.current_time,
                                 self.env.battery1.current_capacity])
        print(
            f'current testing month is {self.env.month}, day is {self.env.day}, initial_soc is {self.env.battery1.current_capacity}' )

        for i in range(24):
            action = self.select_action(state)
            real_action = action
            state, next_state, reward, done, = self.env.step(action)

            record_system_info.append([state[0], self.env.price, self.env.netload,
                                       self.env.pv, self.env.onwind, self.env.offwind,
                                       action, real_action, self.env.battery1.SOC(),
                                       self.env.battery1.energy_change,
                                       #env.battery2.SOC(), env.battery2.energy_change,
                                       #env.battery3.SOC(), env.battery3.energy_change,
                                       next_state[7], next_state[8], next_state[9],
                                       next_state[10], next_state[11],
                                       self.env.unbalance, self.env.operation_cost])
            record_state.append(state)
            record_action.append(real_action)
            record_reward.append(reward)
            record_output.append(self.env.current_output)
            record_unbalance.append(self.env.unbalance)

            state = next_state
            score += reward
            episode_unbalance += self.env.real_unbalance
            episode_operation_cost += self.env.operation_cost

        record_system_info[-1][7:12] = [self.env.final_step_outputs[0], self.env.final_step_outputs[1],
                                  self.env.final_step_outputs[2], self.env.final_step_outputs[3],
                                     self.env.final_step_outputs[4]]
        ## add information of last step soc
        record_system_info[-1][5] = self.env.final_step_outputs[5]
        record = {'init_info':record_init_info, 'information':record_system_info,
                  'state':record_state, 'action':record_action, 'reward':record_reward,
                  'cost':record_cost, 'unbalance':record_unbalance,
                  'record_output':record_output}

        print("score: ", score)
        print("Unbalance: ", episode_unbalance)
        print("Operation Cost: ", episode_operation_cost)

        return record

    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray]) -> torch.Tensor:
        """Return dqn loss."""
        device = self.device  # for shortening the following lines
        state = torch.FloatTensor(samples["obs"]).to(device)
        next_state = torch.FloatTensor(samples["next_obs"]).to(device)
        action = torch.LongTensor(samples["acts"].reshape(-1, 1)).to(device)
        reward = torch.FloatTensor(samples["rews"].reshape(-1, 1)).to(device)
        done = torch.FloatTensor(samples["done"].reshape(-1, 1)).to(device)

        # Categorical DQN algorithm
        delta_z = float(self.v_max - self.v_min) / (self.atom_size - 1)

        with torch.no_grad():
            #next_action = self.dqn_target(next_state).argmax(1)
            next_action = self.dqn_target(next_state)[0]
            next_dist = self.dqn_target.dist(next_state)
            next_dist = next_dist[range(self.batch_size), next_action]

            t_z = reward + (1 - done) * self.gamma * self.support
            t_z = t_z.clamp(min=self.v_min, max=self.v_max)
            b = (t_z - self.v_min) / delta_z
            l = b.floor().long()
            u = b.ceil().long()

            offset = (
                torch.linspace(
                    0, (self.batch_size - 1) * self.atom_size, self.batch_size
                ).long()
                .unsqueeze(1)
                .expand(self.batch_size, self.atom_size)
                .to(self.device)
            )

            proj_dist = torch.zeros(next_dist.size(), device=self.device)
            proj_dist.view(-1).index_add_(
                0, (l + offset).view(-1), (next_dist * (u.float() - b)).view(-1)
            )
            proj_dist.view(-1).index_add_(
                0, (u + offset).view(-1), (next_dist * (b - l.float())).view(-1)
            )

        dist = self.dqn.dist(state)
        log_p = torch.log(dist[range(self.batch_size), action])

        loss = -(proj_dist * log_p).sum(1).mean()

        return loss

    def _target_hard_update(self):
        """Hard update: target <- local."""
        self.dqn_target.load_state_dict(self.dqn.state_dict())

    def get_episode_return(self):
        """Train the agent."""
        self.env.TRAIN = True
        state = self.env.reset()
        episode_return = 0
        episode_unbalance = 0.0
        episode_operation_cost = 0.0

        for i in range(24):
            action = self.select_action(state)
            state, next_state, reward, done, = self.env.step(action)

            state = next_state
            episode_return += reward
            episode_unbalance += self.env.real_unbalance
            episode_operation_cost += self.env.operation_cost

            # if episode ends
            if done:
                break
        return episode_return, episode_unbalance, episode_operation_cost

"""**Test the Categorical DQN Model on the ESS Environment**"""

cwd = None
if_remove = False
visible_gpu = '0'
worker_num = 2
num_threads = 8
_if_per_or_gae = False
run_name = 'Categorical_DQN_experiments'

def init_before_training(if_main):
    global cwd
    if cwd is None:
        agent_name = agent.__class__.__name__
        cwd = f'/content/gdrive/MyDrive/RL_Results/{agent_name}/{run_name}'
    if if_main:
        import shutil  # remove history according to bool(if_remove)
        global if_remove
        if if_remove is None:
            if_remove = bool(input(f"| PRESS 'y' to REMOVE: {cwd}? ") == 'y')
        elif if_remove:
            shutil.rmtree(cwd, ignore_errors=True)
            print(f"| Remove cwd: {cwd}")
        os.makedirs(cwd, exist_ok=True)
    np.random.seed(random_seed)
    torch.manual_seed(random_seed)
    torch.set_num_threads(num_threads)
    torch.set_default_dtype(torch.float32)
    os.environ['CUDA_VISIBLE_DEVICES'] = str(visible_gpu)

reward_record = {'episode': [], 'steps': [], 'mean_episode_reward': [], 'unbalance': [],
                  'episode_operation_cost': []}

save_network=True
test_network= True
save_test_data=True
update_training_data = True
compare_with_pyomo=True

#random_seed_list = [2234]
random_seed_list = [1234, 2234, 3234, 4234, 5234]

for seed in random_seed_list:
    random_seed = seed
    # parameters
    num_frames = 6048 #200 # 10000
    num_episode = 500
    memory_size = 5000000 # 1000
    batch_size = 8 # 32
    target_update = 512 #4096 # 100
    epsilon_decay = 1 / 2000

    save_network=True
    test_network= True
    save_test_data=True
    update_training_data = True
    compare_with_pyomo=True
    # set different seed
    agent = Categorical_DQN_Agent(env, memory_size, batch_size, target_update,
                     epsilon_decay, seed)
    agent_name = f'{agent.__class__.__name__}'
    env = ESSEnv()
    init_before_training(if_main=True)

    # Train
    agent.train(num_frames)
    reward_record = {'mean_episode_reward': [], 'unbalance': [], 'episode_operation_cost': []}

    # Get One Episode
    for i_episode in range(num_episode):
        with torch.no_grad():
            episode_reward, episode_unbalance, episode_operation_cost = agent.get_episode_return()
            reward_record['mean_episode_reward'].append(episode_reward)
            reward_record['unbalance'].append(episode_unbalance)
            reward_record['episode_operation_cost'].append(episode_operation_cost)
        print(
            f'current episode is {i_episode}, reward:{episode_reward}, unbalance:{episode_unbalance}, Operation Cost:{episode_operation_cost}, Memory Size:{agent.memory.__len__}')

    if update_training_data:
        reward_record_path = f'/content/gdrive/MyDrive/RL_Results/Categorical_DQN_Agent/Categorical_DQN_experiments/reward_data_Categorical_DQN_seed_{seed}.pkl'
        with open(reward_record_path, 'wb') as tf:
            pickle.dump(reward_record, tf)

    act_save_path = f'/content/gdrive/MyDrive/RL_Results/Categorical_DQN_Agent/Categorical_DQN_experiments/actor_Categorical_DQN_seed_{seed}.pth'
    print('training data have been saved')
    if save_network:
        torch.save(agent.dqn.state_dict(), act_save_path)
        print('training finished and actor parameters have been saved')

    '''if test_network:
        cwd = agent_name
        agent.dqn.load_state_dict(torch.load(act_save_path))
        print('parameters have been reloaded and testing')
        record = agent.test()
        eval_data_Categorical_DQN = pd.DataFrame(record['information'])
        eval_data_Categorical_DQN.columns = ['time_step', 'price', 'netload', 'action', 'real_action',
                              'soc', 'battery1', 'ccgt', 'coal', 'biomass', 'nuclear', 'hydro',
                                  'unbalance', 'operation_cost']'''
    if test_network:
        cwd = agent_name
        agent.dqn.load_state_dict(torch.load(act_save_path))
        print('parameters have been reloaded and testing')
        all_records = []
        days_list = [22, 23, 24, 25, 26, 27, 28]

        for day in days_list:
            # Reset the environment
            all_records = []
            env.reset()
            env.month = 12
            env.day = day
            print(f'Testing for day {day}')
            record = agent.test()
            all_records.append(record['information'])

            eval_data_Categorical_DQN = pd.concat(
                [pd.DataFrame(record) for record in all_records], ignore_index=True)
            eval_data_Categorical_DQN.columns = ['time_step', 'price', 'netload', 'pv', 'onwind', 'offwind',
                                 'action', 'real_action','soc', 'battery1', 'ccgt', 'coal',
                                 'biomass', 'nuclear', 'hydro', 'unbalance', 'operation_cost']

            eval_data_Categorical_DQN.to_csv(
                f'/content/gdrive/MyDrive/RL_Results/Categorical_DQN_Agent/Categorical_DQN_experiments/eval_data_Categorical_DQN_{seed}_{day}.csv', index=False)

    if save_test_data:
        test_data_save_path = f'/content/gdrive/MyDrive/RL_Results/Categorical_DQN_Agent/Categorical_DQN_experiments/test_data_Categorical_DQN_seed_{seed}.pkl'
        with open(test_data_save_path, 'wb') as tf:
            pickle.dump(all_records, tf)

    '''compare with pyomo data and results'''
    if compare_with_pyomo:
        month = record['init_info'][0][0]
        day = record['init_info'][0][1]
        initial_soc = record['init_info'][0][3]
        print(initial_soc)

"""##**7. Build the DQN + N-Step Learning Agent Module**

Implementation according to:

R. S. Sutton, "Learning to predict by the methods of temporal differences." Machine learning, 3(1):9–44, 1988.

Q-learning accumulates a single reward and then uses the greedy action at the next step to bootstrap. Alternatively, forward-view multi-step targets can be used (Sutton 1988). We call it Truncated N-Step Return from a given state

**A. Build the Replay Buffer for N-step learning**

Implement a replay buffer using numpy.ndarray.
"""

class ReplayBufferNStep_Learning:
    """A simple numpy replay buffer."""

    def __init__(
        self,
        obs_dim: int,
        size: int,
        batch_size: int = 32,
        n_step: int = 3,
        gamma: float = 0.995,
    ):
        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)
        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)
        self.acts_buf = np.zeros([size], dtype=np.float32)
        self.rews_buf = np.zeros([size], dtype=np.float32)
        self.done_buf = np.zeros(size, dtype=np.float32)
        self.max_size, self.batch_size = size, batch_size
        self.ptr, self.size, = 0, 0

        # for N-step Learning
        self.n_step_buffer = deque(maxlen=n_step)
        self.n_step = n_step
        self.gamma = gamma

    def store(
        self,
        obs: np.ndarray,
        act: np.ndarray,
        rew: float,
        next_obs: np.ndarray,
        done: bool
    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:
        transition = (obs, act, rew, next_obs, done)
        self.n_step_buffer.append(transition)

        # single step transition is not ready
        if len(self.n_step_buffer) < self.n_step:
            return ()

        # make a n-step transition
        rew, next_obs, done = self._get_n_step_info(
            self.n_step_buffer, self.gamma
        )
        obs, act = self.n_step_buffer[0][:2]

        self.obs_buf[self.ptr] = obs
        self.next_obs_buf[self.ptr] = next_obs
        self.acts_buf[self.ptr] = act
        self.rews_buf[self.ptr] = rew
        self.done_buf[self.ptr] = done
        self.ptr = (self.ptr + 1) % self.max_size
        self.size = min(self.size + 1, self.max_size)

        return self.n_step_buffer[0]

    def sample_batch(self) -> Dict[str, np.ndarray]:
        indices = np.random.choice(
            self.size, size=self.batch_size, replace=False
        )

        return dict(
            obs=self.obs_buf[indices],
            next_obs=self.next_obs_buf[indices],
            acts=self.acts_buf[indices],
            rews=self.rews_buf[indices],
            done=self.done_buf[indices],
            # for N-step Learning
            indices=indices,
        )

    def sample_batch_from_idxs(
        self, indices: np.ndarray
    ) -> Dict[str, np.ndarray]:
        # for N-step Learning
        return dict(
            obs=self.obs_buf[indices],
            next_obs=self.next_obs_buf[indices],
            acts=self.acts_buf[indices],
            rews=self.rews_buf[indices],
            done=self.done_buf[indices],
        )

    def _get_n_step_info(
        self, n_step_buffer: deque, gamma: float
    ) -> Tuple[np.int64, np.ndarray, bool]:
        """Return n step rew, next_obs, and done."""
        # info of the last transition
        rew, next_obs, done = n_step_buffer[-1][-3:]

        for transition in reversed(list(n_step_buffer)[:-1]):
            r, n_o, d = transition[-3:]

            rew = r + gamma * rew * (1 - d)
            next_obs, done = (n_o, d) if d else (next_obs, done)

        return rew, next_obs, done

    def __len__(self) -> int:
        return self.size

"""**B. Build the DQN + N-step learning Agent**

Note that we combined 1-step loss and n-step loss so as to control high-variance / high-bias trade-off.
"""

class DQN_NStep_Learning_Agent:
    """DQN Agent interacting with environment.

    Attribute:
        env (gym.Env): openAI Gym environment
        memory (ReplayBuffer): replay memory to store transitions
        batch_size (int): batch size for sampling
        epsilon (float): parameter for epsilon greedy policy
        epsilon_decay (float): step size to decrease epsilon
        max_epsilon (float): max value of epsilon
        min_epsilon (float): min value of epsilon
        target_update (int): period for target model's hard update
        gamma (float): discount factor
        dqn (Network): model to train and select actions
        dqn_target (Network): target model to update
        optimizer (torch.optim): optimizer for training dqn
        transition (list): transition information including
                           state, action, reward, next_state, done
        use_n_step (bool): whether to use n_step memory
        n_step (int): step number to calculate n-step td error
        memory_n (ReplayBuffer): n-step replay buffer
    """

    def __init__(
        self,
        env: gym.Env,
        memory_size: int,
        batch_size: int,
        target_update: int,
        epsilon_decay: float,
        seed: int,
        max_epsilon: float = 1.0,
        min_epsilon: float = 0.1, #0.1,
        gamma: float = 0.995, # 0.99
        # N-step Learning
        n_step: int = 3,
    ):
        """Initialization.

        Args:
            env (gym.Env): openAI Gym environment
            memory_size (int): length of memory
            batch_size (int): batch size for sampling
            target_update (int): period for target model's hard update
            epsilon_decay (float): step size to decrease epsilon
            lr (float): learning rate
            max_epsilon (float): max value of epsilon
            min_epsilon (float): min value of epsilon
            gamma (float): discount factor
            n_step (int): step number to calculate n-step td error
        """
        obs_dim = env.state_space.shape[0]
        action_dim = env.action_space.shape[0]

        self.env = env
        self.batch_size = batch_size
        self.epsilon = max_epsilon
        self.epsilon_decay = epsilon_decay
        self.seed = seed
        self.max_epsilon = max_epsilon
        self.min_epsilon = min_epsilon
        self.target_update = target_update
        self.gamma = gamma

        # memory for 1-step Learning
        self.memory = ReplayBufferNStep_Learning(
            obs_dim, memory_size, batch_size, n_step=1, gamma=gamma
        )

        # memory for N-step Learning
        self.use_n_step = True if n_step > 1 else False
        if self.use_n_step:
            self.n_step = n_step
            self.memory_n = ReplayBufferNStep_Learning(
                obs_dim, memory_size, batch_size, n_step=n_step, gamma=gamma
            )

        # device: cpu / gpu
        self.device = torch.device(
            "cuda" if torch.cuda.is_available() else "cpu"
        )
        print(self.device)

        # networks: dqn, dqn_target
        self.dqn = Network(obs_dim, action_dim).to(self.device)
        self.dqn_target = Network(obs_dim, action_dim).to(self.device)
        self.dqn_target.load_state_dict(self.dqn.state_dict())
        self.dqn_target.eval() # set the model in evaluation mode

        # optimizer
        self.optimizer = optim.Adam(self.dqn.parameters())

        # transition to store in memory
        self.transition = list()

        # mode: train / test
        self.is_test = False

    def select_action(self, state: np.ndarray) -> np.ndarray:
        """Select an action from the input state."""
        # epsilon greedy policy
        if self.epsilon > np.random.random():
            selected_action = self.env.action_space.sample()
        else:
            #selected_action = self.dqn(
                #torch.FloatTensor(state).to(self.device)
            #).argmax()
            selected_action = self.dqn(
                torch.FloatTensor(state)[0].to(self.device)
            )
            selected_action = selected_action.detach().cpu().numpy()

        if not self.is_test:
            self.transition = [state, selected_action]

        return selected_action

    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:
        """Take an action and return the response of the env."""
        state, next_state, reward, done, = self.env.step(action)

        if not self.is_test:
            self.transition += [reward, next_state, done]
            # N-step transition
            if self.use_n_step:
                one_step_transition = self.memory_n.store(*self.transition)
            # 1-step transition
            else:
                one_step_transition = self.transition

            # add a single step transition
            if one_step_transition:
                self.memory.store(*one_step_transition)

        return next_state, reward, done

    def update_model(self) -> torch.Tensor:
        """Update the model by gradient descent."""

        samples = self.memory.sample_batch()
        indices = samples["indices"]
        loss = self._compute_dqn_loss(samples, self.gamma)

        # N-step Learning loss
        # we combined 1-step loss and n-step loss so as to prevent high-variance.
        if self.use_n_step:
            samples = self.memory_n.sample_batch_from_idxs(indices)
            gamma = self.gamma ** self.n_step
            n_loss = self._compute_dqn_loss(samples, gamma)
            loss += n_loss

        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()

        return loss.item()

    def train(self, num_frames: int, plotting_interval: int = 200):
        """Train the agent."""
        self.env.TRAIN = True

        state = self.env.reset()
        update_cnt = 0
        epsilons = []
        losses = []
        scores = []
        unbalance_list = []
        operation_cost_list = []
        score = 0
        episode_unbalance = 0.0
        episode_operation_cost = 0.0

        for frame_idx in range(1, num_frames + 1):
            action = self.select_action(state)
            state, next_state, reward, done, = self.env.step(action)

            state = next_state
            score += reward
            episode_unbalance += self.env.real_unbalance
            episode_operation_cost += self.env.operation_cost

            # if episode ends
            if done:
                state = self.env.reset()
                scores.append(score)
                unbalance_list.append(episode_unbalance)
                operation_cost_list.append(episode_operation_cost)
                score = 0
                episode_unbalance = 0.0
                episode_operation_cost = 0.0

            # if training is ready
            if len(self.memory) >= self.batch_size:
                loss = self.update_model()
                losses.append(loss)
                update_cnt += 1

                # linearly decrease epsilon
                self.epsilon = max(
                    self.min_epsilon, self.epsilon - (
                        self.max_epsilon - self.min_epsilon
                    ) * self.epsilon_decay
                )
                epsilons.append(self.epsilon)

                # if hard update is needed
                if update_cnt % self.target_update == 0:
                    self._target_hard_update()

        return score, episode_unbalance, episode_operation_cost

    def test(self) -> None:
        """Test the agent."""

        record_state = []
        record_action = []
        record_reward = []
        record_output = []
        record_cost = []
        record_unbalance = []
        record_system_info = []
        record_init_info = []

        #self.is_test = True
        self.env.TRAIN = False
        #self.env = ESSEnv()
        state = self.env.reset()
        done = False
        score = 0
        episode_unbalance = 0.0
        episode_operation_cost = 0.0

        record_init_info.append([self.env.month, self.env.day, self.env.current_time,
                                 self.env.battery1.current_capacity])
        print(
            f'current testing month is {self.env.month}, day is {self.env.day}, initial_soc is {self.env.battery1.current_capacity}' )

        for i in range(24):
            action = self.select_action(state)
            real_action = action
            state, next_state, reward, done, = self.env.step(action)

            record_system_info.append([state[0], self.env.price, self.env.netload,
                                       self.env.pv, self.env.onwind, self.env.offwind,
                                       action, real_action, self.env.battery1.SOC(),
                                       self.env.battery1.energy_change,
                                       #env.battery2.SOC(), env.battery2.energy_change,
                                       #env.battery3.SOC(), env.battery3.energy_change,
                                       next_state[7], next_state[8], next_state[9],
                                       next_state[10], next_state[11],
                                       self.env.unbalance, self.env.operation_cost])
            record_state.append(state)
            record_action.append(real_action)
            record_reward.append(reward)
            record_output.append(self.env.current_output)
            record_unbalance.append(self.env.unbalance)

            state = next_state
            score += reward
            episode_unbalance += self.env.real_unbalance
            episode_operation_cost += self.env.operation_cost

        record_system_info[-1][7:12] = [self.env.final_step_outputs[0], self.env.final_step_outputs[1],
                                  self.env.final_step_outputs[2], self.env.final_step_outputs[3],
                                     self.env.final_step_outputs[4]]
        ## add information of last step soc
        record_system_info[-1][5] = self.env.final_step_outputs[5]
        record = {'init_info':record_init_info, 'information':record_system_info,
                  'state':record_state, 'action':record_action, 'reward':record_reward,
                  'cost':record_cost, 'unbalance':record_unbalance,
                  'record_output':record_output}

        print("score: ", score)
        print("Unbalance: ", episode_unbalance)
        print("Operation Cost: ", episode_operation_cost)

        return record

    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray]) -> torch.Tensor:
        """Return dqn loss."""
        device = self.device  # for shortening the following lines
        state = torch.FloatTensor(samples["obs"]).to(device)
        next_state = torch.FloatTensor(samples["next_obs"]).to(device)
        action = torch.LongTensor(samples["acts"].reshape(-1, 1)).to(device)
        reward = torch.FloatTensor(samples["rews"].reshape(-1, 1)).to(device)
        done = torch.FloatTensor(samples["done"].reshape(-1, 1)).to(device)

        # G_t   = r + gamma * v(s_{t+1})  if state != Terminal
        #       = r                       otherwise
        curr_q_value = self.dqn(state).gather(1, action)
        next_q_value = self.dqn_target(next_state).max(dim=1, keepdim=True
                                                       )[0].detach()
        mask = 1 - done
        target = (reward + self.gamma * next_q_value * mask).to(self.device)

        # calculate dqn loss
        loss = F.smooth_l1_loss(curr_q_value, target)

        return loss

    def _target_hard_update(self):
        """Hard update: target <- local."""
        self.dqn_target.load_state_dict(self.dqn.state_dict())

    def get_episode_return(self):
        """Train the agent."""
        self.env.TRAIN = True
        state = self.env.reset()
        episode_return = 0
        episode_unbalance = 0.0
        episode_operation_cost = 0.0

        for i in range(24):
            action = self.select_action(state)
            state, next_state, reward, done, = self.env.step(action)

            state = next_state
            episode_return += reward
            episode_unbalance += self.env.real_unbalance
            episode_operation_cost += self.env.operation_cost

            # if episode ends
            if done:
                break
        return episode_return, episode_unbalance, episode_operation_cost

"""**Test the DQN + N-Step Learning Model on the ESS Environment**"""

cwd = None
if_remove = False
visible_gpu = '0'
worker_num = 2
num_threads = 8
_if_per_or_gae = False
run_name = 'DQN_NStep_Learning_experiments'

def init_before_training(if_main):
    global cwd
    if cwd is None:
        agent_name = agent.__class__.__name__
        cwd = f'/content/gdrive/MyDrive/RL_Results/{agent_name}/{run_name}'
    if if_main:
        import shutil  # remove history according to bool(if_remove)
        global if_remove
        if if_remove is None:
            if_remove = bool(input(f"| PRESS 'y' to REMOVE: {cwd}? ") == 'y')
        elif if_remove:
            shutil.rmtree(cwd, ignore_errors=True)
            print(f"| Remove cwd: {cwd}")
        os.makedirs(cwd, exist_ok=True)
    np.random.seed(random_seed)
    torch.manual_seed(random_seed)
    torch.set_num_threads(num_threads)
    torch.set_default_dtype(torch.float32)
    os.environ['CUDA_VISIBLE_DEVICES'] = str(visible_gpu)

reward_record = {'episode': [], 'steps': [], 'mean_episode_reward': [], 'unbalance': [],
                  'episode_operation_cost': []}

save_network=True
test_network= True
save_test_data=True
update_training_data = True
compare_with_pyomo=True

#random_seed_list = [2234]
random_seed_list = [1234, 2234, 3234, 4234, 5234]

for seed in random_seed_list:
    random_seed = seed
    # parameters
    num_frames = 6048 #200 # 10000
    num_episode = 500
    memory_size = 5000000 # 1000
    batch_size = 8 # 32
    target_update = 512 #4096 # 100
    epsilon_decay = 1 / 2000

    save_network=True
    test_network= True
    save_test_data=True
    update_training_data = True
    compare_with_pyomo=True
    # set different seed
    agent = DQN_NStep_Learning_Agent(env, memory_size, batch_size, target_update,
                     epsilon_decay, seed)
    agent_name = f'{agent.__class__.__name__}'
    env = ESSEnv()
    init_before_training(if_main=True)

    # Train
    agent.train(num_frames)
    reward_record = {'mean_episode_reward': [], 'unbalance': [], 'episode_operation_cost': []}

    # Get One Episode
    for i_episode in range(num_episode):
        with torch.no_grad():
            episode_reward, episode_unbalance, episode_operation_cost = agent.get_episode_return()
            reward_record['mean_episode_reward'].append(episode_reward)
            reward_record['unbalance'].append(episode_unbalance)
            reward_record['episode_operation_cost'].append(episode_operation_cost)
        print(
            f'current episode is {i_episode}, reward:{episode_reward}, unbalance:{episode_unbalance}, Operation Cost:{episode_operation_cost}, Memory Size:{agent.memory.__len__}')

    if update_training_data:
        reward_record_path = f'/content/gdrive/MyDrive/RL_Results/DQN_NStep_Learning_Agent/DQN_NStep_Learning_experiments/reward_data_DQN_NStep_Learning_Agent_seed_{seed}.pkl'
        with open(reward_record_path, 'wb') as tf:
            pickle.dump(reward_record, tf)

    act_save_path = f'/content/gdrive/MyDrive/RL_Results/DQN_NStep_Learning_Agent/DQN_NStep_Learning_experiments/actor_DQN_NStep_Learning_Agent_seed_{seed}.pth'
    print('training data have been saved')
    if save_network:
        torch.save(agent.dqn.state_dict(), act_save_path)
        print('training finished and actor parameters have been saved')

    '''if test_network:
        cwd = agent_name
        agent.dqn.load_state_dict(torch.load(act_save_path))
        print('parameters have been reloaded and testing')
        record = agent.test()
        eval_data_DQN_NStep_Learning_Agent = pd.DataFrame(record['information'])
        eval_data_DQN_NStep_Learning_Agent.columns = ['time_step', 'price', 'netload', 'action', 'real_action',
                              'soc', 'battery1', 'ccgt', 'coal', 'biomass', 'nuclear', 'hydro',
                                  'unbalance', 'operation_cost']'''
    if test_network:
        cwd = agent_name
        agent.dqn.load_state_dict(torch.load(act_save_path))
        print('parameters have been reloaded and testing')
        all_records = []
        days_list = [22, 23, 24, 25, 26, 27, 28]

        for day in days_list:
            # Reset the environment
            all_records = []
            env.reset()
            env.month = 12
            env.day = day
            print(f'Testing for day {day}')
            record = agent.test()
            all_records.append(record['information'])

            eval_data_DQN_NStep_Learning = pd.concat(
                [pd.DataFrame(record) for record in all_records], ignore_index=True)
            eval_data_DQN_NStep_Learning.columns = ['time_step', 'price', 'netload', 'pv', 'onwind', 'offwind',
                                 'action', 'real_action','soc', 'battery1', 'ccgt', 'coal',
                                 'biomass', 'nuclear', 'hydro', 'unbalance', 'operation_cost']

            eval_data_DQN_NStep_Learning.to_csv(
                f'/content/gdrive/MyDrive/RL_Results/DQN_NStep_Learning_Agent/DQN_NStep_Learning_experiments/eval_data_DQN_NStep_Learning_{seed}_{day}.csv', index=False)

    if save_test_data:
        test_data_save_path = f'/content/gdrive/MyDrive/RL_Results/DQN_NStep_Learning_Agent/DQN_NStep_Learning_experiments/test_data_DQN_NStep_Learning_Agent_seed_{seed}.pkl'
        with open(test_data_save_path, 'wb') as tf:
            pickle.dump(all_records, tf)

    '''compare with pyomo data and results'''
    if compare_with_pyomo:
        month = record['init_info'][0][0]
        day = record['init_info'][0][1]
        initial_soc = record['init_info'][0][3]
        print(initial_soc)

"""##**8. Build the Rainbow DQN Module**

Implementation according to:

M. Hessel et al., "Rainbow: Combining Improvements in Deep Reinforcement Learning." arXiv preprint arXiv:1710.02298, 2017.

We will integrate all the following seven components into a single integrated agent, which is called **Rainbow!**

1. DQN
2. Double DQN
3. Prioritized Experience Replay
4. Dueling Network
5. Noisy Network
6. Categorical DQN
7. N-step Learning

**A. Create the Prioritized Experience Replay (PER) Buffer Module for Rainbow DQN**

It uses the store method to return boolean in order to inform if a N-step transition has been generated.
"""

class ReplayBufferNStep_Learning:
    """A simple numpy replay buffer."""

    def __init__(
        self,
        obs_dim: int,
        size: int,
        batch_size: int = 32,
        n_step: int = 3,
        gamma: float = 0.995,
    ):
        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)
        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)
        self.acts_buf = np.zeros([size], dtype=np.float32)
        self.rews_buf = np.zeros([size], dtype=np.float32)
        self.done_buf = np.zeros(size, dtype=np.float32)
        self.max_size, self.batch_size = size, batch_size
        self.ptr, self.size, = 0, 0

        # for N-step Learning
        self.n_step_buffer = deque(maxlen=n_step)
        self.n_step = n_step
        self.gamma = gamma

    def store(
        self,
        obs: np.ndarray,
        act: np.ndarray,
        rew: float,
        next_obs: np.ndarray,
        done: bool
    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:
        transition = (obs, act, rew, next_obs, done)
        self.n_step_buffer.append(transition)

        # single step transition is not ready
        if len(self.n_step_buffer) < self.n_step:
            return ()

        # make a n-step transition
        rew, next_obs, done = self._get_n_step_info(
            self.n_step_buffer, self.gamma
        )
        obs, act = self.n_step_buffer[0][:2]

        self.obs_buf[self.ptr] = obs
        self.next_obs_buf[self.ptr] = next_obs
        self.acts_buf[self.ptr] = act
        self.rews_buf[self.ptr] = rew
        self.done_buf[self.ptr] = done
        self.ptr = (self.ptr + 1) % self.max_size
        self.size = min(self.size + 1, self.max_size)

        return self.n_step_buffer[0]

    def sample_batch(self) -> Dict[str, np.ndarray]:
        indices = np.random.choice(
            self.size, size=self.batch_size, replace=False
        )

        return dict(
            obs=self.obs_buf[indices],
            next_obs=self.next_obs_buf[indices],
            acts=self.acts_buf[indices],
            rews=self.rews_buf[indices],
            done=self.done_buf[indices],
            # for N-step Learning
            indices=indices,
        )

    def sample_batch_from_idxs(
        self, indices: np.ndarray
    ) -> Dict[str, np.ndarray]:
        # for N-step Learning
        return dict(
            obs=self.obs_buf[indices],
            next_obs=self.next_obs_buf[indices],
            acts=self.acts_buf[indices],
            rews=self.rews_buf[indices],
            done=self.done_buf[indices],
        )

    def _get_n_step_info(
        self, n_step_buffer: deque, gamma: float
    ) -> Tuple[np.int64, np.ndarray, bool]:
        """Return n step rew, next_obs, and done."""
        # info of the last transition
        rew, next_obs, done = n_step_buffer[-1][-3:]

        for transition in reversed(list(n_step_buffer)[:-1]):
            r, n_o, d = transition[-3:]

            rew = r + gamma * rew * (1 - d)
            next_obs, done = (n_o, d) if d else (next_obs, done)

        return rew, next_obs, done

    def __len__(self) -> int:
        return self.size

class PrioritizedReplayBufferRainbow(ReplayBufferNStep_Learning):
    """Prioritized Replay buffer.

    Attributes:
        max_priority (float): max priority
        tree_ptr (int): next index of tree
        alpha (float): alpha parameter for prioritized replay buffer
        sum_tree (SumSegmentTree): sum tree for prior
        min_tree (MinSegmentTree): min tree for min prior to get max weight
    """

    def __init__(
        self,
        obs_dim: int,
        size: int,
        batch_size: int = 32,
        alpha: float = 0.6,
        n_step: int = 3,
        gamma: float = 0.99,
    ):
        """Initialization."""
        assert alpha >= 0

        super(PrioritizedReplayBufferRainbow, self).__init__(
            obs_dim, size, batch_size, n_step, gamma
        )
        self.max_priority, self.tree_ptr = 1.0, 0
        self.alpha = alpha

        # capacity must be positive and a power of 2.
        tree_capacity = 1
        while tree_capacity < self.max_size:
            tree_capacity *= 2

        self.sum_tree = SumSegmentTree(tree_capacity)
        self.min_tree = MinSegmentTree(tree_capacity)

    def store(
        self,
        obs: np.ndarray,
        act: int,
        rew: float,
        next_obs: np.ndarray,
        done: bool,
    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:
        """Store experience and priority."""
        transition = super().store(obs, act, rew, next_obs, done)

        if transition:
            self.sum_tree[self.tree_ptr] = self.max_priority ** self.alpha
            self.min_tree[self.tree_ptr] = self.max_priority ** self.alpha
            self.tree_ptr = (self.tree_ptr + 1) % self.max_size

        return transition

    def sample_batch(self, beta: float = 0.4) -> Dict[str, np.ndarray]:
        """Sample a batch of experiences."""
        assert len(self) >= self.batch_size
        assert beta > 0

        indices = self._sample_proportional()

        obs = self.obs_buf[indices]
        next_obs = self.next_obs_buf[indices]
        acts = self.acts_buf[indices]
        rews = self.rews_buf[indices]
        done = self.done_buf[indices]
        weights = np.array([self._calculate_weight(i, beta) for i in indices])

        return dict(
            obs=obs,
            next_obs=next_obs,
            acts=acts,
            rews=rews,
            done=done,
            weights=weights,
            indices=indices,
        )

    def update_priorities(self, indices: List[int], priorities: np.ndarray):
        """Update priorities of sampled transitions."""
        assert len(indices) == len(priorities)

        for idx, priority in zip(indices, priorities):
            assert priority > 0
            assert 0 <= idx < len(self)

            self.sum_tree[idx] = priority ** self.alpha
            self.min_tree[idx] = priority ** self.alpha

            self.max_priority = max(self.max_priority, priority)

    def _sample_proportional(self) -> List[int]:
        """Sample indices based on proportions."""
        indices = []
        p_total = self.sum_tree.sum(0, len(self) - 1)
        segment = p_total / self.batch_size

        for i in range(self.batch_size):
            a = segment * i
            b = segment * (i + 1)
            upperbound = random.uniform(a, b)
            idx = self.sum_tree.retrieve(upperbound)
            indices.append(idx)

        return indices

    def _calculate_weight(self, idx: int, beta: float):
        """Calculate the weight of the experience at idx."""
        # get max weight
        p_min = self.min_tree.min() / self.sum_tree.sum()
        max_weight = (p_min * len(self)) ** (-beta)

        # calculate weights
        p_sample = self.sum_tree[idx] / self.sum_tree.sum()
        weight = (p_sample * len(self)) ** (-beta)
        weight = weight / max_weight

        return weight

"""**B. Build the Network for the Rainbow DQN Model**

The Network is built by employing the NoisyLinear for the last three layers of advantage and value layers.

The noise should be reset at evey update step.

Then, the dueling network architecture is adapted for use with return distributions.

Then, we use self.dqn instead of self.dqn_target to obtain the target actions - Using Double DQN.
target_dqn is used when we are not employing the double DQN.

Essentially, the **Rainbow Network** is a composition of the **NoisyNet + DuelingNet + Categorical DQN + Double DQN**.

The network has a shared representation, which is then fed into a value stream with atom_size outputs, and into an advantage stream with atom_size × out_dim outputs.
For each atom, the value and advantage streams are aggregated, as in dueling DQN, and then passed through a softmax layer to obtain the normalized parametric distributions used to estimate the returns’ distributions.

"""

class NoisyLinear(nn.Module):
    """Noisy linear module for NoisyNet.

    Attributes:
        in_features (int): input size of linear module
        out_features (int): output size of linear module
        std_init (float): initial std value
        weight_mu (nn.Parameter): mean value weight parameter
        weight_sigma (nn.Parameter): std value weight parameter
        bias_mu (nn.Parameter): mean value bias parameter
        bias_sigma (nn.Parameter): std value bias parameter

    """

    def __init__(
        self,
        in_features: int,
        out_features: int,
        std_init: float = 0.5,
    ):
        """Initialization."""
        super(NoisyLinear, self).__init__()

        self.in_features = in_features
        self.out_features = out_features
        self.std_init = std_init

        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features))
        self.weight_sigma = nn.Parameter(
            torch.Tensor(out_features, in_features)
        )
        self.register_buffer(
            "weight_epsilon", torch.Tensor(out_features, in_features)
        )

        self.bias_mu = nn.Parameter(torch.Tensor(out_features))
        self.bias_sigma = nn.Parameter(torch.Tensor(out_features))
        self.register_buffer("bias_epsilon", torch.Tensor(out_features))

        self.reset_parameters()
        self.reset_noise()

    def reset_parameters(self):
        """Reset trainable network parameters (factorized gaussian noise)."""
        mu_range = 1 / math.sqrt(self.in_features)
        self.weight_mu.data.uniform_(-mu_range, mu_range)
        self.weight_sigma.data.fill_(
            self.std_init / math.sqrt(self.in_features)
        )
        self.bias_mu.data.uniform_(-mu_range, mu_range)
        self.bias_sigma.data.fill_(
            self.std_init / math.sqrt(self.out_features)
        )

    def reset_noise(self):
        """Make new noise."""
        epsilon_in = self.scale_noise(self.in_features)
        epsilon_out = self.scale_noise(self.out_features)

        # outer product
        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))
        self.bias_epsilon.copy_(epsilon_out)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """Forward method implementation.

        We don't use separate statements on train / eval mode.
        It doesn't show remarkable difference of performance.
        """
        return F.linear(
            x,
            self.weight_mu + self.weight_sigma * self.weight_epsilon,
            self.bias_mu + self.bias_sigma * self.bias_epsilon,
        )

    @staticmethod
    def scale_noise(size: int) -> torch.Tensor:
        """Set scale to make noise (factorized gaussian noise)."""
        x = torch.randn(size)

        return x.sign().mul(x.abs().sqrt())

class NetworkRainbow(nn.Module):
    def __init__(
        self,
        in_dim: int,
        out_dim: int,
        atom_size: int,
        support: torch.Tensor
    ):
        """Initialization."""
        super(NetworkRainbow, self).__init__()

        self.support = support
        self.out_dim = out_dim
        self.atom_size = atom_size

        # set common feature layer
        self.feature_layer = nn.Sequential(
            nn.Linear(in_dim, 256),
            nn.ReLU(),
        )

        # set advantage layer
        self.advantage_hidden_layer1 = NoisyLinear(256, 256)
        self.advantage_hidden_layer2 = NoisyLinear(256, 256)
        self.advantage_layer = NoisyLinear(256, out_dim * atom_size)

        # set value layer
        self.value_hidden_layer1 = NoisyLinear(256, 256)
        self.value_hidden_layer2 = NoisyLinear(256, 256)
        self.value_layer = NoisyLinear(256, atom_size)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """Forward method implementation."""
        dist = self.dist(x)
        q = torch.sum(dist * self.support, dim=2)

        return q

    def dist(self, x: torch.Tensor) -> torch.Tensor:
        """Get distribution for atoms."""
        feature = self.feature_layer(x)
        adv_hid1 = F.relu(self.advantage_hidden_layer1(feature))
        adv_hid2 = F.relu(self.advantage_hidden_layer2(feature))
        val_hid1 = F.relu(self.value_hidden_layer1(feature))
        val_hid2 = F.relu(self.value_hidden_layer2(feature))

        advantage = self.advantage_layer(adv_hid2).view(
            -1, self.out_dim, self.atom_size
        )
        value = self.value_layer(val_hid2).view(-1, 1, self.atom_size)
        q_atoms = value + advantage - advantage.mean(dim=1, keepdim=True)

        dist = F.softmax(q_atoms, dim=-1)
        dist = dist.clamp(min=1e-3)  # for avoiding nans

        return dist

    def reset_noise(self):
        """Reset all noisy layers."""
        self.advantage_hidden_layer1.reset_noise()
        self.advantage_hidden_layer2.reset_noise()
        self.advantage_layer.reset_noise()
        self.value_hidden_layer1.reset_noise()
        self.value_hidden_layer2.reset_noise()
        self.value_layer.reset_noise()

"""**C. Build the Rainbow Agent for the Rainbow DQN Model**"""

class Rainbow_DQN_Agent:
    """DQN Agent interacting with environment.

    Attribute:
        env (gym.Env): openAI Gym environment
        memory (ReplayBuffer): replay memory to store transitions
        batch_size (int): batch size for sampling
        target_update (int): period for target model's hard update
        gamma (float): discount factor
        dqn (Network): model to train and select actions
        dqn_target (Network): target model to update
        optimizer (torch.optim): optimizer for training dqn
        transition (list): transition information including
                           state, action, reward, next_state, done
        v_min (float): min value of support
        v_max (float): max value of support
        atom_size (int): the unit number of support
        support (torch.Tensor): support for categorical dqn
        use_n_step (bool): whether to use n_step memory
        n_step (int): step number to calculate n-step td error
        memory_n (ReplayBuffer): n-step replay buffer
    """

    def __init__(
        self,
        env: gym.Env,
        memory_size: int,
        batch_size: int,
        target_update: int,
        seed: int,
        gamma: float = 0.995, # 0.99
        # PER parameters
        alpha: float = 0.2,
        beta: float = 0.6,
        prior_eps: float = 1e-6,
        # Categorical DQN parameters
        v_min: float = -300, #-10, #-300.0, # According to the Paper # 0.0,
        v_max: float = 300, #10, #300.0, # According to the Paper # 200.0,
        atom_size: int = 510, #51,
        # N-step Learning
        n_step: int = 3,
    ):
        """Initialization.

        Args:
            env (gym.Env): openAI Gym environment
            memory_size (int): length of memory
            batch_size (int): batch size for sampling
            target_update (int): period for target model's hard update
            lr (float): learning rate
            gamma (float): discount factor
            alpha (float): determines how much prioritization is used
            beta (float): determines how much importance sampling is used
            prior_eps (float): guarantees every transition can be sampled
            v_min (float): min value of support
            v_max (float): max value of support
            atom_size (int): the unit number of support
            n_step (int): step number to calculate n-step td error
        """
        obs_dim = env.state_space.shape[0]
        action_dim = env.action_space.shape[0]

        self.env = env
        self.batch_size = batch_size
        self.seed = seed
        self.target_update = target_update
        self.gamma = gamma
        # NoisyNet: All attributes related to epsilon are removed

        # device: cpu / gpu
        self.device = torch.device(
            "cuda" if torch.cuda.is_available() else "cpu"
        )
        print(self.device)

        # PER
        # memory for 1-step Learning
        self.beta = beta
        self.prior_eps = prior_eps
        self.memory = PrioritizedReplayBufferRainbow(
            obs_dim, memory_size, batch_size, alpha=alpha, gamma=gamma
        )

        # memory for N-step Learning
        self.use_n_step = True if n_step > 1 else False
        if self.use_n_step:
            self.n_step = n_step
            self.memory_n = ReplayBufferNStep_Learning(
                obs_dim, memory_size, batch_size, n_step=n_step, gamma=gamma
            )

        # Categorical DQN parameters
        self.v_min = v_min
        self.v_max = v_max
        self.atom_size = atom_size
        self.support = torch.linspace(
            self.v_min, self.v_max, self.atom_size
        ).to(self.device)

        # networks: dqn, dqn_target

        self.dqn = NetworkRainbow(
            obs_dim, action_dim, self.atom_size, self.support
        ).to(self.device)
        self.dqn_target = NetworkRainbow(
            obs_dim, action_dim, self.atom_size, self.support
        ).to(self.device)
        self.dqn_target.load_state_dict(self.dqn.state_dict())
        self.dqn_target.eval() # set the model in evaluation mode

        # optimizer
        self.optimizer = optim.Adam(self.dqn.parameters())

        # transition to store in memory
        self.transition = list()

        # mode: train / test
        self.is_test = False

    def select_action(self, state: np.ndarray) -> np.ndarray:
        """Select an action from the input state."""

        # NoisyNet: no epsilon greedy action selection
        selected_action = self.dqn(
            torch.FloatTensor(state).to(self.device)
        )
        print(selected_action)
        selected_action = selected_action.detach().cpu().numpy()

        if not self.is_test:
            self.transition = [state, selected_action]

        return selected_action

    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:
        """Take an action and return the response of the env."""
        state, next_state, reward, done, = self.env.step(action)

        if not self.is_test:
            self.transition += [reward, next_state, done]

            # N-step transition
            if self.use_n_step:
                one_step_transition = self.memory_n.store(*self.transition)
            # 1-step transition
            else:
                one_step_transition = self.transition

            # add a single step transition
            if one_step_transition:
                self.memory.store(*one_step_transition)

        return next_state, reward, done

    def update_model(self) -> torch.Tensor:
        """Update the model by gradient descent."""

        # PER needs beta to calculate weights
        samples = self.memory.sample_batch(self.beta)
        weights = torch.FloatTensor(
            samples["weights"].reshape(-1, 1)
        ).to(self.device)
        indices = samples["indices"]

        # 1-step Learning loss
        elementwise_loss = self._compute_dqn_loss(samples, self.gamma)

        # PER: importance sampling before average
        loss = torch.mean(elementwise_loss * weights)

        # N-step Learning loss
        # we combined 1-step loss and n-step loss so as to prevent high-variance.
        # The original rainbow employs n-step loss only. - NOVELTY!
        if self.use_n_step:
            gamma = self.gamma ** self.n_step
            samples = self.memory_n.sample_batch_from_idxs(indices)
            elementwise_loss_n_loss = self._compute_dqn_loss(samples, gamma)
            elementwise_loss += elementwise_loss_n_loss

            # PER: importance sampling before average
            loss = torch.mean(elementwise_loss * weights)

        self.optimizer.zero_grad()
        loss.backward()
        clip_grad_norm_(self.dqn.parameters(), 10.0)
        self.optimizer.step()

        # PER: update priorities
        loss_for_prior = elementwise_loss.detach().cpu().numpy()
        new_priorities = loss_for_prior + self.prior_eps
        self.memory.update_priorities(indices, new_priorities)

        # NoisyNet: reset noise
        self.dqn.reset_noise()
        self.dqn_target.reset_noise()

        return loss.item()

    def train(self, num_frames: int, plotting_interval: int = 200):
        """Train the agent."""
        self.env.TRAIN = True

        state = self.env.reset()
        print(f'state is: {state}')
        update_cnt = 0
        epsilons = []
        losses = []
        scores = []
        unbalance_list = []
        operation_cost_list = []
        score = 0
        episode_unbalance = 0.0
        episode_operation_cost = 0.0

        for frame_idx in range(1, num_frames + 1):
            action = self.select_action(state)[0]
            state, next_state, reward, done, = self.env.step(action)

            state = next_state
            score += reward
            episode_unbalance += self.env.real_unbalance
            episode_operation_cost += self.env.operation_cost

            # NoisyNet: removed decrease of epsilon

            # PER: increase beta
            fraction = min(frame_idx / num_frames, 1.0)
            self.beta = self.beta + fraction * (1.0 - self.beta)

            # if episode ends
            if done:
                state = self.env.reset()
                scores.append(score)
                unbalance_list.append(episode_unbalance)
                operation_cost_list.append(episode_operation_cost)
                score = 0
                episode_unbalance = 0.0
                episode_operation_cost = 0.0

            # if training is ready
            if len(self.memory) >= self.batch_size:
                loss = self.update_model()
                losses.append(loss)
                update_cnt += 1

                # if hard update is needed
                if update_cnt % self.target_update == 0:
                    self._target_hard_update()

        return score, episode_unbalance, episode_operation_cost

    def test(self) -> None:
        """Test the agent."""

        record_state = []
        record_action = []
        record_reward = []
        record_output = []
        record_cost = []
        record_unbalance = []
        record_system_info = []
        record_init_info = []

        #self.is_test = True
        self.env.TRAIN = False
        #self.env = ESSEnv()
        state = self.env.reset()
        done = False
        score = 0
        episode_unbalance = 0.0
        episode_operation_cost = 0.0

        record_init_info.append([self.env.month, self.env.day, self.env.current_time,
                                 self.env.battery1.current_capacity])
        print(
            f'current testing month is {self.env.month}, day is {self.env.day}, initial_soc is {self.env.battery1.current_capacity}' )

        for i in range(24):
            action = self.select_action(state)[0]
            real_action = action
            state, next_state, reward, done, = self.env.step(action)

            record_system_info.append([state[0], self.env.price, self.env.netload,
                                       self.env.pv, self.env.onwind, self.env.offwind,
                                       action, real_action, self.env.battery1.SOC(),
                                       self.env.battery1.energy_change,
                                       #env.battery2.SOC(), env.battery2.energy_change,
                                       #env.battery3.SOC(), env.battery3.energy_change,
                                       next_state[7], next_state[8], next_state[9],
                                       next_state[10], next_state[11],
                                       self.env.unbalance, self.env.operation_cost])
            record_state.append(state)
            record_action.append(real_action)
            record_reward.append(reward)
            record_output.append(self.env.current_output)
            record_unbalance.append(self.env.unbalance)

            state = next_state
            score += reward
            episode_unbalance += self.env.real_unbalance
            episode_operation_cost += self.env.operation_cost

        record_system_info[-1][7:12] = [self.env.final_step_outputs[0], self.env.final_step_outputs[1],
                                  self.env.final_step_outputs[2], self.env.final_step_outputs[3],
                                     self.env.final_step_outputs[4]]
        ## add information of last step soc
        record_system_info[-1][5] = self.env.final_step_outputs[5]
        record = {'init_info':record_init_info, 'information':record_system_info,
                  'state':record_state, 'action':record_action, 'reward':record_reward,
                  'cost':record_cost, 'unbalance':record_unbalance,
                  'record_output':record_output}

        print("score: ", score)
        print("Unbalance: ", episode_unbalance)
        print("Operation Cost: ", episode_operation_cost)

        return record

    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray]) -> torch.Tensor:
        """Return Categorical dqn loss."""
        device = self.device  # for shortening the following lines
        state = torch.FloatTensor(samples["obs"]).to(device)
        next_state = torch.FloatTensor(samples["next_obs"]).to(device)
        action = torch.LongTensor(samples["acts"].reshape(-1, 1)).to(device)
        reward = torch.FloatTensor(samples["rews"].reshape(-1, 1)).to(device)
        done = torch.FloatTensor(samples["done"].reshape(-1, 1)).to(device)

        # Categorical DQN algorithm
        delta_z = float(self.v_max - self.v_min) / (self.atom_size - 1)

        with torch.no_grad():
            # Double DQN or DQN
            next_action = self.dqn(next_state) # Double DQN
            #next_action = self.dqn_target(next_state) # DQN
            next_dist = self.dqn_target.dist(next_state)
            next_dist = next_dist[range(self.batch_size), next_action]

            t_z = reward + (1 - done) * self.gamma * self.support
            t_z = t_z.clamp(min=self.v_min, max=self.v_max)
            b = (t_z - self.v_min) / delta_z
            l = b.floor().long()
            u = b.ceil().long()

            offset = (
                torch.linspace(
                    0, (self.batch_size - 1) * self.atom_size, self.batch_size
                ).long()
                .unsqueeze(1)
                .expand(self.batch_size, self.atom_size)
                .to(self.device)
            )

            proj_dist = torch.zeros(next_dist.size(), device=self.device)
            proj_dist.view(-1).index_add_(
                0, (l + offset).view(-1), (next_dist * (u.float() - b)).view(-1)
            )
            proj_dist.view(-1).index_add_(
                0, (u + offset).view(-1), (next_dist * (b - l.float())).view(-1)
            )

        dist = self.dqn.dist(state)
        log_p = torch.log(dist[range(self.batch_size), action])
        elementwise_loss = -(proj_dist * log_p).sum(1)

        return elementwise_loss

    def _target_hard_update(self):
        """Hard update: target <- local."""
        self.dqn_target.load_state_dict(self.dqn.state_dict())


    def get_episode_return(self):
        """Train the agent."""
        self.env.TRAIN = True
        state = self.env.reset()
        episode_return = 0
        episode_unbalance = 0.0
        episode_operation_cost = 0.0

        for i in range(24):
            action = self.select_action(state)[0]
            state, next_state, reward, done, = self.env.step(action)

            state = next_state
            episode_return += reward
            episode_unbalance += self.env.real_unbalance
            episode_operation_cost += self.env.operation_cost

            # if episode ends
            if done:
                break
        return episode_return, episode_unbalance, episode_operation_cost

"""**Test the Rainbow DQN Module on the ESS Environment**"""

cwd = None
if_remove = False
visible_gpu = '0'
worker_num = 2
num_threads = 8
_if_per_or_gae = False
run_name = 'Rainbow_DQN_experiments'

def init_before_training(if_main):
    global cwd
    if cwd is None:
        agent_name = agent.__class__.__name__
        cwd = f'/content/gdrive/MyDrive/RL_Results/{agent_name}/{run_name}'
    if if_main:
        import shutil  # remove history according to bool(if_remove)
        global if_remove
        if if_remove is None:
            if_remove = bool(input(f"| PRESS 'y' to REMOVE: {cwd}? ") == 'y')
        elif if_remove:
            shutil.rmtree(cwd, ignore_errors=True)
            print(f"| Remove cwd: {cwd}")
        os.makedirs(cwd, exist_ok=True)
    np.random.seed(random_seed)
    torch.manual_seed(random_seed)
    torch.set_num_threads(num_threads)
    torch.set_default_dtype(torch.float32)
    os.environ['CUDA_VISIBLE_DEVICES'] = str(visible_gpu)

reward_record = {'episode': [], 'steps': [], 'mean_episode_reward': [], 'unbalance': [],
                  'episode_operation_cost': []}

save_network=True
test_network= True
save_test_data=True
update_training_data = True
compare_with_pyomo=True

#random_seed_list = [2234]
random_seed_list = [1234, 2234, 3234, 4234, 5234]

for seed in random_seed_list:
    random_seed = seed
    # parameters
    num_frames = 6048 #200 # 10000
    num_episode = 500
    memory_size = 5000000 # 1000
    batch_size = 8 # 32
    target_update = 512 #4096 # 100

    save_network=True
    test_network= True
    save_test_data=True
    update_training_data = True
    compare_with_pyomo=True
    # set different seed
    agent = Rainbow_DQN_Agent(env, memory_size, batch_size, target_update, seed)
    agent_name = f'{agent.__class__.__name__}'
    env = ESSEnv()
    init_before_training(if_main=True)

    # Train
    agent.train(num_frames)

    reward_record = {'mean_episode_reward': [], 'unbalance': [], 'episode_operation_cost': []}

    # Get One Episode
    for i_episode in range(num_episode):
        with torch.no_grad():
            episode_reward, episode_unbalance, episode_operation_cost = agent.get_episode_return()
            reward_record['mean_episode_reward'].append(episode_reward)
            reward_record['unbalance'].append(episode_unbalance)
            reward_record['episode_operation_cost'].append(episode_operation_cost)
        print(
            f'current episode is {i_episode}, reward:{episode_reward}, unbalance:{episode_unbalance}, Operation Cost:{episode_operation_cost}, Memory Size:{agent.memory.__len__}')

    if update_training_data:
        reward_record_path = f'/content/gdrive/MyDrive/RL_Results/Rainbow_DQN_Agent/Rainbow_DQN_experiments/reward_data_Rainbow_DQN_seed_{seed}.pkl'
        with open(reward_record_path, 'wb') as tf:
            pickle.dump(reward_record, tf)

    act_save_path = f'/content/gdrive/MyDrive/RL_Results/Rainbow_DQN_Agent/Rainbow_DQN_experiments/actor_Rainbow_DQN_seed_{seed}.pth'
    print('training data have been saved')
    if save_network:
        torch.save(agent.dqn.state_dict(), act_save_path)
        print('training finished and actor parameters have been saved')

    '''if test_network:
        cwd = agent_name
        agent.dqn.load_state_dict(torch.load(act_save_path))
        print('parameters have been reloaded and testing')
        record = agent.test()
        eval_data_Rainbow_DQN = pd.DataFrame(record['information'])
        eval_data_Rainbow_DQN.columns = ['time_step', 'price', 'netload', 'action', 'real_action',
                              'soc', 'battery1', 'ccgt', 'coal', 'biomass', 'nuclear', 'hydro',
                                  'unbalance', 'operation_cost']'''
    if test_network:
        cwd = agent_name
        agent.dqn.load_state_dict(torch.load(act_save_path))
        print('parameters have been reloaded and testing')
        all_records = []
        days_list = [22, 23, 24, 25, 26, 27, 28]

        for day in days_list:
            # Reset the environment
            all_records = []
            env.reset()
            env.month = 12
            env.day = day
            print(f'Testing for day {day}')
            record = agent.test()
            all_records.append(record['information'])

            eval_data_Rainbow_DQN = pd.concat(
                [pd.DataFrame(record) for record in all_records], ignore_index=True)
            eval_data_Rainbow_DQN.columns = ['time_step', 'price', 'netload', 'pv', 'onwind', 'offwind',
                                 'action', 'real_action','soc', 'battery1', 'ccgt', 'coal',
                                 'biomass', 'nuclear', 'hydro', 'unbalance', 'operation_cost']

            eval_data_Rainbow_DQN.to_csv(
                f'/content/gdrive/MyDrive/RL_Results/Rainbow_DQN_Agent/Rainbow_DQN_experiments/eval_data_Rainbow_DQN_{seed}_{day}.csv', index=False)

    if save_test_data:
        test_data_save_path = f'/content/gdrive/MyDrive/RL_Results/Rainbow_DQN_Agent/Rainbow_DQN_experiments/test_data_Rainbow_DQN_seed_{seed}.pkl'
        with open(test_data_save_path, 'wb') as tf:
            pickle.dump(all_records, tf)

    '''compare with pyomo data and results'''
    if compare_with_pyomo:
        month = record['init_info'][0][0]
        day = record['init_info'][0][1]
        initial_soc = record['init_info'][0][3]
        print(initial_soc)

"""#**EXPERIMENTAL RESULT ANALYSIS - PERFORMANCE ON THE TESTING SET**

**Access All 5 Random Seeds Testing Operation Cost, and Grid Unbalance Data for All Models**

Evaluated Every 24 Hours for 7 days.

###**1. DQN Algorithm - Base Network**
"""

seed = [1234, 2234, 3234, 4234, 5234]
day = 22
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQNAgent/DQN_2_experiments/eval_data_DQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_2_day22 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_2_day22[col_name] = concatenated_df[col_name].mean(axis=1)

day = 23
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQNAgent/DQN_2_experiments/eval_data_DQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_2_day23 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_2_day23[col_name] = concatenated_df[col_name].mean(axis=1)

day = 24
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQNAgent/DQN_2_experiments/eval_data_DQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_2_day24 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_2_day24[col_name] = concatenated_df[col_name].mean(axis=1)

day = 25
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQNAgent/DQN_2_experiments/eval_data_DQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_2_day25 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_2_day25[col_name] = concatenated_df[col_name].mean(axis=1)

day = 26
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQNAgent/DQN_2_experiments/eval_data_DQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_2_day26 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_2_day26[col_name] = concatenated_df[col_name].mean(axis=1)

day = 27
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQNAgent/DQN_2_experiments/eval_data_DQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_2_day27 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_2_day27[col_name] = concatenated_df[col_name].mean(axis=1)

day = 28
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQNAgent/DQN_2_experiments/eval_data_DQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_2_day28 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_2_day28[col_name] = concatenated_df[col_name].mean(axis=1)

# Put All 7 Days Data Together

eval_data_DQN_2_Op_Cost = []
eval_data_DQN_2_Op_Cost.append(sum(eval_data_DQN_2_day22['operation_cost']))
eval_data_DQN_2_Op_Cost.append(sum(eval_data_DQN_2_day23['operation_cost']))
eval_data_DQN_2_Op_Cost.append(sum(eval_data_DQN_2_day24['operation_cost']))
eval_data_DQN_2_Op_Cost.append(sum(eval_data_DQN_2_day25['operation_cost']))
eval_data_DQN_2_Op_Cost.append(sum(eval_data_DQN_2_day26['operation_cost']))
eval_data_DQN_2_Op_Cost.append(sum(eval_data_DQN_2_day27['operation_cost']))
eval_data_DQN_2_Op_Cost.append(sum(eval_data_DQN_2_day28['operation_cost']))

eval_data_DQN_2_Unbalance = []
eval_data_DQN_2_Unbalance.append(sum(eval_data_DQN_2_day22['unbalance']))
eval_data_DQN_2_Unbalance.append(sum(eval_data_DQN_2_day23['unbalance']))
eval_data_DQN_2_Unbalance.append(sum(eval_data_DQN_2_day24['unbalance']))
eval_data_DQN_2_Unbalance.append(sum(eval_data_DQN_2_day25['unbalance']))
eval_data_DQN_2_Unbalance.append(sum(eval_data_DQN_2_day26['unbalance']))
eval_data_DQN_2_Unbalance.append(sum(eval_data_DQN_2_day27['unbalance']))
eval_data_DQN_2_Unbalance.append(sum(eval_data_DQN_2_day28['unbalance']))

"""##**2. Double DQN Algorithm**"""

day = 22
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DDQNAgent/DDQN_experiments/eval_data_DDQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DDQN_day22 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DDQN_day22[col_name] = concatenated_df[col_name].mean(axis=1)

day = 23
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DDQNAgent/DDQN_experiments/eval_data_DDQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DDQN_day23 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DDQN_day23[col_name] = concatenated_df[col_name].mean(axis=1)

day = 24
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DDQNAgent/DDQN_experiments/eval_data_DDQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DDQN_day24 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DDQN_day24[col_name] = concatenated_df[col_name].mean(axis=1)

day = 25
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DDQNAgent/DDQN_experiments/eval_data_DDQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DDQN_day25 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DDQN_day25[col_name] = concatenated_df[col_name].mean(axis=1)

day = 26
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DDQNAgent/DDQN_experiments/eval_data_DDQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DDQN_day26 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DDQN_day26[col_name] = concatenated_df[col_name].mean(axis=1)

day = 27
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DDQNAgent/DDQN_experiments/eval_data_DDQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DDQN_day27 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DDQN_day27[col_name] = concatenated_df[col_name].mean(axis=1)

day = 28
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DDQNAgent/DDQN_experiments/eval_data_DDQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DDQN_day28 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DDQN_day28[col_name] = concatenated_df[col_name].mean(axis=1)

# Put All 7 Days Data Together

eval_data_DDQN_Op_Cost = []
eval_data_DDQN_Op_Cost.append(sum(eval_data_DDQN_day22['operation_cost']))
eval_data_DDQN_Op_Cost.append(sum(eval_data_DDQN_day23['operation_cost']))
eval_data_DDQN_Op_Cost.append(sum(eval_data_DDQN_day24['operation_cost']))
eval_data_DDQN_Op_Cost.append(sum(eval_data_DDQN_day25['operation_cost']))
eval_data_DDQN_Op_Cost.append(sum(eval_data_DDQN_day26['operation_cost']))
eval_data_DDQN_Op_Cost.append(sum(eval_data_DDQN_day27['operation_cost']))
eval_data_DDQN_Op_Cost.append(sum(eval_data_DDQN_day28['operation_cost']))

eval_data_DDQN_Unbalance = []
eval_data_DDQN_Unbalance.append(sum(eval_data_DDQN_day22['unbalance']))
eval_data_DDQN_Unbalance.append(sum(eval_data_DDQN_day23['unbalance']))
eval_data_DDQN_Unbalance.append(sum(eval_data_DDQN_day24['unbalance']))
eval_data_DDQN_Unbalance.append(sum(eval_data_DDQN_day25['unbalance']))
eval_data_DDQN_Unbalance.append(sum(eval_data_DDQN_day26['unbalance']))
eval_data_DDQN_Unbalance.append(sum(eval_data_DDQN_day27['unbalance']))
eval_data_DDQN_Unbalance.append(sum(eval_data_DDQN_day28['unbalance']))

"""##**3. DQN Algorithm With Prioritized Experience Replay (PER)**

"""

day = 22
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_PER_Agent/DQN_PER_experiments/eval_data_DQN_PER_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_PER_day22 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_PER_day22[col_name] = concatenated_df[col_name].mean(axis=1)

day = 23
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_PER_Agent/DQN_PER_experiments/eval_data_DQN_PER_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_PER_day23 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_PER_day23[col_name] = concatenated_df[col_name].mean(axis=1)

day = 24
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_PER_Agent/DQN_PER_experiments/eval_data_DQN_PER_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_PER_day24 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_PER_day24[col_name] = concatenated_df[col_name].mean(axis=1)

day = 25
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_PER_Agent/DQN_PER_experiments/eval_data_DQN_PER_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_PER_day25 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_PER_day25[col_name] = concatenated_df[col_name].mean(axis=1)

day = 26
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_PER_Agent/DQN_PER_experiments/eval_data_DQN_PER_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_PER_day26 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_PER_day26[col_name] = concatenated_df[col_name].mean(axis=1)

day = 27
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_PER_Agent/DQN_PER_experiments/eval_data_DQN_PER_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_PER_day27 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_PER_day27[col_name] = concatenated_df[col_name].mean(axis=1)

day = 28
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_PER_Agent/DQN_PER_experiments/eval_data_DQN_PER_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_PER_day28 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_PER_day28[col_name] = concatenated_df[col_name].mean(axis=1)

# Put All 7 Days Data Together

eval_data_DQN_PER_Op_Cost = []
eval_data_DQN_PER_Op_Cost.append(sum(eval_data_DQN_PER_day22['operation_cost']))
eval_data_DQN_PER_Op_Cost.append(sum(eval_data_DQN_PER_day23['operation_cost']))
eval_data_DQN_PER_Op_Cost.append(sum(eval_data_DQN_PER_day24['operation_cost']))
eval_data_DQN_PER_Op_Cost.append(sum(eval_data_DQN_PER_day25['operation_cost']))
eval_data_DQN_PER_Op_Cost.append(sum(eval_data_DQN_PER_day26['operation_cost']))
eval_data_DQN_PER_Op_Cost.append(sum(eval_data_DQN_PER_day27['operation_cost']))
eval_data_DQN_PER_Op_Cost.append(sum(eval_data_DQN_PER_day28['operation_cost']))

eval_data_DQN_PER_Unbalance = []
eval_data_DQN_PER_Unbalance.append(sum(eval_data_DQN_PER_day22['unbalance']))
eval_data_DQN_PER_Unbalance.append(sum(eval_data_DQN_PER_day23['unbalance']))
eval_data_DQN_PER_Unbalance.append(sum(eval_data_DQN_PER_day24['unbalance']))
eval_data_DQN_PER_Unbalance.append(sum(eval_data_DQN_PER_day25['unbalance']))
eval_data_DQN_PER_Unbalance.append(sum(eval_data_DQN_PER_day26['unbalance']))
eval_data_DQN_PER_Unbalance.append(sum(eval_data_DQN_PER_day27['unbalance']))
eval_data_DQN_PER_Unbalance.append(sum(eval_data_DQN_PER_day28['unbalance']))

"""##**4. DQN + Dueling Network Algorithm**

"""

day = 22
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_DuelingNet_Agent/DQN_DuelingNet_experiments/eval_data_DQN_DuelingNet_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_DuelingNet_day22 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_DuelingNet_day22[col_name] = concatenated_df[col_name].mean(axis=1)

day = 23
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_DuelingNet_Agent/DQN_DuelingNet_experiments/eval_data_DQN_DuelingNet_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_DuelingNet_day23 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_DuelingNet_day23[col_name] = concatenated_df[col_name].mean(axis=1)

day = 24
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_DuelingNet_Agent/DQN_DuelingNet_experiments/eval_data_DQN_DuelingNet_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_DuelingNet_day24 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_DuelingNet_day24[col_name] = concatenated_df[col_name].mean(axis=1)

day = 25
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_DuelingNet_Agent/DQN_DuelingNet_experiments/eval_data_DQN_DuelingNet_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_DuelingNet_day25 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_DuelingNet_day25[col_name] = concatenated_df[col_name].mean(axis=1)

day = 26
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_DuelingNet_Agent/DQN_DuelingNet_experiments/eval_data_DQN_DuelingNet_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_DuelingNet_day26 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_DuelingNet_day26[col_name] = concatenated_df[col_name].mean(axis=1)

day = 27
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_DuelingNet_Agent/DQN_DuelingNet_experiments/eval_data_DQN_DuelingNet_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_DuelingNet_day27 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_DuelingNet_day27[col_name] = concatenated_df[col_name].mean(axis=1)

day = 28
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_DuelingNet_Agent/DQN_DuelingNet_experiments/eval_data_DQN_DuelingNet_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_DuelingNet_day28 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_DuelingNet_day28[col_name] = concatenated_df[col_name].mean(axis=1)

# Put All 7 Days Data Together

eval_data_DQN_DuelingNet_Op_Cost = []
eval_data_DQN_DuelingNet_Op_Cost.append(sum(eval_data_DQN_DuelingNet_day22['operation_cost']))
eval_data_DQN_DuelingNet_Op_Cost.append(sum(eval_data_DQN_DuelingNet_day23['operation_cost']))
eval_data_DQN_DuelingNet_Op_Cost.append(sum(eval_data_DQN_DuelingNet_day24['operation_cost']))
eval_data_DQN_DuelingNet_Op_Cost.append(sum(eval_data_DQN_DuelingNet_day25['operation_cost']))
eval_data_DQN_DuelingNet_Op_Cost.append(sum(eval_data_DQN_DuelingNet_day26['operation_cost']))
eval_data_DQN_DuelingNet_Op_Cost.append(sum(eval_data_DQN_DuelingNet_day27['operation_cost']))
eval_data_DQN_DuelingNet_Op_Cost.append(sum(eval_data_DQN_DuelingNet_day28['operation_cost']))

eval_data_DQN_DuelingNet_Unbalance = []
eval_data_DQN_DuelingNet_Unbalance.append(sum(eval_data_DQN_DuelingNet_day22['unbalance']))
eval_data_DQN_DuelingNet_Unbalance.append(sum(eval_data_DQN_DuelingNet_day23['unbalance']))
eval_data_DQN_DuelingNet_Unbalance.append(sum(eval_data_DQN_DuelingNet_day24['unbalance']))
eval_data_DQN_DuelingNet_Unbalance.append(sum(eval_data_DQN_DuelingNet_day25['unbalance']))
eval_data_DQN_DuelingNet_Unbalance.append(sum(eval_data_DQN_DuelingNet_day26['unbalance']))
eval_data_DQN_DuelingNet_Unbalance.append(sum(eval_data_DQN_DuelingNet_day27['unbalance']))
eval_data_DQN_DuelingNet_Unbalance.append(sum(eval_data_DQN_DuelingNet_day28['unbalance']))

"""##**5. DQN + Noisy Network Algorithm**"""

day = 22
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_NoisyNet_Agent/DQN_NoisyNet_experiments/eval_data_DQN_NoisyNet_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_NoisyNet_day22 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_NoisyNet_day22[col_name] = concatenated_df[col_name].mean(axis=1)

day = 23
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_NoisyNet_Agent/DQN_NoisyNet_experiments/eval_data_DQN_NoisyNet_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_NoisyNet_day23 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_NoisyNet_day23[col_name] = concatenated_df[col_name].mean(axis=1)

day = 24
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_NoisyNet_Agent/DQN_NoisyNet_experiments/eval_data_DQN_NoisyNet_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_NoisyNet_day24 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_NoisyNet_day24[col_name] = concatenated_df[col_name].mean(axis=1)

day = 25
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_NoisyNet_Agent/DQN_NoisyNet_experiments/eval_data_DQN_NoisyNet_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_NoisyNet_day25 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_NoisyNet_day25[col_name] = concatenated_df[col_name].mean(axis=1)

day = 26
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_NoisyNet_Agent/DQN_NoisyNet_experiments/eval_data_DQN_NoisyNet_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_NoisyNet_day26 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_NoisyNet_day26[col_name] = concatenated_df[col_name].mean(axis=1)

day = 27
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_NoisyNet_Agent/DQN_NoisyNet_experiments/eval_data_DQN_NoisyNet_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_NoisyNet_day27 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_NoisyNet_day27[col_name] = concatenated_df[col_name].mean(axis=1)

day = 28
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_NoisyNet_Agent/DQN_NoisyNet_experiments/eval_data_DQN_NoisyNet_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_NoisyNet_day28 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_NoisyNet_day28[col_name] = concatenated_df[col_name].mean(axis=1)

# Put All 7 Days Data Together

eval_data_DQN_NoisyNet_Op_Cost = []
eval_data_DQN_NoisyNet_Op_Cost.append(sum(eval_data_DQN_NoisyNet_day22['operation_cost']))
eval_data_DQN_NoisyNet_Op_Cost.append(sum(eval_data_DQN_NoisyNet_day23['operation_cost']))
eval_data_DQN_NoisyNet_Op_Cost.append(sum(eval_data_DQN_NoisyNet_day24['operation_cost']))
eval_data_DQN_NoisyNet_Op_Cost.append(sum(eval_data_DQN_NoisyNet_day25['operation_cost']))
eval_data_DQN_NoisyNet_Op_Cost.append(sum(eval_data_DQN_NoisyNet_day26['operation_cost']))
eval_data_DQN_NoisyNet_Op_Cost.append(sum(eval_data_DQN_NoisyNet_day27['operation_cost']))
eval_data_DQN_NoisyNet_Op_Cost.append(sum(eval_data_DQN_NoisyNet_day28['operation_cost']))

eval_data_DQN_NoisyNet_Unbalance = []
eval_data_DQN_NoisyNet_Unbalance.append(sum(eval_data_DQN_NoisyNet_day22['unbalance']))
eval_data_DQN_NoisyNet_Unbalance.append(sum(eval_data_DQN_NoisyNet_day23['unbalance']))
eval_data_DQN_NoisyNet_Unbalance.append(sum(eval_data_DQN_NoisyNet_day24['unbalance']))
eval_data_DQN_NoisyNet_Unbalance.append(sum(eval_data_DQN_NoisyNet_day25['unbalance']))
eval_data_DQN_NoisyNet_Unbalance.append(sum(eval_data_DQN_NoisyNet_day26['unbalance']))
eval_data_DQN_NoisyNet_Unbalance.append(sum(eval_data_DQN_NoisyNet_day27['unbalance']))
eval_data_DQN_NoisyNet_Unbalance.append(sum(eval_data_DQN_NoisyNet_day28['unbalance']))

"""##**6. Categorical DQN - A Distributional DRL Algorithm**

"""

day = 22
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/Categorical_DQN_Agent/Categorical_DQN_experiments/eval_data_Categorical_DQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_Categorical_DQN_day22 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_Categorical_DQN_day22[col_name] = concatenated_df[col_name].mean(axis=1)

day = 23
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/Categorical_DQN_Agent/Categorical_DQN_experiments/eval_data_Categorical_DQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_Categorical_DQN_day23 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_Categorical_DQN_day23[col_name] = concatenated_df[col_name].mean(axis=1)

day = 24
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/Categorical_DQN_Agent/Categorical_DQN_experiments/eval_data_Categorical_DQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_Categorical_DQN_day24 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_Categorical_DQN_day24[col_name] = concatenated_df[col_name].mean(axis=1)

day = 25
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/Categorical_DQN_Agent/Categorical_DQN_experiments/eval_data_Categorical_DQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_Categorical_DQN_day25 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_Categorical_DQN_day25[col_name] = concatenated_df[col_name].mean(axis=1)

day = 26
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/Categorical_DQN_Agent/Categorical_DQN_experiments/eval_data_Categorical_DQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_Categorical_DQN_day26 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_Categorical_DQN_day26[col_name] = concatenated_df[col_name].mean(axis=1)

day = 27
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/Categorical_DQN_Agent/Categorical_DQN_experiments/eval_data_Categorical_DQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_Categorical_DQN_day27 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_Categorical_DQN_day27[col_name] = concatenated_df[col_name].mean(axis=1)

day = 28
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/Categorical_DQN_Agent/Categorical_DQN_experiments/eval_data_Categorical_DQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_Categorical_DQN_day28 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_Categorical_DQN_day28[col_name] = concatenated_df[col_name].mean(axis=1)

# Put All 7 Days Data Together

eval_data_Categorical_DQN_Op_Cost = []
eval_data_Categorical_DQN_Op_Cost.append(sum(eval_data_Categorical_DQN_day22['operation_cost']))
eval_data_Categorical_DQN_Op_Cost.append(sum(eval_data_Categorical_DQN_day23['operation_cost']))
eval_data_Categorical_DQN_Op_Cost.append(sum(eval_data_Categorical_DQN_day24['operation_cost']))
eval_data_Categorical_DQN_Op_Cost.append(sum(eval_data_Categorical_DQN_day25['operation_cost']))
eval_data_Categorical_DQN_Op_Cost.append(sum(eval_data_Categorical_DQN_day26['operation_cost']))
eval_data_Categorical_DQN_Op_Cost.append(sum(eval_data_Categorical_DQN_day27['operation_cost']))
eval_data_Categorical_DQN_Op_Cost.append(sum(eval_data_Categorical_DQN_day28['operation_cost']))

eval_data_Categorical_DQN_Unbalance = []
eval_data_Categorical_DQN_Unbalance.append(sum(eval_data_Categorical_DQN_day22['unbalance']))
eval_data_Categorical_DQN_Unbalance.append(sum(eval_data_Categorical_DQN_day23['unbalance']))
eval_data_Categorical_DQN_Unbalance.append(sum(eval_data_Categorical_DQN_day24['unbalance']))
eval_data_Categorical_DQN_Unbalance.append(sum(eval_data_Categorical_DQN_day25['unbalance']))
eval_data_Categorical_DQN_Unbalance.append(sum(eval_data_Categorical_DQN_day26['unbalance']))
eval_data_Categorical_DQN_Unbalance.append(sum(eval_data_Categorical_DQN_day27['unbalance']))
eval_data_Categorical_DQN_Unbalance.append(sum(eval_data_Categorical_DQN_day28['unbalance']))

"""##**7. DQN + N-Step Learning Agent**

"""

day = 22
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_NStep_Learning_Agent/DQN_NStep_Learning_experiments/eval_data_DQN_NStep_Learning_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_NStep_Learning_day22 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_NStep_Learning_day22[col_name] = concatenated_df[col_name].mean(axis=1)

day = 23
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_NStep_Learning_Agent/DQN_NStep_Learning_experiments/eval_data_DQN_NStep_Learning_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_NStep_Learning_day23 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_NStep_Learning_day23[col_name] = concatenated_df[col_name].mean(axis=1)

day = 24
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_NStep_Learning_Agent/DQN_NStep_Learning_experiments/eval_data_DQN_NStep_Learning_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_NStep_Learning_day24 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_NStep_Learning_day24[col_name] = concatenated_df[col_name].mean(axis=1)

day = 25
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_NStep_Learning_Agent/DQN_NStep_Learning_experiments/eval_data_DQN_NStep_Learning_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_NStep_Learning_day25 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_NStep_Learning_day25[col_name] = concatenated_df[col_name].mean(axis=1)

day = 26
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_NStep_Learning_Agent/DQN_NStep_Learning_experiments/eval_data_DQN_NStep_Learning_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_NStep_Learning_day26 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_NStep_Learning_day26[col_name] = concatenated_df[col_name].mean(axis=1)

day = 27
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_NStep_Learning_Agent/DQN_NStep_Learning_experiments/eval_data_DQN_NStep_Learning_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_NStep_Learning_day27 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_NStep_Learning_day27[col_name] = concatenated_df[col_name].mean(axis=1)

day = 28
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/DQN_NStep_Learning_Agent/DQN_NStep_Learning_experiments/eval_data_DQN_NStep_Learning_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_DQN_NStep_Learning_day28 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_DQN_NStep_Learning_day28[col_name] = concatenated_df[col_name].mean(axis=1)

# Put All 7 Days Data Together

eval_data_DQN_NStep_Learning_Op_Cost = []
eval_data_DQN_NStep_Learning_Op_Cost.append(sum(eval_data_DQN_NStep_Learning_day22['operation_cost']))
eval_data_DQN_NStep_Learning_Op_Cost.append(sum(eval_data_DQN_NStep_Learning_day23['operation_cost']))
eval_data_DQN_NStep_Learning_Op_Cost.append(sum(eval_data_DQN_NStep_Learning_day24['operation_cost']))
eval_data_DQN_NStep_Learning_Op_Cost.append(sum(eval_data_DQN_NStep_Learning_day25['operation_cost']))
eval_data_DQN_NStep_Learning_Op_Cost.append(sum(eval_data_DQN_NStep_Learning_day26['operation_cost']))
eval_data_DQN_NStep_Learning_Op_Cost.append(sum(eval_data_DQN_NStep_Learning_day27['operation_cost']))
eval_data_DQN_NStep_Learning_Op_Cost.append(sum(eval_data_DQN_NStep_Learning_day28['operation_cost']))

eval_data_DQN_NStep_Learning_Unbalance = []
eval_data_DQN_NStep_Learning_Unbalance.append(sum(eval_data_DQN_NStep_Learning_day22['unbalance']))
eval_data_DQN_NStep_Learning_Unbalance.append(sum(eval_data_DQN_NStep_Learning_day23['unbalance']))
eval_data_DQN_NStep_Learning_Unbalance.append(sum(eval_data_DQN_NStep_Learning_day24['unbalance']))
eval_data_DQN_NStep_Learning_Unbalance.append(sum(eval_data_DQN_NStep_Learning_day25['unbalance']))
eval_data_DQN_NStep_Learning_Unbalance.append(sum(eval_data_DQN_NStep_Learning_day26['unbalance']))
eval_data_DQN_NStep_Learning_Unbalance.append(sum(eval_data_DQN_NStep_Learning_day27['unbalance']))
eval_data_DQN_NStep_Learning_Unbalance.append(sum(eval_data_DQN_NStep_Learning_day28['unbalance']))

"""##**8. Rainbow DQN**

7 (seven) components into a single integrated agent, called **Rainbow!**

1. DQN
2. Double DQN
3. Prioritized Experience Replay
4. Dueling Network
5. Noisy Network
6. Categorical DQN
7. N-step Learning
"""

day = 22
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/Rainbow_DQN_Agent/Rainbow_DQN_experiments/eval_data_Rainbow_DQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_Rainbow_DQN_day22 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_Rainbow_DQN_day22[col_name] = concatenated_df[col_name].mean(axis=1)

day = 23
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/Rainbow_DQN_Agent/Rainbow_DQN_experiments/eval_data_Rainbow_DQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_Rainbow_DQN_day23 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_Rainbow_DQN_day23[col_name] = concatenated_df[col_name].mean(axis=1)

day = 24
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/Rainbow_DQN_Agent/Rainbow_DQN_experiments/eval_data_Rainbow_DQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_Rainbow_DQN_day24 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_Rainbow_DQN_day24[col_name] = concatenated_df[col_name].mean(axis=1)

day = 25
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/Rainbow_DQN_Agent/Rainbow_DQN_experiments/eval_data_Rainbow_DQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_Rainbow_DQN_day25 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_Rainbow_DQN_day25[col_name] = concatenated_df[col_name].mean(axis=1)

day = 26
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/Rainbow_DQN_Agent/Rainbow_DQN_experiments/eval_data_Rainbow_DQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_Rainbow_DQN_day26 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_Rainbow_DQN_day26[col_name] = concatenated_df[col_name].mean(axis=1)

day = 27
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/Rainbow_DQN_Agent/Rainbow_DQN_experiments/eval_data_Rainbow_DQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_Rainbow_DQN_day27 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_Rainbow_DQN_day27[col_name] = concatenated_df[col_name].mean(axis=1)

day = 28
dfs = []
for s in seed:
    filename = f'/content/gdrive/MyDrive/RL_Results/Rainbow_DQN_Agent/Rainbow_DQN_experiments/eval_data_Rainbow_DQN_{s}_{day}.csv'
    df = pd.read_csv(filename)
    dfs.append(df)
concatenated_df = pd.concat(dfs, axis=1)
eval_data_Rainbow_DQN_day28 = pd.DataFrame()
for col_name, col_data in concatenated_df.items():
    if np.issubdtype(col_data.dtype, np.number):
        eval_data_Rainbow_DQN_day28[col_name] = concatenated_df[col_name].mean(axis=1)

# Put All 7 Days Data Together

eval_data_Rainbow_DQN_Op_Cost = []
eval_data_Rainbow_DQN_Op_Cost.append(sum(eval_data_Rainbow_DQN_day22['operation_cost']))
eval_data_Rainbow_DQN_Op_Cost.append(sum(eval_data_Rainbow_DQN_day23['operation_cost']))
eval_data_Rainbow_DQN_Op_Cost.append(sum(eval_data_Rainbow_DQN_day24['operation_cost']))
eval_data_Rainbow_DQN_Op_Cost.append(sum(eval_data_Rainbow_DQN_day25['operation_cost']))
eval_data_Rainbow_DQN_Op_Cost.append(sum(eval_data_Rainbow_DQN_day26['operation_cost']))
eval_data_Rainbow_DQN_Op_Cost.append(sum(eval_data_Rainbow_DQN_day27['operation_cost']))
eval_data_Rainbow_DQN_Op_Cost.append(sum(eval_data_Rainbow_DQN_day28['operation_cost']))

eval_data_Rainbow_DQN_Unbalance = []
eval_data_Rainbow_DQN_Unbalance.append(sum(eval_data_Rainbow_DQN_day22['unbalance']))
eval_data_Rainbow_DQN_Unbalance.append(sum(eval_data_Rainbow_DQN_day23['unbalance']))
eval_data_Rainbow_DQN_Unbalance.append(sum(eval_data_Rainbow_DQN_day24['unbalance']))
eval_data_Rainbow_DQN_Unbalance.append(sum(eval_data_Rainbow_DQN_day25['unbalance']))
eval_data_Rainbow_DQN_Unbalance.append(sum(eval_data_Rainbow_DQN_day26['unbalance']))
eval_data_Rainbow_DQN_Unbalance.append(sum(eval_data_Rainbow_DQN_day27['unbalance']))
eval_data_Rainbow_DQN_Unbalance.append(sum(eval_data_Rainbow_DQN_day28['unbalance']))

"""###**Solve the mixed-integer nonlinear programming (MINLP) problem With Gurobi Solver**

**A Theoretical Optimal Solution Baseline**
"""

def optimization_base_result(env_RL, month, day, initial_soc):

    pv = env_RL.data_manager.get_series_pv_data(month, day)
    wind = env_RL.data_manager.get_series_wind_data(month, day)
    offwind = env_RL.data_manager.get_series_offwind_data(month, day)
    price = env_RL.data_manager.get_series_price_data(month, day)
    load = env_RL.data_manager.get_series_electricity_cons_data(month, day)
    period = env_RL.episode_length

    # parameters
    DG_parameters = env_RL.dg_parameters

    def get_dg_info(parameters):
        p_max = []
        p_min = []
        ramping_up = []
        ramping_down = []
        dg_cap_cost = []
        dg_marg_cost = []

        for name, gen_info in parameters.items():
            p_max.append(gen_info['power_output_max'])
            p_min.append(gen_info['power_output_min'])
            ramping_up.append(gen_info['ramping_up'])
            ramping_down.append(gen_info['ramping_down'])
            dg_cap_cost.append(gen_info['dg_cap_cost'])
            dg_marg_cost.append(gen_info['dg_marg_cost'])
        return p_max, p_min, ramping_up, ramping_down, dg_cap_cost, dg_marg_cost

    p_max, p_min, ramping_up, ramping_down, dg_cap_cost, dg_marg_cost = get_dg_info(
        parameters = DG_parameters)

    battery_parameters = env_RL.battery_parameters
    NUM_GEN = len(DG_parameters.keys())
    battery_capacity = env_RL.battery1.capacity
    battery_efficiency = env_RL.battery1.efficiency
    bess_cap_cost = env_RL.battery_parameters['bess_cap_cost']
    bess_marg_cost = env_RL.battery_parameters['bess_marg_cost']
    #netload = env_RL.netload

    m = gp.Model("PowerGeneration")

    # add the amount of power to be generated from power plant i during
    # hour h; this has to be at least 0, variable to the model.
    z = m.addVars(NUM_GEN, period, name = "z", lb = 0) # power generated in each plant for each hour

    # add the Binary variables to the model : Let u be an indicator of whether
    # plant i is on during hour h. It act as on/off switches - 1 if true, or 0 otherwise.
    u = m.addVars(NUM_GEN, period, name = "u", vtype = GRB.BINARY) # is the plant on? for each plant and hour

    # let v and w and be indicators of whether plant i is started up or shut down,
    # respectively, for hour h.
    v = m.addVars(NUM_GEN, period, name = "v", vtype = GRB.BINARY) # start up the plant? for each plant and hour
    w = m.addVars(NUM_GEN, period, name = "w", vtype = GRB.BINARY) # shut down the plant? for each plant and hour
    bec = m.addVars(period, vtype = GRB.CONTINUOUS, lb = -env_RL.battery1.max_charge,
                    ub = env_RL.battery1.max_charge, name = 'bec')
    gei = m.addVars(period, vtype = GRB.CONTINUOUS, lb = 0, ub = env_RL.grid.exchange_ability,
                    name = 'gei')# set constrains for exchange between external grid and distributed energy system
    gee = m.addVars(period, vtype = GRB.CONTINUOUS, lb = 0, ub = env_RL.grid.exchange_ability,
                    name='gee')
    soc = m.addVars(period, vtype = GRB.CONTINUOUS, lb = 0.2, ub = 0.8, name='soc')

    print("This model has", len(z) + len(u) + len(v) + len(w) +\
          len(bec) + len(gei) + len(gee) + len(soc), "decision variables.")

    # Next, we tell the model what range of values the decision variables can take.
    # This is done through constraints.

    # Constraint: Meet demand:
    # First, we want to make sure that the total power generated by all the power
    # plants in each hour is > OR equal to the power demand in that hour.
    m.addConstrs(((
        sum(z[i, h] for i in range(NUM_GEN)) + pv[h] + wind[h] + offwind[h] + gei[h] >= load[h] + bec[h] + gee[h]
        ) for h in range(period)), name = 'powerbalance')

    #Constraint: State of Charge (SOC)
    m.addConstr(battery_capacity * soc[0] == battery_capacity * initial_soc + (
        bec[0] * battery_efficiency), name = 'soc0')
    m.addConstrs((
        battery_capacity * soc[h] == battery_capacity * soc[h-1] + (
            bec[h] * battery_efficiency) for h in range(1, period)), name = 'soc update')

    # Constraint: Maximum and minimum generation levels:
    # We make sure that the power generated from each plant does not exceed the plant's
    # maximum capacity (denoted by). We also want to make sure that when the plant
    # is "off", when, we do not generate any power.
    # Furthermore, recall that each plant needs to generate a certain minimum %
    # amount of power, i.e: plants must produce at least 1% of their capacity.
    m.addConstrs((z[i, h] <= u[i, h] * p_max[i] for i in range(
        NUM_GEN) for h in range(period)), 'output_max')
    m.addConstrs((z[i, h] >= u[i, h] * p_min[i] for i in range(
        NUM_GEN) for h in range(period)), 'output_min')

    # Constraint: Max rampdown, rampup:
    # While operating the power plants, it is preferable not to cause drastic changes
    # in power generation. We can enforce a limit on the speed at which power generation
    # is ramped up or ramped down. We can define constraints that ensure that the
    # magnitude of quantity is no more than a certain percentage of the maximum
    # capacity. This percentage is given by the ramp up/ramp down speed.
    m.addConstrs((
        z[i, h + 1] - z[i, h] <= ramping_up[i] for i in range(
            NUM_GEN) for h in range(period - 1)), 'ramping_up')
    m.addConstrs((
        z[i, h] - z[i, h + 1] <= ramping_down[i] for i in range(
            NUM_GEN) for h in range(period - 1)), 'ramping_down')

    # Constraint: If switched on, must be on:
    # Next, we ensure that when a power plant is switched "on," the plant is "on"
    # (and in effect starts generating power). Mathematically, when v = 1,
    # u is set to 1. Similarly, when a plant is "switched off," the plant is "off";
    # when w is 1, u is set to 0.
    m.addConstrs((v[i, h] <= u[i, h]) for i in range(NUM_GEN) for h in range(
        period))
    m.addConstrs((w[i, h] <= 1 - u[i, h]) for i in range(NUM_GEN) for h in range(
        period))

    # Constraint: Link startup/shutdown variables to "on"/"off" variables:
    # Finally, we link the startup/shutdown variables (v and w) with the "on"/"off"
    # variables (u).
    # Three possible scenario values are: -1, 0, 1.
    #If it is -1, it means that the plant is "switched off" for hour h, forcing
    # the variable w to be 1.
    # If it is 1, it means that the plant is "switched on" for hour h, forcing the
    # variable v to be 1.
    # If it is 0, it means that the plant is neither "switched on" nor "switched off"
    # for hour h; forcing the variables w and v to be 0.
    m.addConstrs((
        v[i, h] - w[i, h] == u[i, h] - u[i, h-1]) for i in range(
            NUM_GEN) for h in range(period) if h > 1)

    # Objective: Minimize the total costs
    #objective_dg_cap_cost = gp.quicksum((dg_cap_cost[i] * u[i, h])for h in range(
        #period) for i in range(NUM_GEN)) # Capital operating cost
    objective_dg_marg_cost = gp.quicksum((dg_marg_cost[i] * u[i, h])for h in range(
        period) for i in range(NUM_GEN)) # Marginal operating cost
    #cost_bess_cap_cost = gp.quicksum(bess_cap_cost for h in range(period))
    cost_bess_marg_cost = gp.quicksum(bess_marg_cost for h in range(period))
    cost_grid_import = gp.quicksum(gei[h] * price[h] for h in range(period))
    cost_grid_export = gp.quicksum(
        gee[h] * price[h] * env_RL.sell_coefficient for h in range(period))
    m.setObjective((objective_dg_marg_cost +\
                    cost_bess_marg_cost + cost_grid_import - cost_grid_export
                    ), sense = GRB.MINIMIZE)
    m.update()

    print(m.getAttr("VarName", m.getVars()))
    print('==========================================================================')
    print(m.getAttr("ConstrName", m.getConstrs()))
    print('==========================================================================')
    obj = m.getObjective()
    print(f"\nobj: {obj}")
    print('==========================================================================')

    m.optimize()

    output_record={
        'pv':[], 'wind':[], 'offwind':[], 'price':[],'load':[],'netload':[],'soc':[],'battery_energy_change':[],'grid_import':[],'grid_export':[],'ccgt':[],'coal':[],'biomass':[],'nuclear':[],'hydro':[],'step_cost':[]}

    for h in range(period):
        #gen_cost_cap = sum((u[i, h].x * (dg_cap_cost[i])) for i in range(NUM_GEN))
        gen_cost_marg = sum((u[i, h].x * (dg_marg_cost[i])) for i in range(NUM_GEN))
        #cost_bess_cap_cost = bess_cap_cost
        cost_bess_marg_cost = bess_marg_cost
        grid_import_cost = gei[h].x * price[h]
        grid_export_cost = gee[h].x * price[h] *env_RL.sell_coefficient
        output_record['pv'].append(pv[h])
        output_record['wind'].append(wind[h])
        output_record['offwind'].append(offwind[h])
        output_record['price'].append(price[h])
        output_record['load'].append(load[h])
        output_record['netload'].append(load[h]-pv[h]-wind[h]-offwind[h])
        output_record['soc'].append(soc[h].x)
        output_record['battery_energy_change'].append(bec[h].x)
        output_record['grid_import'].append(gei[h].x)
        output_record['grid_export'].append(gee[h].x)
        output_record['ccgt'].append(z[0, h].x)
        output_record['coal'].append(z[1, h].x)
        output_record['biomass'].append(z[2, h].x)
        output_record['nuclear'].append(z[3, h].x)
        output_record['hydro'].append(z[4, h].x)
        output_record['step_cost'].append(gen_cost_marg + cost_bess_marg_cost +\
                                          grid_import_cost - grid_export_cost)
    output_record_df = pd.DataFrame.from_dict(output_record)

    return output_record_df

## Test Using Data Between December 22-31, 2021 (7 Diiferent Days)

# Using Month is: 12, Day is:22, Initial SOC is:0.3

month = 12
day = 22
initial_soc = 0.3

base_result_Day22 = optimization_base_result(env, month, day, initial_soc)

# Using Month is: 12, Day is:23, Initial SOC is:0.3

month = 12
day = 23
initial_soc = 0.3

base_result_Day23 = optimization_base_result(env, month, day, initial_soc)

# Using Month is: 12, Day is:24, Initial SOC is:0.3

month = 12
day = 24
initial_soc = 0.3

base_result_Day24 = optimization_base_result(env, month, day, initial_soc)

# Using Month is: 12, Day is:25, Initial SOC is:0.3

month = 12
day = 25
initial_soc = 0.3

base_result_Day25 = optimization_base_result(env, month, day, initial_soc)

# Using Month is: 12, Day is:26, Initial SOC is:0.3

month = 12
day = 26
initial_soc = 0.3

base_result_Day26 = optimization_base_result(env, month, day, initial_soc)

# Using Month is: 12, Day is:27, Initial SOC is:0.3

month = 12
day = 27
initial_soc = 0.3

base_result_Day27 = optimization_base_result(env, month, day, initial_soc)

# Using Month is: 12, Day is:28, Initial SOC is:0.3

month = 12
day = 28
initial_soc = 0.3

base_result_Day28 = optimization_base_result(env, month, day, initial_soc)

# Add All 7 Days Data Together

MINLP_Model_Op_Costs = []
MINLP_Model_Op_Costs.append(sum(base_result_Day22['step_cost']))
MINLP_Model_Op_Costs.append(sum(base_result_Day23['step_cost']))
MINLP_Model_Op_Costs.append(sum(base_result_Day24['step_cost']))
MINLP_Model_Op_Costs.append(sum(base_result_Day25['step_cost']))
MINLP_Model_Op_Costs.append(sum(base_result_Day26['step_cost']))
MINLP_Model_Op_Costs.append(sum(base_result_Day27['step_cost']))
MINLP_Model_Op_Costs.append(sum(base_result_Day28['step_cost']))

"""###**Visualize the Testing Operation Cost and Grid Unbalance for All Models and The Baseline - WTPV-18%**

**Note:**

This is a Cummulative for 7 different days.

The Test is performed Using Data randomly sampled between December 22 and 31, 2021.

An Initial SOC of 0.3 and Days between 22nd - 28th December, 2021 are used for the Baseline Optmization.
"""

plt.figure(figsize=(15, 9))
plt.gca().set_facecolor("white")
plt.gca().spines[['top', 'right']].set_visible(False)

MINLP_Model_Op_Costs = pd.Series(
    MINLP_Model_Op_Costs, index=pd.date_range(
        start='2021-12-22', periods=len(
            MINLP_Model_Op_Costs), freq='D'))

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_2_Op_Cost, marker='*', linestyle='-', color='maroon',
         label='DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_Rainbow_DQN_Op_Cost, marker='*', linestyle='-',
         color='black', label='Rainbow-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_NStep_Learning_Op_Cost, marker='*', linestyle='-',
         color='purple', label='MS-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_Categorical_DQN_Op_Cost, marker='*', linestyle='-',
         color='red', label='Categorical-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_NoisyNet_Op_Cost, marker='*', linestyle='-',
         color='gold', label='NN-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_DuelingNet_Op_Cost, marker='*', linestyle='-',
         color='teal', label='Duel-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_PER_Op_Cost, marker='*', linestyle='-',
         color='navy', label='PER-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DDQN_Op_Cost, marker='*', linestyle='-',
         color='olive', label='DDQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         MINLP_Model_Op_Costs, marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=20)

plt.xlabel('Days', size=25, fontweight='bold')
plt.ylabel('Cummulative Operation Cost (£)', size=25, fontweight='bold')
plt.xticks(rotation=30, size=15, fontweight='bold')
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')
ax = plt.gca()
# Set linewidth and edge color for each spine
for spine in ax.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax.xaxis.grid(False)  # Remove x-axis grid lines
ax.yaxis.grid(True)
#plt.yscale('log')
plt.legend(loc='best', ncol=3, frameon=True, fontsize='14',
           fancybox=True, framealpha=1, shadow=True, borderpad=1)
# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_Cummulative_OperationCost_During_Testing.png')
plt.tight_layout()
plt.show()

plt.figure(figsize=(15, 9))
plt.gca().set_facecolor("white")
plt.gca().spines[['top', 'right']].set_visible(False)

plt.plot(eval_data_DQN_2_Unbalance, marker='*', linestyle='-', color='maroon',
         label='DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_Rainbow_DQN_Unbalance, marker='*', linestyle='-',
         color='black', label='Rainbow-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DQN_NStep_Learning_Unbalance, marker='*', linestyle='-',
         color='purple', label='MS-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_Categorical_DQN_Unbalance, marker='*', linestyle='-',
         color='red', label='Categorical-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DQN_NoisyNet_Unbalance, marker='*', linestyle='-',
         color='gold', label='NN-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DQN_DuelingNet_Unbalance, marker='*', linestyle='-',
         color='teal', label='Duel-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DQN_PER_Unbalance, marker='*', linestyle='-',
         color='navy', label='PER-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DDQN_Unbalance, marker='*', linestyle='-',
         color='olive', label='DDQN', linewidth=3.5, markersize=20)

plt.xlabel('Days', size=25, fontweight='bold')
plt.ylabel('Cummulative Grid Unbalance (MW)', size=25, fontweight='bold')
plt.xticks(rotation=30, size=15, fontweight='bold')
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')
ax = plt.gca()
# Set linewidth and edge color for each spine
for spine in ax.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax.xaxis.grid(False)  # Remove x-axis grid lines
ax.yaxis.grid(True)
#plt.yscale('log')
plt.legend(loc='best', ncol=3, frameon=True, fontsize='13',
           fancybox=True, framealpha=1, shadow=True, borderpad=1)

plt.axhline(y=0, color='k', linestyle='--', linewidth=3.5)
plt.text(3.2, 2.5, 'Excess Generation - Obtains Benefits', fontsize=25, fontweight='bold', ha='center')
plt.text(3.5, -20.5, 'Shedding Load - Obtains Penalty', fontsize=25, fontweight='bold', ha='center')

# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_Cummulative_GridUnbalance_During_Testing.png')
plt.tight_layout()
plt.show()

"""#**EXPERIMENTAL RESULT ANALYSIS - Operational Scheduling Management (Dispatch Decisions) For The Proposed Model**

**RAINBOW DQN MODEL**
"""

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (16, 12)
fig, axs = plt.subplots(2, 2)
plt.subplots_adjust(wspace=0.5, hspace=0.5)
plt.autoscale(tight=True)

T = np.array([i for i in range(24)])
# plot Netload and Price at first
axs[0, 0].cla()
axs[0, 0].set_facecolor("white")
axs[0, 0].spines[['top', 'right']].set_visible(False)
axs[0, 0].set_ylabel('Price (£/MWh)', size=20, fontweight='bold')
axs[0, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[0, 0].plot(T, eval_data_Rainbow_DQN_day22['price'], label='Price',
            color='orange', linewidth = 4.0, linestyle='solid', drawstyle = 'steps-mid')
#axs[0, 0].legend(loc='best', ncol=1, frameon=True, fontsize='12',
        #fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)
axs_netload = axs[0, 0].twinx()
axs_netload.set_facecolor("white")
axs_netload.spines[['top', 'right']].set_visible(False)
axs_netload.set_ylabel('Netload (MW)', size=20, fontweight='bold')
axs_netload.tick_params(axis='y', rotation=0, labelsize=20)
axs_netload.bar(T, eval_data_Rainbow_DQN_day22['netload'], label='Netload',
             color = 'navy', linewidth = 4.0, align = 'center', width = 0.4)

# Combine legends from both Axes
lines, labels = axs[0, 0].get_legend_handles_labels()
lines_netload, labels_netload = axs_netload.get_legend_handles_labels()
axs_netload.legend(lines + lines_netload, labels + labels_netload,
              loc='best', ncol=1, frameon=True, fontsize='14',
        fancybox=True, framealpha=1, shadow=True, borderpad=2, labelspacing=0.2)
axs[0, 0].set_title('Netload and Price', size=25, fontweight='bold')
axs[0, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[0, 0].tick_params(axis='y', rotation=0, labelsize=15)
axs[0, 0] = plt.gca()
for spine in axs[0, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 0].xaxis.grid(False)
axs[0, 0].yaxis.grid(False)

# Plot Generation and Netload in ax[2]
axs[0, 1].cla()
axs[0, 1].set_facecolor("white")
axs[0, 1].spines[['top', 'right']].set_visible(False)
axs[0, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
axs[0, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_Rainbow_DQN_day22['battery1'])
battery_negative = np.array(eval_data_Rainbow_DQN_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_Rainbow_DQN_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_Rainbow_DQN_day22['unbalance']), 0)

axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['ccgt'], label='CCGT')
axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['coal'], label='COAL',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'])
axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['biomass'], label='BIOMASS',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'])
axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['nuclear'], label='NUCLEAR',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'])
axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['hydro'], label='HYDRO',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'])

axs[0, 1].bar(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[0, 1].bar(T, -battery_negative, label = 'battery discharge', hatch='/',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'] +\
              eval_data_Rainbow_DQN_day22['hydro'])
axs[0, 1].bar(T, -imported_from_grid, label = 'imported from grid',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'] +\
              eval_data_Rainbow_DQN_day22['hydro'] - battery_negative)
axs[0, 1].bar(T, -exported_2_grid, label = 'exported to grid',
              bottom = -battery_positive)

axs[0, 1].plot(T, eval_data_Rainbow_DQN_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 3.0, linestyle='solid')
axs[0, 1].legend(loc='best', ncol=2, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

axs[0, 1].set_title('Outputs of Generating Units - Rainbow DQN Model', size=20, fontweight='bold')
axs[0, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[0, 1].tick_params(axis='y', rotation=0, labelsize=20)
#axs[1] = plt.gca()
for spine in axs[0, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 1].xaxis.grid(False)
axs[0, 1].yaxis.grid(False)

# Plot Generation By Baseline Optimal Solution
axs[1, 0].cla()
axs[1, 0].set_facecolor("white")
axs[1, 0].spines[['top', 'right']].set_visible(False)
axs[1, 0].set_ylabel('Power (MW)', size=25, fontweight='bold')
axs[1, 0].set_xlabel('Time (h)', size=25, fontweight='bold')
battery_positive = np.array(base_result_Day22['battery_energy_change'])
battery_negative = np.array(base_result_Day22['battery_energy_change'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.array(base_result_Day22['grid_import'])
exported_2_grid = np.array(base_result_Day22['grid_export'])

axs[1, 0].bar(T, base_result_Day22['ccgt'], label='CCGT')
axs[1, 0].bar(T, base_result_Day22['coal'], label='COAL',
              bottom = base_result_Day22['ccgt'])
axs[1, 0].bar(T, base_result_Day22['biomass'], label='BIOMASS',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'])
axs[1, 0].bar(T, base_result_Day22['nuclear'], label='NUCLEAR',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'] +\
              base_result_Day22['biomass'])
axs[1, 0].bar(T, base_result_Day22['hydro'], label='HYDRO',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'] +\
              base_result_Day22['biomass'] + base_result_Day22['nuclear'])

axs[1, 0].bar(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[1, 0].bar(T, -battery_negative, label = 'battery discharge', hatch='/',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'] +\
              base_result_Day22['biomass'] + base_result_Day22['nuclear'] +\
              base_result_Day22['hydro'])
axs[1, 0].bar(T, -imported_from_grid, label = 'imported from grid',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'] +\
              base_result_Day22['biomass'] + base_result_Day22['nuclear'] +\
              base_result_Day22['hydro'] - battery_negative)
axs[1, 0].bar(T, -exported_2_grid, label = 'exported to grid',
              bottom = -battery_positive)

axs[1, 0].plot(T, base_result_Day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs[1, 0].legend(loc='best', ncol=2, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

axs[1, 0].set_title('Outputs of Generating Units - Optimal Solution Model', size=20, fontweight='bold')
axs[1, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[1, 0].tick_params(axis='y', rotation=0, labelsize=20)
#axs[1] = plt.gca()
for spine in axs[1, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 0].xaxis.grid(False)
axs[1, 0].yaxis.grid(False)

# plot energy charge/discharge with price in ax[3].
axs[1, 1].cla()
axs[1, 1].set_facecolor("white")
axs[1, 1].spines[['top', 'right']].set_visible(False)
axs[1, 1].set_ylabel('Price (£/MWh)', size=25, fontweight='bold')
axs[1, 1].set_xlabel('Time (h)', size=25, fontweight='bold')

axs[1, 1].plot(T, eval_data_Rainbow_DQN_day22['price'], drawstyle='steps-mid', label='Price',
               color = 'red', linewidth = 4.0, linestyle='solid')
axs[1, 1].legend(loc='best', ncol=1, frameon=True, fontsize='12',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)
axs_soc = axs[1, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=25, fontweight='bold')
axs_soc.plot(T, eval_data_Rainbow_DQN_day22['soc'], drawstyle='steps-mid', label='SOC',
               color = 'grey', linewidth = 4.0, linestyle='solid')
axs_soc.plot(T, base_result_Day22['soc'], drawstyle='steps-mid', label='SOC-Baseline',
               color = 'sienna', linewidth = 4.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[1, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=1, frameon=True, fontsize='14',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

axs[1, 1].set_title('Energy Charge/Discharge With Price', size=25, fontweight='bold')
axs[1, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[1, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[1, 1] = plt.gca()
for spine in axs[1, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 1].xaxis.grid(False)
axs[1, 1].yaxis.grid(False)

# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Proposed_Model_Rainbow_DQN_Performance_During_Testing.png')
plt.tight_layout()
plt.show()

"""**HOURLY OPERATION COST COMPARISON AMONG ALL MODELS**"""

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (22, 20)
fig, axs = plt.subplots(2, 1)
plt.subplots_adjust(wspace=0.6, hspace=0.4)
plt.autoscale(tight=True)

T = np.array([i for i in range(24)])
# plot Netload and Price at first
axs[0].cla()
axs[0].set_facecolor("white")
axs[0].spines[['top', 'right']].set_visible(False)
axs[0].set_ylabel('Netload (MW)', size=35, fontweight='bold')
axs[0].set_xlabel('Time (h)', size=35, fontweight='bold')
axs[0].bar(T, eval_data_DQN_2_day22['netload'], label='Netload',
            color='orange', linewidth = 2.0, align = 'center', width = 0.4)
axs_netload = axs[0].twinx()
axs_netload.set_facecolor("white")
axs_netload.spines[['top', 'right']].set_visible(False)
axs_netload.set_ylabel('Price (£/MWh)', size=35, fontweight='bold')
axs_netload.tick_params(axis='y', rotation=0, labelsize=25)
axs_netload.plot(T, eval_data_DQN_2_day22['price'], label='Price',
             color = 'navy', linewidth = 6.0, linestyle='solid', drawstyle = 'steps-mid')

# Combine legends from both Axes
lines, labels = axs[0].get_legend_handles_labels()
lines_netload, labels_netload = axs_netload.get_legend_handles_labels()
axs[0].legend(lines + lines_netload, labels + labels_netload,
              loc='best', ncol=1, frameon=True, fontsize='20',
        fancybox=True, framealpha=1, shadow=True, borderpad=2, labelspacing=0.3)
axs[0].set_title('Netload and Price', size=35, fontweight='bold')
axs[0].tick_params(axis='x', rotation=30, labelsize=25)
axs[0].tick_params(axis='y', rotation=0, labelsize=25)
axs[0] = plt.gca()
for spine in axs[0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0].xaxis.grid(False)
axs[0].yaxis.grid(True)

# plot Model's Operation Cost here
axs[1].cla()
axs[1].set_facecolor("white")
axs[1].spines[['top', 'right']].set_visible(False)
axs[1].set_ylabel('Operation Cost (£)', size=35, fontweight='bold')
axs[1].set_xlabel('Time (h)', size=35, fontweight='bold')

axs[1].plot(T, eval_data_DQN_2_day22['operation_cost'], label='DQN',
            alpha=1.0, linewidth = 5.0, color = 'gold')
axs[1].plot(T, eval_data_Rainbow_DQN_day22['operation_cost'], label='Rainbow-DQN',
            alpha=1.0, linewidth = 5.0, color = 'olive', drawstyle = 'steps-mid')
axs[1].plot(T, eval_data_DQN_NStep_Learning_day22['operation_cost'], label='MS-DQN',
            alpha=1.0, linewidth = 5.0, color = 'peachpuff')
axs[1].plot(T, eval_data_Categorical_DQN_day22['operation_cost'], label='Categorical-DQN',
            alpha=1.0, linewidth = 5.0, color = 'peru')
axs[1].plot(T, eval_data_DQN_NoisyNet_day22['operation_cost'], label='NN-DQN',
            alpha=1.0, linewidth = 5.0, color = 'darkseagreen')
axs[1].plot(T, eval_data_DQN_DuelingNet_day22['operation_cost'], label='Duel-DQN',
            alpha=1.0, linewidth = 5.0, color = 'dodgerblue')
axs[1].plot(T, eval_data_DQN_PER_day22['operation_cost'], label='PER-DQN',
            alpha=1.0, linewidth = 5.0, color = 'darkorange')
axs[1].plot(T, eval_data_DDQN_day22['operation_cost'], label='DDQN',
            alpha=1.0, linewidth = 5.0, color = 'black', linestyle='-')
axs[1].plot(T, base_result_Day22['step_cost'], label='MINLP-Baseline',
            alpha=1.0, linewidth = 5.0, color = 'navy', linestyle='--')

axs[1].set_title('Hourly Operation Cost',
                  size=35, fontweight='bold')
axs[1].tick_params(axis='x', rotation=30, labelsize=25)
axs[1].tick_params(axis='y', rotation=0, labelsize=25)
axs[1].legend(loc='best', ncol=3, frameon=True, fontsize='16',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)
for spine in axs[1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1].xaxis.grid(False)
axs[1].yaxis.grid(True)
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_OperationCost_During_Testing.png',
            format='svg', dpi=600, bbox_inches='tight')
plt.tight_layout()
plt.show()

"""**Cummulative Hourly Operation Cost for All Algorithms**"""

DQN_cum_epi_opcost = sum(eval_data_DQN_2_day22['operation_cost'])
DDQN_cum_epi_opcost = sum(eval_data_DDQN_day22['operation_cost'])
DQN_PER_cum_epi_opcost = sum(eval_data_DQN_PER_day22['operation_cost'])
DQN_DuelingNet_cum_epi_opcost = sum(eval_data_DQN_DuelingNet_day22['operation_cost'])
DQN_NoisyNet_cum_epi_opcost = sum(eval_data_DQN_NoisyNet_day22['operation_cost'])
Categorical_DQN_cum_epi_opcost = sum(eval_data_Categorical_DQN_day22['operation_cost'])
DQN_NStep_Learning_cum_epi_opcost = sum(eval_data_DQN_NStep_Learning_day22['operation_cost'])
Rainbow_DQN_cum_epi_opcost = sum(eval_data_Rainbow_DQN_day22['operation_cost'])
MINLP_Baseline = sum(base_result_Day22['step_cost'])
# Define the cumulative values

cumulative_op_costs = [
    DQN_cum_epi_opcost, DQN_PER_cum_epi_opcost, DDQN_cum_epi_opcost,
    DQN_DuelingNet_cum_epi_opcost, DQN_NoisyNet_cum_epi_opcost,
    Categorical_DQN_cum_epi_opcost,
    DQN_NStep_Learning_cum_epi_opcost,
    Rainbow_DQN_cum_epi_opcost, MINLP_Baseline,
]

# Define agent names
agent_names = [
    "DQN", "PER-DQN", "DDQN", "Duel-DQN", "NN-DQN",
    "Cat-DQN",
    "MS-DQN",
    "Rainbow-DQN", 'MINLP-Baseline'
]

bar_width = 0.4

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (20, 15)
plt.subplots_adjust(wspace=0.5, hspace=0.5)

# Plotting

plt.subplot(2, 2, 1)
plt.cla()
plt.gca().spines[['top', 'right']].set_visible(False)
bars = plt.bar(agent_names, cumulative_op_costs, color='orange',
               width=bar_width, label='Cumulative Operation Cost')
plt.xlabel('DRL Agent', size=35, fontweight='bold')
plt.ylabel('Cumulative Operation Cost (£)', size=30, fontweight='bold')
plt.xticks(rotation=45, ha='right', size=15, fontweight='bold')  # Rotate agent names for better readability
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')

plt.legend(loc="best", ncol=1, frameon=True, fontsize='18',
            fancybox=True, framealpha=1, shadow=True, borderpad=1)
ax2 = plt.gca()
for spine in ax2.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax2.xaxis.grid(False)
ax2.yaxis.grid(True)

# Draw line connecting the tops of the bars
max_values_op_costs = [bar.get_height() for bar in bars]
plt.plot(agent_names, max_values_op_costs, marker='o', color='k',
         linewidth=2.5, markersize=8)

plt.subplot(2, 2, 2)
plt.cla()
plt.gca().spines[['top', 'right']].set_visible(False)
plt.plot(agent_names, cumulative_op_costs, marker='o', color='k',
         linewidth=2.5, markersize=8, label='Cumulative Operation Cost')
plt.xlabel('DRL Agent', size=35, fontweight='bold')
plt.ylabel('Cumulative Operation Cost (£)', size=30, fontweight='bold')
plt.xticks(rotation=45, ha='right', size=15, fontweight='bold')  # Rotate agent names for better readability
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')

plt.legend(loc="best", ncol=1, frameon=True, fontsize='18',
            fancybox=True, framealpha=1, shadow=True, borderpad=1)

ax1 = plt.gca()
for spine in ax1.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax1.xaxis.grid(False)
ax1.yaxis.grid(True)

output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Cumulative_Operation_Cost_All_Models_2021.png')
plt.tight_layout()
plt.show()

print(cumulative_op_costs)

"""###**Scheduled BESS Energy Charge and Discharge Vs SOC For All Models Compared to the Baseline**"""

plt.rcParams["figure.figsize"] = (15, 15)
fig, axs = plt.subplots(4, 2)
plt.subplots_adjust(wspace=0.5, hspace=0.5)
plt.autoscale(tight=True)

T = np.array([i for i in range(24)])

# RainBow Vs Baseline
axs[0, 0].set_facecolor("white")
axs[0, 0].spines[['top', 'right']].set_visible(False)
axs[0, 0].cla()
axs[0, 0].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[0, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[0, 0].plot(T, eval_data_Rainbow_DQN_day22['battery1'], marker='*', linestyle='-',
         color='red', label='Rainbow-DQN', linewidth=3.5, markersize=8)
axs[0, 0].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[0, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_Rainbow_DQN_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[0, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[0, 0].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[0, 0].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[0, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[0, 0].tick_params(axis='y', rotation=0, labelsize=15)

axs[0, 0] = plt.gca()
for spine in axs[0, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 0].xaxis.grid(False)
axs[0, 0].yaxis.grid(False)

# DQN+NOISE Vs Baseline
axs[0, 1].set_facecolor("white")
axs[0, 1].spines[['top', 'right']].set_visible(False)
axs[0, 1].cla()
axs[0, 1].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[0, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[0, 1].plot(T, eval_data_DQN_NoisyNet_day22['battery1'], marker='*', linestyle='-',
         color='red', label='NN-DQN', linewidth=3.5, markersize=8)
axs[0, 1].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[0, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_NoisyNet_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[0, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[0, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[0, 1].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[0, 1].tick_params(axis='x', rotation=30, labelsize=15)
axs[0, 1].tick_params(axis='y', rotation=0, labelsize=15)

axs[0, 1] = plt.gca()
for spine in axs[0, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 1].xaxis.grid(False)
axs[0, 1].yaxis.grid(False)

# DQN+DUEL Vs Baseline
axs[1, 0].set_facecolor("white")
axs[1, 0].spines[['top', 'right']].set_visible(False)
axs[1, 0].cla()
axs[1, 0].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[1, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[1, 0].plot(T, eval_data_DQN_DuelingNet_day22['battery1'], marker='*', linestyle='-',
         color='red', label='Duel-DQN', linewidth=3.5, markersize=8)
axs[1, 0].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[1, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_DuelingNet_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[1, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 0].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[1, 0].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[1, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[1, 0].tick_params(axis='y', rotation=0, labelsize=15)

axs[1, 0] = plt.gca()
for spine in axs[1, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 0].xaxis.grid(False)
axs[1, 0].yaxis.grid(False)

# DDQN Vs Baseline
axs[1, 1].set_facecolor("white")
axs[1, 1].spines[['top', 'right']].set_visible(False)
axs[1, 1].cla()
axs[1, 1].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[1, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[1, 1].plot(T, eval_data_DDQN_day22['battery1'], marker='*', linestyle='-',
         color='red', label='DDQN', linewidth=3.5, markersize=8)
axs[1, 1].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[1, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DDQN_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[1, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[1, 1].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[1, 1].tick_params(axis='x', rotation=30, labelsize=15)
axs[1, 1].tick_params(axis='y', rotation=0, labelsize=15)

axs[1, 1] = plt.gca()
for spine in axs[1, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 1].xaxis.grid(False)
axs[1, 1].yaxis.grid(False)

# DQN+PER Vs Baseline
axs[2, 0].set_facecolor("white")
axs[2, 0].spines[['top', 'right']].set_visible(False)
axs[2, 0].cla()
axs[2, 0].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[2, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[2, 0].plot(T, eval_data_DQN_PER_day22['battery1'], marker='*', linestyle='-',
         color='red', label='PER-DQN', linewidth=3.5, markersize=8)
axs[2, 0].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[2, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_PER_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[2, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[2, 0].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[2, 0].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[2, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[2, 0].tick_params(axis='y', rotation=0, labelsize=15)

axs[2, 0] = plt.gca()
for spine in axs[2, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[2, 0].xaxis.grid(False)
axs[2, 0].yaxis.grid(False)

# DQN+NStep-Learning Vs Baseline
axs[2, 1].set_facecolor("white")
axs[2, 1].spines[['top', 'right']].set_visible(False)
axs[2, 1].cla()
axs[2, 1].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[2, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[2, 1].plot(T, eval_data_DQN_NStep_Learning_day22['battery1'], marker='*', linestyle='-',
         color='red', label='MS-DQN', linewidth=3.5, markersize=8)
axs[2, 1].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[2, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_NStep_Learning_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[2, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[2, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[2, 1].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[2, 1].tick_params(axis='x', rotation=30, labelsize=15)
axs[2, 1].tick_params(axis='y', rotation=0, labelsize=15)

axs[2, 1] = plt.gca()
for spine in axs[2, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[2, 1].xaxis.grid(False)
axs[2, 1].yaxis.grid(False)

# DQN Vs Baseline
axs[3, 0].set_facecolor("white")
axs[3, 0].spines[['top', 'right']].set_visible(False)
axs[3, 0].cla()
axs[3, 0].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[3, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[3, 0].plot(T, eval_data_DQN_2_day22['battery1'], marker='*', linestyle='-',
         color='red', label='DQN', linewidth=3.5, markersize=8)
axs[3, 0].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[3, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_2_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[3, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[3, 0].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[3, 0].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[3, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[3, 0].tick_params(axis='y', rotation=0, labelsize=15)

axs[3, 0] = plt.gca()
for spine in axs[3, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[3, 0].xaxis.grid(False)
axs[3, 0].yaxis.grid(False)

# CategoricalDQN Vs Baseline
axs[3, 1].set_facecolor("white")
axs[3, 1].spines[['top', 'right']].set_visible(False)
axs[3, 1].cla()
axs[3, 1].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[3, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[3, 1].plot(T, eval_data_Categorical_DQN_day22['battery1'], marker='*', linestyle='-',
         color='red', label='Categorical-DQN', linewidth=3.5, markersize=8)
axs[3, 1].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[3, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_Categorical_DQN_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[3, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[3, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[3, 1].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[3, 1].tick_params(axis='x', rotation=30, labelsize=15)
axs[3, 1].tick_params(axis='y', rotation=0, labelsize=15)

axs[3, 1] = plt.gca()
for spine in axs[3, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[3, 1].xaxis.grid(False)
axs[3, 1].yaxis.grid(False)

# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_BESS_Change_VS_SOC_During_Testing.png')
plt.tight_layout()
plt.show()

plt.rcParams["figure.figsize"] = (15, 15)
fig, axs = plt.subplots(4, 2)
plt.subplots_adjust(wspace=0.8, hspace=0.8)
plt.autoscale(tight=True)

T = np.array([i for i in range(24)])

# RainBow
axs[0, 0].set_facecolor("white")
axs[0, 0].spines[['top', 'right']].set_visible(False)
axs[0, 0].cla()
axs[0, 0].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[0, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_Rainbow_DQN_day22['battery1'])
battery_negative = np.array(eval_data_Rainbow_DQN_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_Rainbow_DQN_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_Rainbow_DQN_day22['unbalance']), 0)

axs[0, 0].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple', alpha=0.3)
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'] +\
              eval_data_Rainbow_DQN_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'] +\
              eval_data_Rainbow_DQN_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[0, 0].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'],
                       eval_data_Rainbow_DQN_day22['hydro'], label='HYDRO', color='green')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'],
                       eval_data_Rainbow_DQN_day22['nuclear'], label='NUCLEAR', color='red')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'],
                       eval_data_Rainbow_DQN_day22['biomass'], label='BIOMASS', color='violet')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'], eval_data_Rainbow_DQN_day22['coal'],
                       label='COAL', color='seagreen')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'], label='CCGT', color='gray')
axs[0, 0].plot(T, eval_data_Rainbow_DQN_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[0, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_Rainbow_DQN_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[0, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[0, 0].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[0, 0].set_xticks([])
axs[0, 0].set_title('Rainbow DQN',
                    size=20, fontweight='bold')
#axs[0, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[0, 0].tick_params(axis='y', rotation=0, labelsize=20)
axs[0, 0] = plt.gca()
for spine in axs[0, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 0].xaxis.grid(False)
axs[0, 0].yaxis.grid(False)

# DQN+NOISE
axs[0, 1].set_facecolor("white")
axs[0, 1].spines[['top', 'right']].set_visible(False)
axs[0, 1].cla()
axs[0, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[0, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_NoisyNet_day22['battery1'])
battery_negative = np.array(eval_data_DQN_NoisyNet_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_NoisyNet_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_NoisyNet_day22['unbalance']), 0)

axs[0, 1].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'] +\
              eval_data_DQN_NoisyNet_day22['biomass'] + eval_data_DQN_NoisyNet_day22['nuclear'] +\
              eval_data_DQN_NoisyNet_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'] +\
              eval_data_DQN_NoisyNet_day22['biomass'] + eval_data_DQN_NoisyNet_day22['nuclear'] +\
              eval_data_DQN_NoisyNet_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[0, 1].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'] +\
              eval_data_DQN_NoisyNet_day22['biomass'] + eval_data_DQN_NoisyNet_day22['nuclear'],
                       eval_data_DQN_NoisyNet_day22['hydro'], label='HYDRO', color='green')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'] +\
              eval_data_DQN_NoisyNet_day22['biomass'],
                       eval_data_DQN_NoisyNet_day22['nuclear'], label='NUCLEAR', color='red')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'],
                       eval_data_DQN_NoisyNet_day22['biomass'], label='BIOMASS', color='violet')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'], eval_data_DQN_NoisyNet_day22['coal'],
                       label='COAL', color='seagreen')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'], label='CCGT', color='gray')
axs[0, 1].plot(T, eval_data_DQN_NoisyNet_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[0, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_NoisyNet_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[0, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[0, 1].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[0, 1].set_xticks([])
axs[0, 1].set_title('NN-DQN', size=20,
                    fontweight='bold')
#axs[0, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[0, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[0, 1] = plt.gca()
for spine in axs[0, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 1].xaxis.grid(False)
axs[0, 1].yaxis.grid(False)

# DQN+DUEL eval_data_DQN_DuelingNet_day22
axs[1, 0].set_facecolor("white")
axs[1, 0].spines[['top', 'right']].set_visible(False)
axs[1, 0].cla()
axs[1, 0].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[1, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_DuelingNet_day22['battery1'])
battery_negative = np.array(eval_data_DQN_DuelingNet_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_DuelingNet_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_DuelingNet_day22['unbalance']), 0)

axs[1, 0].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'] +\
              eval_data_DQN_DuelingNet_day22['biomass'] + eval_data_DQN_DuelingNet_day22['nuclear'] +\
              eval_data_DQN_DuelingNet_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'] +\
              eval_data_DQN_DuelingNet_day22['biomass'] + eval_data_DQN_DuelingNet_day22['nuclear'] +\
              eval_data_DQN_DuelingNet_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[1, 0].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'] +\
              eval_data_DQN_DuelingNet_day22['biomass'] + eval_data_DQN_DuelingNet_day22['nuclear'],
                       eval_data_DQN_DuelingNet_day22['hydro'], label='HYDRO', color='green')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'] +\
              eval_data_DQN_DuelingNet_day22['biomass'],
                       eval_data_DQN_DuelingNet_day22['nuclear'], label='NUCLEAR', color='red')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'],
                       eval_data_DQN_DuelingNet_day22['biomass'], label='BIOMASS', color='violet')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'], eval_data_DQN_DuelingNet_day22['coal'],
                       label='COAL', color='seagreen')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'], label='CCGT', color='gray')
axs[1, 0].plot(T, eval_data_DQN_DuelingNet_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[1, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_DuelingNet_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[1, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 0].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[1, 0].set_xticks([])
axs[1, 0].set_title('Duel-DQN', size=20,
                    fontweight='bold', y = 0.9)
#axs[1, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[1, 0].tick_params(axis='y', rotation=0, labelsize=20)
axs[1, 0] = plt.gca()
for spine in axs[1, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 0].xaxis.grid(False)
axs[1, 0].yaxis.grid(False)

# DDQN
axs[1, 1].set_facecolor("white")
axs[1, 1].spines[['top', 'right']].set_visible(False)
axs[1, 1].cla()
axs[1, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[1, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DDQN_day22['battery1'])
battery_negative = np.array(eval_data_DDQN_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DDQN_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DDQN_day22['unbalance']), 0)

axs[1, 1].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'] +\
              eval_data_DDQN_day22['biomass'] + eval_data_DDQN_day22['nuclear'] +\
              eval_data_DDQN_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'] +\
              eval_data_DDQN_day22['biomass'] + eval_data_DDQN_day22['nuclear'] +\
              eval_data_DDQN_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[1, 1].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'] +\
              eval_data_DDQN_day22['biomass'] + eval_data_DDQN_day22['nuclear'],
                       eval_data_DDQN_day22['hydro'], label='HYDRO', color='green')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'] +\
              eval_data_DDQN_day22['biomass'],
                       eval_data_DDQN_day22['nuclear'], label='NUCLEAR', color='red')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'],
                       eval_data_DDQN_day22['biomass'], label='BIOMASS', color='violet')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'], eval_data_DDQN_day22['coal'],
                       label='COAL', color='seagreen')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'], label='CCGT', color='gray')
axs[1, 1].plot(T, eval_data_DDQN_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[1, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DDQN_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[1, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 1].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[1, 1].set_xticks([])
axs[1, 1].set_title('DDQN', size=20,
                    fontweight='bold', y = 0.9)
#axs[1, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[1, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[1, 1] = plt.gca()
for spine in axs[1, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 1].xaxis.grid(False)
axs[1, 1].yaxis.grid(False)

# DQN+PER
axs[2, 0].set_facecolor("white")
axs[2, 0].spines[['top', 'right']].set_visible(False)
axs[2, 0].cla()
axs[2, 0].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[2, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_PER_day22['battery1'])
battery_negative = np.array(eval_data_DQN_PER_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_PER_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_PER_day22['unbalance']), 0)

axs[2, 0].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'] +\
              eval_data_DQN_PER_day22['biomass'] + eval_data_DQN_PER_day22['nuclear'] +\
              eval_data_DQN_PER_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'] +\
              eval_data_DQN_PER_day22['biomass'] + eval_data_DQN_PER_day22['nuclear'] +\
              eval_data_DQN_PER_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[2, 0].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'] +\
              eval_data_DQN_PER_day22['biomass'] + eval_data_DQN_PER_day22['nuclear'],
                       eval_data_DQN_PER_day22['hydro'], label='HYDRO', color='green')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'] +\
              eval_data_DQN_PER_day22['biomass'],
                       eval_data_DQN_PER_day22['nuclear'], label='NUCLEAR', color='red')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'],
                       eval_data_DQN_PER_day22['biomass'], label='BIOMASS', color='violet')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'], eval_data_DQN_PER_day22['coal'],
                       label='COAL', color='seagreen')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'], label='CCGT', color='gray')
axs[2, 0].plot(T, eval_data_DQN_PER_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[2, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_PER_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[2, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[2, 0].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[2, 0].set_xticks([])
axs[2, 0].set_title('PER-DQN', size=20,
                    fontweight='bold', y = 0.9)
#axs[2, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[2, 0].tick_params(axis='y', rotation=0, labelsize=20)
axs[2, 0] = plt.gca()
for spine in axs[2, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[2, 0].xaxis.grid(False)
axs[2, 0].yaxis.grid(False)

# DQN+NStep-Learning
axs[2, 1].set_facecolor("white")
axs[2, 1].spines[['top', 'right']].set_visible(False)
axs[2, 1].cla()
axs[2, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[2, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_NStep_Learning_day22['battery1'])
battery_negative = np.array(eval_data_DQN_NStep_Learning_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_NStep_Learning_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_NStep_Learning_day22['unbalance']), 0)

axs[2, 1].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'] +\
              eval_data_DQN_NStep_Learning_day22['biomass'] + eval_data_DQN_NStep_Learning_day22['nuclear'] +\
              eval_data_DQN_NStep_Learning_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'] +\
              eval_data_DQN_NStep_Learning_day22['biomass'] + eval_data_DQN_NStep_Learning_day22['nuclear'] +\
              eval_data_DQN_NStep_Learning_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[2, 1].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'] +\
              eval_data_DQN_NStep_Learning_day22['biomass'] + eval_data_DQN_NStep_Learning_day22['nuclear'],
                       eval_data_DQN_NStep_Learning_day22['hydro'], label='HYDRO', color='green')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'] +\
              eval_data_DQN_NStep_Learning_day22['biomass'],
                       eval_data_DQN_NStep_Learning_day22['nuclear'], label='NUCLEAR', color='red')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'],
                       eval_data_DQN_NStep_Learning_day22['biomass'], label='BIOMASS', color='violet')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'], eval_data_DQN_NStep_Learning_day22['coal'],
                       label='COAL', color='seagreen')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'], label='CCGT', color='gray')
axs[2, 1].plot(T, eval_data_DQN_NStep_Learning_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[2, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_NStep_Learning_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[2, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[2, 1].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[2, 1].set_xticks([])
axs[2, 1].set_title('MS-DQN', size=20,
                    fontweight='bold', y = 0.9)
#axs[2, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[2, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[2, 1] = plt.gca()
for spine in axs[2, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[2, 1].xaxis.grid(False)
axs[2, 1].yaxis.grid(False)

# DQN
axs[3, 0].set_facecolor("white")
axs[3, 0].spines[['top', 'right']].set_visible(False)
axs[3, 0].cla()
axs[3, 0].set_ylabel('Power (MW)', size=20, fontweight='bold')
axs[3, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_2_day22['battery1'])
battery_negative = np.array(eval_data_DQN_2_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_2_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_2_day22['unbalance']), 0)

axs[3, 0].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'] +\
              eval_data_DQN_2_day22['biomass'] + eval_data_DQN_2_day22['nuclear'] +\
              eval_data_DQN_2_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'] +\
              eval_data_DQN_2_day22['biomass'] + eval_data_DQN_2_day22['nuclear'] +\
              eval_data_DQN_2_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[3, 0].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'] +\
              eval_data_DQN_2_day22['biomass'] + eval_data_DQN_2_day22['nuclear'],
                       eval_data_DQN_2_day22['hydro'], label='HYDRO', color='green')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'] +\
              eval_data_DQN_2_day22['biomass'],
                       eval_data_DQN_2_day22['nuclear'], label='NUCLEAR', color='red')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'],
                       eval_data_DQN_2_day22['biomass'], label='BIOMASS', color='violet')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'], eval_data_DQN_2_day22['coal'],
                       label='COAL', color='seagreen')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'], label='CCGT', color='gray')
axs[3, 0].plot(T, eval_data_DQN_2_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[3, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_2_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[3, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[3, 0].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.46), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)

axs[3, 0].set_title('DQN', size=20,
                    fontweight='bold', y = 0.9)
axs[3, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[3, 0].tick_params(axis='y', rotation=0, labelsize=20)
axs[3, 0] = plt.gca()
for spine in axs[3, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[3, 0].xaxis.grid(False)
axs[3, 0].yaxis.grid(False)

# CategoricalDQN
axs[3, 1].set_facecolor("white")
axs[3, 1].spines[['top', 'right']].set_visible(False)
axs[3, 1].cla()
axs[3, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
axs[3, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_Categorical_DQN_day22['battery1'])
battery_negative = np.array(eval_data_Categorical_DQN_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_Categorical_DQN_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_Categorical_DQN_day22['unbalance']), 0)

axs[3, 1].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'] +\
              eval_data_Categorical_DQN_day22['biomass'] + eval_data_Categorical_DQN_day22['nuclear'] +\
              eval_data_Categorical_DQN_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'] +\
              eval_data_Categorical_DQN_day22['biomass'] + eval_data_Categorical_DQN_day22['nuclear'] +\
              eval_data_Categorical_DQN_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[3, 1].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'] +\
              eval_data_Categorical_DQN_day22['biomass'] + eval_data_Categorical_DQN_day22['nuclear'],
                       eval_data_Categorical_DQN_day22['hydro'], label='HYDRO', color='green')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'] +\
              eval_data_Categorical_DQN_day22['biomass'],
                       eval_data_Categorical_DQN_day22['nuclear'], label='NUCLEAR', color='red')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'],
                       eval_data_Categorical_DQN_day22['biomass'], label='BIOMASS', color='violet')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'], eval_data_Categorical_DQN_day22['coal'],
                       label='COAL', color='seagreen')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'], label='CCGT', color='gray')
axs[3, 1].plot(T, eval_data_Categorical_DQN_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[3, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_Categorical_DQN_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[3, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[3, 1].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.46), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)

axs[3, 1].set_title('Categorical-DQN', size=20,
                    fontweight='bold', y = 0.9)
axs[3, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[3, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[3, 1] = plt.gca()
for spine in axs[3, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[3, 1].xaxis.grid(False)
axs[3, 1].yaxis.grid(False)

# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Operational_Scheduling_Management_of_all_Models_During_Testing.png')
plt.tight_layout()
plt.show()

"""**Cummulative Operation Cost Savings Relative to The Baseline Network - DQN**"""

# Day 22
dqn22 = eval_data_DQN_2_day22['operation_cost']
rainbow22 = eval_data_Rainbow_DQN_day22['operation_cost']
dqn_nstep22 = eval_data_DQN_NStep_Learning_day22['operation_cost']
categorical_dqn22 = eval_data_Categorical_DQN_day22['operation_cost']
dqn_noise22 = eval_data_DQN_NoisyNet_day22['operation_cost']
dqn_duel22 = eval_data_DQN_DuelingNet_day22['operation_cost']
dqn_per22 = eval_data_DQN_PER_day22['operation_cost']
ddqn22 = eval_data_DDQN_day22['operation_cost']
minlp22 = base_result_Day22['step_cost']
# Day 23
dqn23 = eval_data_DQN_2_day23['operation_cost']
rainbow23 = eval_data_Rainbow_DQN_day23['operation_cost']
dqn_nstep23 = eval_data_DQN_NStep_Learning_day23['operation_cost']
categorical_dqn23 = eval_data_Categorical_DQN_day23['operation_cost']
dqn_noise23 = eval_data_DQN_NoisyNet_day23['operation_cost']
dqn_duel23 = eval_data_DQN_DuelingNet_day23['operation_cost']
dqn_per23 = eval_data_DQN_PER_day23['operation_cost']
ddqn23 = eval_data_DDQN_day23['operation_cost']
minlp23 = base_result_Day23['step_cost']
# Day 24
dqn24 = eval_data_DQN_2_day24['operation_cost']
rainbow24 = eval_data_Rainbow_DQN_day24['operation_cost']
dqn_nstep24 = eval_data_DQN_NStep_Learning_day24['operation_cost']
categorical_dqn24 = eval_data_Categorical_DQN_day24['operation_cost']
dqn_noise24 = eval_data_DQN_NoisyNet_day24['operation_cost']
dqn_duel24 = eval_data_DQN_DuelingNet_day24['operation_cost']
dqn_per24 = eval_data_DQN_PER_day24['operation_cost']
ddqn24 = eval_data_DDQN_day24['operation_cost']
minlp24 = base_result_Day24['step_cost']
# Day 25
dqn25 = eval_data_DQN_2_day25['operation_cost']
rainbow25 = eval_data_Rainbow_DQN_day25['operation_cost']
dqn_nstep25 = eval_data_DQN_NStep_Learning_day25['operation_cost']
categorical_dqn25 = eval_data_Categorical_DQN_day25['operation_cost']
dqn_noise25 = eval_data_DQN_NoisyNet_day25['operation_cost']
dqn_duel25 = eval_data_DQN_DuelingNet_day25['operation_cost']
dqn_per25 = eval_data_DQN_PER_day25['operation_cost']
ddqn25 = eval_data_DDQN_day25['operation_cost']
minlp25 = base_result_Day25['step_cost']
# Day 26
dqn26 = eval_data_DQN_2_day26['operation_cost']
rainbow26 = eval_data_Rainbow_DQN_day26['operation_cost']
dqn_nstep26 = eval_data_DQN_NStep_Learning_day26['operation_cost']
categorical_dqn26 = eval_data_Categorical_DQN_day26['operation_cost']
dqn_noise26 = eval_data_DQN_NoisyNet_day26['operation_cost']
dqn_duel26 = eval_data_DQN_DuelingNet_day26['operation_cost']
dqn_per26 = eval_data_DQN_PER_day26['operation_cost']
ddqn26 = eval_data_DDQN_day26['operation_cost']
minlp26 = base_result_Day26['step_cost']
# Day 27
dqn27 = eval_data_DQN_2_day27['operation_cost']
rainbow27 = eval_data_Rainbow_DQN_day27['operation_cost']
dqn_nstep27 = eval_data_DQN_NStep_Learning_day27['operation_cost']
categorical_dqn27 = eval_data_Categorical_DQN_day27['operation_cost']
dqn_noise27 = eval_data_DQN_NoisyNet_day27['operation_cost']
dqn_duel27 = eval_data_DQN_DuelingNet_day27['operation_cost']
dqn_per27 = eval_data_DQN_PER_day27['operation_cost']
ddqn27 = eval_data_DDQN_day27['operation_cost']
minlp27 = base_result_Day27['step_cost']
# Day 28
dqn28 = eval_data_DQN_2_day28['operation_cost']
rainbow28 = eval_data_Rainbow_DQN_day28['operation_cost']
dqn_nstep28 = eval_data_DQN_NStep_Learning_day28['operation_cost']
categorical_dqn28 = eval_data_Categorical_DQN_day28['operation_cost']
dqn_noise28 = eval_data_DQN_NoisyNet_day28['operation_cost']
dqn_duel28 = eval_data_DQN_DuelingNet_day28['operation_cost']
dqn_per28 = eval_data_DQN_PER_day28['operation_cost']
ddqn28 = eval_data_DDQN_day28['operation_cost']
minlp28 = base_result_Day28['step_cost']

# concatenate
dqn = pd.concat([dqn22, dqn23, dqn24, dqn25, dqn26, dqn27, dqn28], axis=0)
rainbow = pd.concat([rainbow22, rainbow23, rainbow24, rainbow25, rainbow26, rainbow27, rainbow28],
                    axis=0)
dqn_nstep = pd.concat([dqn_nstep22, dqn_nstep23, dqn_nstep24, dqn_nstep25, dqn_nstep26, dqn_nstep27, dqn_nstep28],
                      axis=0)
categorical_dqn = pd.concat([categorical_dqn22, categorical_dqn23, categorical_dqn24, categorical_dqn25,
                             categorical_dqn26, categorical_dqn27, categorical_dqn28],
                             axis=0)
dqn_noise = pd.concat([dqn_noise22, dqn_noise23, dqn_noise24, dqn_noise25, dqn_noise26,
                       dqn_noise27, dqn_noise28], axis=0)
dqn_duel = pd.concat([dqn_duel22, dqn_duel23, dqn_duel24, dqn_duel25, dqn_duel26,
                      dqn_duel27, dqn_duel28], axis=0)
dqn_per = pd.concat([dqn_per22, dqn_per23, dqn_per24, dqn_per25, dqn_per26,
                     dqn_per27, dqn_per28], axis=0)
ddqn = pd.concat([ddqn22, ddqn23, ddqn24, ddqn25, ddqn26, ddqn27, ddqn28], axis=0)
minlp = pd.concat([minlp22, minlp23, minlp24, minlp25, minlp26, minlp27,
                   minlp28], axis=0)

# Operation Cost Savings
dqn_savings = dqn - dqn
rainbow_savings = dqn - rainbow
dqn_nstep_savings = dqn - dqn_nstep
categorical_dqn_savings = dqn - categorical_dqn
dqn_noise_savings = dqn - dqn_noise
dqn_duel_savings = dqn - dqn_duel
dqn_per_savings = dqn - dqn_per
ddqn_savings = dqn - ddqn
minlp_savings = dqn - minlp

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (22, 20)
fig, axs = plt.subplots(1, 1)
plt.subplots_adjust(wspace=0.6, hspace=0.4)
plt.autoscale(tight=True)

T = np.array([i for i in range(168)])

axs.set_facecolor("white")
axs.spines[['top', 'right']].set_visible(False)
axs.cla()
axs.set_ylabel('Operation Cost Savings (£)', size=35, fontweight='bold')
axs.set_xlabel('Time (h)', size=35, fontweight='bold')

axs.plot(T, rainbow_savings, label='Rainbow-DQN',
            alpha=1.0, linewidth = 5.0, color = 'olive', drawstyle = 'steps-mid')
axs.plot(T, dqn_nstep_savings, label='MS-DQN',
            alpha=1.0, linewidth = 5.0, color = 'peachpuff', drawstyle = 'steps-mid')
axs.plot(T, categorical_dqn_savings, label='Categorical-DQN',
            alpha=1.0, linewidth = 5.0, color = 'peru', drawstyle = 'steps-mid')
axs.plot(T, dqn_noise_savings, label='NN-DQN',
            alpha=1.0, linewidth = 5.0, color = 'darkseagreen', drawstyle = 'steps-mid')
axs.plot(T, dqn_duel_savings, label='Duel-DQN',
            alpha=1.0, linewidth = 5.0, color = 'dodgerblue', drawstyle = 'steps-mid')
axs.plot(T, dqn_per_savings, label='PER-DQN',
            alpha=1.0, linewidth = 5.0, color = 'darkorange', drawstyle = 'steps-mid')
axs.plot(T, ddqn_savings, label='DDQN',
            alpha=1.0, linewidth = 5.0, color = 'navy', linestyle='-', drawstyle = 'steps-mid')
axs.plot(T, minlp_savings, label='MINLP-Baseline',
            alpha=1.0, linewidth = 5.0, color = 'gold', linestyle='-', drawstyle = 'steps-mid')
axs.plot(T, dqn_savings, label='DQN',
            alpha=1.0, linewidth = 7.0, color = 'black', linestyle='-.', drawstyle = 'steps-mid')

axs.tick_params(axis='x', rotation=30, labelsize=25)
axs.tick_params(axis='y', rotation=0, labelsize=25)
axs.legend(loc='best', ncol=3, frameon=True, fontsize='18',
        fancybox=True, framealpha=1, shadow=True, borderpad=2, labelspacing=0.3)
axs = plt.gca()
for spine in axs.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs.xaxis.grid(False)
axs.yaxis.grid(False)
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_OperationCost_Savings_During_Testing.png',
            format='svg', dpi=600, bbox_inches='tight')
plt.tight_layout()
plt.show()

print('==================================================================')
print(dqn_savings)
print('==================================================================')
print(rainbow_savings)
print('==================================================================')
print(dqn_nstep_savings)
print('==================================================================')
print(categorical_dqn_savings)
print('==================================================================')
print(dqn_noise_savings)
print('==================================================================')
print(dqn_duel_savings)
print('==================================================================')
print(dqn_per_savings)
print('==================================================================')
print(ddqn_savings)
print('==================================================================')
print(minlp_savings)
print('==================================================================')

"""**Compute All Algorithm's Ability to Utilize RES - Total Consumption Rate of RES**

Larger is better!
"""

DQN_cum_pv = sum(eval_data_DQN_2_day22['pv'])
DDQN_cum_pv = sum(eval_data_DDQN_day22['pv'])
DQN_PER_cum_pv = sum(eval_data_DQN_PER_day22['pv'])
DQN_DuelingNet_cum_pv = sum(eval_data_DQN_DuelingNet_day22['pv'])
DQN_NoisyNet_cum_pv = sum(eval_data_DQN_NoisyNet_day22['pv'])
Categorical_DQN_cum_pv = sum(eval_data_Categorical_DQN_day22['pv'])
DQN_NStep_Learning_cum_pv = sum(eval_data_DQN_NStep_Learning_day22['pv'])
Rainbow_DQN_cum_pv = sum(eval_data_Rainbow_DQN_day22['pv'])
MINLP_Baseline_pv = sum(base_result_Day22['pv'])

DQN_cum_onwind = sum(eval_data_DQN_2_day22['onwind'])
DDQN_cum_onwind = sum(eval_data_DDQN_day22['onwind'])
DQN_PER_cum_onwind = sum(eval_data_DQN_PER_day22['onwind'])
DQN_DuelingNet_cum_onwind = sum(eval_data_DQN_DuelingNet_day22['onwind'])
DQN_NoisyNet_cum_onwind = sum(eval_data_DQN_NoisyNet_day22['onwind'])
Categorical_DQN_cum_onwind = sum(eval_data_Categorical_DQN_day22['onwind'])
DQN_NStep_Learning_cum_onwind = sum(eval_data_DQN_NStep_Learning_day22['onwind'])
Rainbow_DQN_cum_onwind = sum(eval_data_Rainbow_DQN_day22['onwind'])
MINLP_Baseline_onwind = sum(base_result_Day22['wind'])

DQN_cum_offwind = sum(eval_data_DQN_2_day22['offwind'])
DDQN_cum_offwind = sum(eval_data_DDQN_day22['offwind'])
DQN_PER_cum_offwind = sum(eval_data_DQN_PER_day22['offwind'])
DQN_DuelingNet_cum_offwind = sum(eval_data_DQN_DuelingNet_day22['offwind'])
DQN_NoisyNet_cum_offwind = sum(eval_data_DQN_NoisyNet_day22['offwind'])
Categorical_DQN_cum_offwind = sum(eval_data_Categorical_DQN_day22['offwind'])
DQN_NStep_Learning_cum_offwind = sum(eval_data_DQN_NStep_Learning_day22['offwind'])
Rainbow_DQN_cum_offwind = sum(eval_data_Rainbow_DQN_day22['offwind'])
MINLP_Baseline_offwind = sum(base_result_Day22['offwind'])

DQN_RESComsumptionRate = (DQN_cum_pv + DQN_cum_onwind + DQN_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DDQN_RESComsumptionRate = (DDQN_cum_pv + DDQN_cum_onwind + DDQN_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DQN_PER_RESComsumptionRate = (DQN_PER_cum_pv + DQN_PER_cum_onwind + DQN_PER_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DQN_DuelingNet_RESComsumptionRate = (DQN_DuelingNet_cum_pv + DQN_DuelingNet_cum_onwind + DQN_DuelingNet_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DQN_NoisyNet_RESComsumptionRate = (DQN_NoisyNet_cum_pv + DQN_NoisyNet_cum_onwind + DQN_NoisyNet_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
Categorical_DQN_RESComsumptionRate = (Categorical_DQN_cum_pv + Categorical_DQN_cum_onwind + Categorical_DQN_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DQN_NStep_Learning_RESComsumptionRate = (DQN_NStep_Learning_cum_pv + DQN_NStep_Learning_cum_onwind + DQN_NStep_Learning_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
Rainbow_DQN_RESComsumptionRate = (Rainbow_DQN_cum_pv + Rainbow_DQN_cum_onwind + Rainbow_DQN_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
MINLP_Baseline_RESComsumptionRate = (MINLP_Baseline_pv + MINLP_Baseline_onwind + MINLP_Baseline_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)

RESComsumptionRate = [
    DQN_RESComsumptionRate, DQN_PER_RESComsumptionRate, DDQN_RESComsumptionRate,
    DQN_DuelingNet_RESComsumptionRate, DQN_NoisyNet_RESComsumptionRate,
    Categorical_DQN_RESComsumptionRate,
    DQN_NStep_Learning_RESComsumptionRate,
    Rainbow_DQN_RESComsumptionRate, MINLP_Baseline_RESComsumptionRate,
]

# Define agent names
agent_names = [
    "DQN", "PER-DQN", "DDQN", "Duel-DQN", "NN-DQN",
    "Cat-DQN",
    "MS-DQN",
    "Rainbow-DQN", 'MINLP-Baseline'
]

bar_width = 0.4

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (12, 8)
plt.subplots_adjust(wspace=0.5, hspace=0.5)

# Plotting

plt.subplot(1, 1, 1)
plt.cla()
plt.gca().spines[['top', 'right']].set_visible(False)
bars = plt.bar(agent_names, RESComsumptionRate, color='orange',
               width=bar_width, label='RES Comsumption Rate')
plt.xlabel('DRL Agent', size=35, fontweight='bold')
plt.ylabel('RES Comsumption Rate', size=30, fontweight='bold')
plt.xticks(rotation=45, ha='right', size=15, fontweight='bold')  # Rotate agent names for better readability
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')

plt.legend(loc="best", ncol=1, frameon=True, fontsize='18',
            fancybox=True, framealpha=1, shadow=True, borderpad=1)
ax2 = plt.gca()
for spine in ax2.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax2.xaxis.grid(False)
ax2.yaxis.grid(True)

# Draw line connecting the tops of the bars
max_values_op_costs = [bar.get_height() for bar in bars]
plt.plot(agent_names, max_values_op_costs, marker='o', color='k',
         linewidth=2.5, markersize=8)

output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Cumulative_RESComsumptionRate_All_Models_2021.png')
plt.tight_layout()
plt.show()

print(RESComsumptionRate)

"""###**Visualize the Testing Operation Cost and Grid Unbalance for All Models and The Baseline - WTPV-0%**

**Note:**

This is a Cummulative for 7 different days.

The Test is performed Using Data randomly sampled between December 22 and 31, 2021.

An Initial SOC of 0.3 and Days between 22nd - 28th December, 2021 are used for the Baseline Optmization.
"""

plt.figure(figsize=(15, 9))
plt.gca().set_facecolor("white")
plt.gca().spines[['top', 'right']].set_visible(False)

MINLP_Model_Op_Costs = pd.Series(
    MINLP_Model_Op_Costs, index=pd.date_range(
        start='2021-12-22', periods=len(
            MINLP_Model_Op_Costs), freq='D'))

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_2_Op_Cost, marker='*', linestyle='-', color='maroon',
         label='DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_Rainbow_DQN_Op_Cost, marker='*', linestyle='-',
         color='black', label='Rainbow-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_NStep_Learning_Op_Cost, marker='*', linestyle='-',
         color='purple', label='MS-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_Categorical_DQN_Op_Cost, marker='*', linestyle='-',
         color='red', label='Categorical-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_NoisyNet_Op_Cost, marker='*', linestyle='-',
         color='gold', label='NN-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_DuelingNet_Op_Cost, marker='*', linestyle='-',
         color='teal', label='Duel-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_PER_Op_Cost, marker='*', linestyle='-',
         color='navy', label='PER-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DDQN_Op_Cost, marker='*', linestyle='-',
         color='olive', label='DDQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         MINLP_Model_Op_Costs, marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=20)

plt.xlabel('Days', size=25, fontweight='bold')
plt.ylabel('Cummulative Operation Cost (£)', size=25, fontweight='bold')
plt.xticks(rotation=30, size=15, fontweight='bold')
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')
ax = plt.gca()
# Set linewidth and edge color for each spine
for spine in ax.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax.xaxis.grid(False)  # Remove x-axis grid lines
ax.yaxis.grid(True)
#plt.yscale('log')
plt.legend(loc='best', ncol=3, frameon=True, fontsize='14',
           fancybox=True, framealpha=1, shadow=True, borderpad=1)
# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_Cummulative_OperationCost_During_Testing.png')
plt.tight_layout()
plt.show()

plt.figure(figsize=(15, 9))
plt.gca().set_facecolor("white")
plt.gca().spines[['top', 'right']].set_visible(False)

plt.plot(eval_data_DQN_2_Unbalance, marker='*', linestyle='-', color='maroon',
         label='DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_Rainbow_DQN_Unbalance, marker='*', linestyle='-',
         color='black', label='Rainbow-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DQN_NStep_Learning_Unbalance, marker='*', linestyle='-',
         color='purple', label='MS-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_Categorical_DQN_Unbalance, marker='*', linestyle='-',
         color='red', label='Categorical-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DQN_NoisyNet_Unbalance, marker='*', linestyle='-',
         color='gold', label='NN-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DQN_DuelingNet_Unbalance, marker='*', linestyle='-',
         color='teal', label='Duel-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DQN_PER_Unbalance, marker='*', linestyle='-',
         color='navy', label='PER-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DDQN_Unbalance, marker='*', linestyle='-',
         color='olive', label='DDQN', linewidth=3.5, markersize=20)

plt.xlabel('Days', size=25, fontweight='bold')
plt.ylabel('Cummulative Grid Unbalance (MW)', size=25, fontweight='bold')
plt.xticks(rotation=30, size=15, fontweight='bold')
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')
ax = plt.gca()
# Set linewidth and edge color for each spine
for spine in ax.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax.xaxis.grid(False)  # Remove x-axis grid lines
ax.yaxis.grid(True)
#plt.yscale('log')
plt.legend(loc='best', ncol=3, frameon=True, fontsize='13',
           fancybox=True, framealpha=1, shadow=True, borderpad=1)

plt.axhline(y=0, color='k', linestyle='--', linewidth=3.5)
plt.text(3.2, 2.5, 'Excess Generation - Obtains Benefits', fontsize=25, fontweight='bold', ha='center')
plt.text(3.5, -20.5, 'Shedding Load - Obtains Penalty', fontsize=25, fontweight='bold', ha='center')

# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_Cummulative_GridUnbalance_During_Testing.png')
plt.tight_layout()
plt.show()

"""#**EXPERIMENTAL RESULT ANALYSIS - Operational Scheduling Management (Dispatch Decisions) For The Proposed Model**

**RAINBOW DQN MODEL**
"""

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (16, 12)
fig, axs = plt.subplots(2, 2)
plt.subplots_adjust(wspace=0.5, hspace=0.5)
plt.autoscale(tight=True)

T = np.array([i for i in range(24)])
# plot Netload and Price at first
axs[0, 0].cla()
axs[0, 0].set_facecolor("white")
axs[0, 0].spines[['top', 'right']].set_visible(False)
axs[0, 0].set_ylabel('Price (£/MWh)', size=20, fontweight='bold')
axs[0, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[0, 0].plot(T, eval_data_Rainbow_DQN_day22['price'], label='Price',
            color='orange', linewidth = 4.0, linestyle='solid', drawstyle = 'steps-mid')
#axs[0, 0].legend(loc='best', ncol=1, frameon=True, fontsize='12',
        #fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)
axs_netload = axs[0, 0].twinx()
axs_netload.set_facecolor("white")
axs_netload.spines[['top', 'right']].set_visible(False)
axs_netload.set_ylabel('Netload (MW)', size=20, fontweight='bold')
axs_netload.tick_params(axis='y', rotation=0, labelsize=20)
axs_netload.bar(T, eval_data_Rainbow_DQN_day22['netload'], label='Netload',
             color = 'navy', linewidth = 4.0, align = 'center', width = 0.4)

# Combine legends from both Axes
lines, labels = axs[0, 0].get_legend_handles_labels()
lines_netload, labels_netload = axs_netload.get_legend_handles_labels()
axs_netload.legend(lines + lines_netload, labels + labels_netload,
              loc='best', ncol=1, frameon=True, fontsize='14',
        fancybox=True, framealpha=1, shadow=True, borderpad=2, labelspacing=0.2)
axs[0, 0].set_title('Netload and Price', size=25, fontweight='bold')
axs[0, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[0, 0].tick_params(axis='y', rotation=0, labelsize=15)
axs[0, 0] = plt.gca()
for spine in axs[0, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 0].xaxis.grid(False)
axs[0, 0].yaxis.grid(False)

# Plot Generation and Netload in ax[2]
axs[0, 1].cla()
axs[0, 1].set_facecolor("white")
axs[0, 1].spines[['top', 'right']].set_visible(False)
axs[0, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
axs[0, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_Rainbow_DQN_day22['battery1'])
battery_negative = np.array(eval_data_Rainbow_DQN_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_Rainbow_DQN_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_Rainbow_DQN_day22['unbalance']), 0)

axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['ccgt'], label='CCGT')
axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['coal'], label='COAL',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'])
axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['biomass'], label='BIOMASS',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'])
axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['nuclear'], label='NUCLEAR',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'])
axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['hydro'], label='HYDRO',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'])

axs[0, 1].bar(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[0, 1].bar(T, -battery_negative, label = 'battery discharge', hatch='/',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'] +\
              eval_data_Rainbow_DQN_day22['hydro'])
axs[0, 1].bar(T, -imported_from_grid, label = 'imported from grid',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'] +\
              eval_data_Rainbow_DQN_day22['hydro'] - battery_negative)
axs[0, 1].bar(T, -exported_2_grid, label = 'exported to grid',
              bottom = -battery_positive)

axs[0, 1].plot(T, eval_data_Rainbow_DQN_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 3.0, linestyle='solid')
axs[0, 1].legend(loc='best', ncol=2, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

axs[0, 1].set_title('Outputs of Generating Units - Rainbow DQN Model', size=20, fontweight='bold')
axs[0, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[0, 1].tick_params(axis='y', rotation=0, labelsize=20)
#axs[1] = plt.gca()
for spine in axs[0, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 1].xaxis.grid(False)
axs[0, 1].yaxis.grid(False)

# Plot Generation By Baseline Optimal Solution
axs[1, 0].cla()
axs[1, 0].set_facecolor("white")
axs[1, 0].spines[['top', 'right']].set_visible(False)
axs[1, 0].set_ylabel('Power (MW)', size=25, fontweight='bold')
axs[1, 0].set_xlabel('Time (h)', size=25, fontweight='bold')
battery_positive = np.array(base_result_Day22['battery_energy_change'])
battery_negative = np.array(base_result_Day22['battery_energy_change'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.array(base_result_Day22['grid_import'])
exported_2_grid = np.array(base_result_Day22['grid_export'])

axs[1, 0].bar(T, base_result_Day22['ccgt'], label='CCGT')
axs[1, 0].bar(T, base_result_Day22['coal'], label='COAL',
              bottom = base_result_Day22['ccgt'])
axs[1, 0].bar(T, base_result_Day22['biomass'], label='BIOMASS',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'])
axs[1, 0].bar(T, base_result_Day22['nuclear'], label='NUCLEAR',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'] +\
              base_result_Day22['biomass'])
axs[1, 0].bar(T, base_result_Day22['hydro'], label='HYDRO',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'] +\
              base_result_Day22['biomass'] + base_result_Day22['nuclear'])

axs[1, 0].bar(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[1, 0].bar(T, -battery_negative, label = 'battery discharge', hatch='/',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'] +\
              base_result_Day22['biomass'] + base_result_Day22['nuclear'] +\
              base_result_Day22['hydro'])
axs[1, 0].bar(T, -imported_from_grid, label = 'imported from grid',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'] +\
              base_result_Day22['biomass'] + base_result_Day22['nuclear'] +\
              base_result_Day22['hydro'] - battery_negative)
axs[1, 0].bar(T, -exported_2_grid, label = 'exported to grid',
              bottom = -battery_positive)

axs[1, 0].plot(T, base_result_Day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs[1, 0].legend(loc='best', ncol=2, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

axs[1, 0].set_title('Outputs of Generating Units - Optimal Solution Model', size=20, fontweight='bold')
axs[1, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[1, 0].tick_params(axis='y', rotation=0, labelsize=20)
#axs[1] = plt.gca()
for spine in axs[1, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 0].xaxis.grid(False)
axs[1, 0].yaxis.grid(False)

# plot energy charge/discharge with price in ax[3].
axs[1, 1].cla()
axs[1, 1].set_facecolor("white")
axs[1, 1].spines[['top', 'right']].set_visible(False)
axs[1, 1].set_ylabel('Price (£/MWh)', size=25, fontweight='bold')
axs[1, 1].set_xlabel('Time (h)', size=25, fontweight='bold')

axs[1, 1].plot(T, eval_data_Rainbow_DQN_day22['price'], drawstyle='steps-mid', label='Price',
               color = 'red', linewidth = 4.0, linestyle='solid')
axs[1, 1].legend(loc='best', ncol=1, frameon=True, fontsize='12',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)
axs_soc = axs[1, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=25, fontweight='bold')
axs_soc.plot(T, eval_data_Rainbow_DQN_day22['soc'], drawstyle='steps-mid', label='SOC',
               color = 'grey', linewidth = 4.0, linestyle='solid')
axs_soc.plot(T, base_result_Day22['soc'], drawstyle='steps-mid', label='SOC-Baseline',
               color = 'sienna', linewidth = 4.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[1, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=1, frameon=True, fontsize='14',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

axs[1, 1].set_title('Energy Charge/Discharge With Price', size=25, fontweight='bold')
axs[1, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[1, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[1, 1] = plt.gca()
for spine in axs[1, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 1].xaxis.grid(False)
axs[1, 1].yaxis.grid(False)

# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Proposed_Model_Rainbow_DQN_Performance_During_Testing.png')
plt.tight_layout()
plt.show()

"""**HOURLY OPERATION COST COMPARISON AMONG ALL MODELS**"""

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (22, 20)
fig, axs = plt.subplots(2, 1)
plt.subplots_adjust(wspace=0.6, hspace=0.4)
plt.autoscale(tight=True)

T = np.array([i for i in range(24)])
# plot Netload and Price at first
axs[0].cla()
axs[0].set_facecolor("white")
axs[0].spines[['top', 'right']].set_visible(False)
axs[0].set_ylabel('Netload (MW)', size=35, fontweight='bold')
axs[0].set_xlabel('Time (h)', size=35, fontweight='bold')
axs[0].bar(T, eval_data_DQN_2_day22['netload'], label='Netload',
            color='orange', linewidth = 2.0, align = 'center', width = 0.4)
axs_netload = axs[0].twinx()
axs_netload.set_facecolor("white")
axs_netload.spines[['top', 'right']].set_visible(False)
axs_netload.set_ylabel('Price (£/MWh)', size=35, fontweight='bold')
axs_netload.tick_params(axis='y', rotation=0, labelsize=25)
axs_netload.plot(T, eval_data_DQN_2_day22['price'], label='Price',
             color = 'navy', linewidth = 6.0, linestyle='solid', drawstyle = 'steps-mid')

# Combine legends from both Axes
lines, labels = axs[0].get_legend_handles_labels()
lines_netload, labels_netload = axs_netload.get_legend_handles_labels()
axs[0].legend(lines + lines_netload, labels + labels_netload,
              loc='best', ncol=1, frameon=True, fontsize='20',
        fancybox=True, framealpha=1, shadow=True, borderpad=2, labelspacing=0.3)
axs[0].set_title('Netload and Price', size=35, fontweight='bold')
axs[0].tick_params(axis='x', rotation=30, labelsize=25)
axs[0].tick_params(axis='y', rotation=0, labelsize=25)
axs[0] = plt.gca()
for spine in axs[0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0].xaxis.grid(False)
axs[0].yaxis.grid(True)

# plot Model's Operation Cost here
axs[1].cla()
axs[1].set_facecolor("white")
axs[1].spines[['top', 'right']].set_visible(False)
axs[1].set_ylabel('Operation Cost (£)', size=35, fontweight='bold')
axs[1].set_xlabel('Time (h)', size=35, fontweight='bold')

axs[1].plot(T, eval_data_DQN_2_day22['operation_cost'], label='DQN',
            alpha=1.0, linewidth = 5.0, color = 'gold')
axs[1].plot(T, eval_data_Rainbow_DQN_day22['operation_cost'], label='Rainbow-DQN',
            alpha=1.0, linewidth = 5.0, color = 'olive', drawstyle = 'steps-mid')
axs[1].plot(T, eval_data_DQN_NStep_Learning_day22['operation_cost'], label='MS-DQN',
            alpha=1.0, linewidth = 5.0, color = 'peachpuff')
axs[1].plot(T, eval_data_Categorical_DQN_day22['operation_cost'], label='Categorical-DQN',
            alpha=1.0, linewidth = 5.0, color = 'peru')
axs[1].plot(T, eval_data_DQN_NoisyNet_day22['operation_cost'], label='NN-DQN',
            alpha=1.0, linewidth = 5.0, color = 'darkseagreen')
axs[1].plot(T, eval_data_DQN_DuelingNet_day22['operation_cost'], label='Duel-DQN',
            alpha=1.0, linewidth = 5.0, color = 'dodgerblue')
axs[1].plot(T, eval_data_DQN_PER_day22['operation_cost'], label='PER-DQN',
            alpha=1.0, linewidth = 5.0, color = 'darkorange')
axs[1].plot(T, eval_data_DDQN_day22['operation_cost'], label='DDQN',
            alpha=1.0, linewidth = 5.0, color = 'black', linestyle='-')
axs[1].plot(T, base_result_Day22['step_cost'], label='MINLP-Baseline',
            alpha=1.0, linewidth = 5.0, color = 'navy', linestyle='--')

axs[1].set_title('Hourly Operation Cost',
                  size=35, fontweight='bold')
axs[1].tick_params(axis='x', rotation=30, labelsize=25)
axs[1].tick_params(axis='y', rotation=0, labelsize=25)
axs[1].legend(loc='best', ncol=3, frameon=True, fontsize='16',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)
for spine in axs[1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1].xaxis.grid(False)
axs[1].yaxis.grid(True)
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_OperationCost_During_Testing.png',
            format='svg', dpi=600, bbox_inches='tight')
plt.tight_layout()
plt.show()

"""**Cummulative Hourly Operation Cost for All Algorithms**"""

DQN_cum_epi_opcost = sum(eval_data_DQN_2_day22['operation_cost'])
DDQN_cum_epi_opcost = sum(eval_data_DDQN_day22['operation_cost'])
DQN_PER_cum_epi_opcost = sum(eval_data_DQN_PER_day22['operation_cost'])
DQN_DuelingNet_cum_epi_opcost = sum(eval_data_DQN_DuelingNet_day22['operation_cost'])
DQN_NoisyNet_cum_epi_opcost = sum(eval_data_DQN_NoisyNet_day22['operation_cost'])
Categorical_DQN_cum_epi_opcost = sum(eval_data_Categorical_DQN_day22['operation_cost'])
DQN_NStep_Learning_cum_epi_opcost = sum(eval_data_DQN_NStep_Learning_day22['operation_cost'])
Rainbow_DQN_cum_epi_opcost = sum(eval_data_Rainbow_DQN_day22['operation_cost'])
MINLP_Baseline = sum(base_result_Day22['step_cost'])
# Define the cumulative values

cumulative_op_costs = [
    DQN_cum_epi_opcost, DQN_PER_cum_epi_opcost, DDQN_cum_epi_opcost,
    DQN_DuelingNet_cum_epi_opcost, DQN_NoisyNet_cum_epi_opcost,
    Categorical_DQN_cum_epi_opcost,
    DQN_NStep_Learning_cum_epi_opcost,
    Rainbow_DQN_cum_epi_opcost, MINLP_Baseline,
]

# Define agent names
agent_names = [
    "DQN", "PER-DQN", "DDQN", "Duel-DQN", "NN-DQN",
    "Cat-DQN",
    "MS-DQN",
    "Rainbow-DQN", 'MINLP-Baseline'
]

bar_width = 0.4

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (20, 15)
plt.subplots_adjust(wspace=0.5, hspace=0.5)

# Plotting

plt.subplot(2, 2, 1)
plt.cla()
plt.gca().spines[['top', 'right']].set_visible(False)
bars = plt.bar(agent_names, cumulative_op_costs, color='orange',
               width=bar_width, label='Cumulative Operation Cost')
plt.xlabel('DRL Agent', size=35, fontweight='bold')
plt.ylabel('Cumulative Operation Cost (£)', size=30, fontweight='bold')
plt.xticks(rotation=45, ha='right', size=15, fontweight='bold')  # Rotate agent names for better readability
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')

plt.legend(loc="best", ncol=1, frameon=True, fontsize='18',
            fancybox=True, framealpha=1, shadow=True, borderpad=1)
ax2 = plt.gca()
for spine in ax2.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax2.xaxis.grid(False)
ax2.yaxis.grid(True)

# Draw line connecting the tops of the bars
max_values_op_costs = [bar.get_height() for bar in bars]
plt.plot(agent_names, max_values_op_costs, marker='o', color='k',
         linewidth=2.5, markersize=8)

plt.subplot(2, 2, 2)
plt.cla()
plt.gca().spines[['top', 'right']].set_visible(False)
plt.plot(agent_names, cumulative_op_costs, marker='o', color='k',
         linewidth=2.5, markersize=8, label='Cumulative Operation Cost')
plt.xlabel('DRL Agent', size=35, fontweight='bold')
plt.ylabel('Cumulative Operation Cost (£)', size=30, fontweight='bold')
plt.xticks(rotation=45, ha='right', size=15, fontweight='bold')  # Rotate agent names for better readability
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')

plt.legend(loc="best", ncol=1, frameon=True, fontsize='18',
            fancybox=True, framealpha=1, shadow=True, borderpad=1)

ax1 = plt.gca()
for spine in ax1.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax1.xaxis.grid(False)
ax1.yaxis.grid(True)

output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Cumulative_Operation_Cost_All_Models_2021.png')
plt.tight_layout()
plt.show()

print(cumulative_op_costs)

"""###**Scheduled BESS Energy Charge and Discharge Vs SOC For All Models Compared to the Baseline**"""

plt.rcParams["figure.figsize"] = (15, 15)
fig, axs = plt.subplots(4, 2)
plt.subplots_adjust(wspace=0.5, hspace=0.5)
plt.autoscale(tight=True)

T = np.array([i for i in range(24)])

# RainBow Vs Baseline
axs[0, 0].set_facecolor("white")
axs[0, 0].spines[['top', 'right']].set_visible(False)
axs[0, 0].cla()
axs[0, 0].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[0, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[0, 0].plot(T, eval_data_Rainbow_DQN_day22['battery1'], marker='*', linestyle='-',
         color='red', label='Rainbow-DQN', linewidth=3.5, markersize=8)
axs[0, 0].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[0, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_Rainbow_DQN_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[0, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[0, 0].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[0, 0].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[0, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[0, 0].tick_params(axis='y', rotation=0, labelsize=15)

axs[0, 0] = plt.gca()
for spine in axs[0, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 0].xaxis.grid(False)
axs[0, 0].yaxis.grid(False)

# DQN+NOISE Vs Baseline
axs[0, 1].set_facecolor("white")
axs[0, 1].spines[['top', 'right']].set_visible(False)
axs[0, 1].cla()
axs[0, 1].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[0, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[0, 1].plot(T, eval_data_DQN_NoisyNet_day22['battery1'], marker='*', linestyle='-',
         color='red', label='NN-DQN', linewidth=3.5, markersize=8)
axs[0, 1].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[0, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_NoisyNet_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[0, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[0, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[0, 1].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[0, 1].tick_params(axis='x', rotation=30, labelsize=15)
axs[0, 1].tick_params(axis='y', rotation=0, labelsize=15)

axs[0, 1] = plt.gca()
for spine in axs[0, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 1].xaxis.grid(False)
axs[0, 1].yaxis.grid(False)

# DQN+DUEL Vs Baseline
axs[1, 0].set_facecolor("white")
axs[1, 0].spines[['top', 'right']].set_visible(False)
axs[1, 0].cla()
axs[1, 0].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[1, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[1, 0].plot(T, eval_data_DQN_DuelingNet_day22['battery1'], marker='*', linestyle='-',
         color='red', label='Duel-DQN', linewidth=3.5, markersize=8)
axs[1, 0].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[1, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_DuelingNet_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[1, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 0].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[1, 0].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[1, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[1, 0].tick_params(axis='y', rotation=0, labelsize=15)

axs[1, 0] = plt.gca()
for spine in axs[1, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 0].xaxis.grid(False)
axs[1, 0].yaxis.grid(False)

# DDQN Vs Baseline
axs[1, 1].set_facecolor("white")
axs[1, 1].spines[['top', 'right']].set_visible(False)
axs[1, 1].cla()
axs[1, 1].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[1, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[1, 1].plot(T, eval_data_DDQN_day22['battery1'], marker='*', linestyle='-',
         color='red', label='DDQN', linewidth=3.5, markersize=8)
axs[1, 1].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[1, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DDQN_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[1, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[1, 1].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[1, 1].tick_params(axis='x', rotation=30, labelsize=15)
axs[1, 1].tick_params(axis='y', rotation=0, labelsize=15)

axs[1, 1] = plt.gca()
for spine in axs[1, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 1].xaxis.grid(False)
axs[1, 1].yaxis.grid(False)

# DQN+PER Vs Baseline
axs[2, 0].set_facecolor("white")
axs[2, 0].spines[['top', 'right']].set_visible(False)
axs[2, 0].cla()
axs[2, 0].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[2, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[2, 0].plot(T, eval_data_DQN_PER_day22['battery1'], marker='*', linestyle='-',
         color='red', label='PER-DQN', linewidth=3.5, markersize=8)
axs[2, 0].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[2, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_PER_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[2, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[2, 0].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[2, 0].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[2, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[2, 0].tick_params(axis='y', rotation=0, labelsize=15)

axs[2, 0] = plt.gca()
for spine in axs[2, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[2, 0].xaxis.grid(False)
axs[2, 0].yaxis.grid(False)

# DQN+NStep-Learning Vs Baseline
axs[2, 1].set_facecolor("white")
axs[2, 1].spines[['top', 'right']].set_visible(False)
axs[2, 1].cla()
axs[2, 1].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[2, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[2, 1].plot(T, eval_data_DQN_NStep_Learning_day22['battery1'], marker='*', linestyle='-',
         color='red', label='MS-DQN', linewidth=3.5, markersize=8)
axs[2, 1].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[2, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_NStep_Learning_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[2, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[2, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[2, 1].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[2, 1].tick_params(axis='x', rotation=30, labelsize=15)
axs[2, 1].tick_params(axis='y', rotation=0, labelsize=15)

axs[2, 1] = plt.gca()
for spine in axs[2, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[2, 1].xaxis.grid(False)
axs[2, 1].yaxis.grid(False)

# DQN Vs Baseline
axs[3, 0].set_facecolor("white")
axs[3, 0].spines[['top', 'right']].set_visible(False)
axs[3, 0].cla()
axs[3, 0].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[3, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[3, 0].plot(T, eval_data_DQN_2_day22['battery1'], marker='*', linestyle='-',
         color='red', label='DQN', linewidth=3.5, markersize=8)
axs[3, 0].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[3, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_2_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[3, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[3, 0].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[3, 0].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[3, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[3, 0].tick_params(axis='y', rotation=0, labelsize=15)

axs[3, 0] = plt.gca()
for spine in axs[3, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[3, 0].xaxis.grid(False)
axs[3, 0].yaxis.grid(False)

# CategoricalDQN Vs Baseline
axs[3, 1].set_facecolor("white")
axs[3, 1].spines[['top', 'right']].set_visible(False)
axs[3, 1].cla()
axs[3, 1].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[3, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[3, 1].plot(T, eval_data_Categorical_DQN_day22['battery1'], marker='*', linestyle='-',
         color='red', label='Categorical-DQN', linewidth=3.5, markersize=8)
axs[3, 1].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[3, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_Categorical_DQN_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[3, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[3, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[3, 1].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[3, 1].tick_params(axis='x', rotation=30, labelsize=15)
axs[3, 1].tick_params(axis='y', rotation=0, labelsize=15)

axs[3, 1] = plt.gca()
for spine in axs[3, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[3, 1].xaxis.grid(False)
axs[3, 1].yaxis.grid(False)

# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_BESS_Change_VS_SOC_During_Testing.png')
plt.tight_layout()
plt.show()

plt.rcParams["figure.figsize"] = (15, 15)
fig, axs = plt.subplots(4, 2)
plt.subplots_adjust(wspace=0.8, hspace=0.8)
plt.autoscale(tight=True)

T = np.array([i for i in range(24)])

# RainBow
axs[0, 0].set_facecolor("white")
axs[0, 0].spines[['top', 'right']].set_visible(False)
axs[0, 0].cla()
axs[0, 0].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[0, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_Rainbow_DQN_day22['battery1'])
battery_negative = np.array(eval_data_Rainbow_DQN_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_Rainbow_DQN_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_Rainbow_DQN_day22['unbalance']), 0)

axs[0, 0].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple', alpha=0.3)
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'] +\
              eval_data_Rainbow_DQN_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'] +\
              eval_data_Rainbow_DQN_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[0, 0].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'],
                       eval_data_Rainbow_DQN_day22['hydro'], label='HYDRO', color='green')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'],
                       eval_data_Rainbow_DQN_day22['nuclear'], label='NUCLEAR', color='red')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'],
                       eval_data_Rainbow_DQN_day22['biomass'], label='BIOMASS', color='violet')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'], eval_data_Rainbow_DQN_day22['coal'],
                       label='COAL', color='seagreen')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'], label='CCGT', color='gray')
axs[0, 0].plot(T, eval_data_Rainbow_DQN_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[0, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_Rainbow_DQN_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[0, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[0, 0].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[0, 0].set_xticks([])
axs[0, 0].set_title('Rainbow DQN',
                    size=20, fontweight='bold')
#axs[0, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[0, 0].tick_params(axis='y', rotation=0, labelsize=20)
axs[0, 0] = plt.gca()
for spine in axs[0, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 0].xaxis.grid(False)
axs[0, 0].yaxis.grid(False)

# DQN+NOISE
axs[0, 1].set_facecolor("white")
axs[0, 1].spines[['top', 'right']].set_visible(False)
axs[0, 1].cla()
axs[0, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[0, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_NoisyNet_day22['battery1'])
battery_negative = np.array(eval_data_DQN_NoisyNet_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_NoisyNet_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_NoisyNet_day22['unbalance']), 0)

axs[0, 1].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'] +\
              eval_data_DQN_NoisyNet_day22['biomass'] + eval_data_DQN_NoisyNet_day22['nuclear'] +\
              eval_data_DQN_NoisyNet_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'] +\
              eval_data_DQN_NoisyNet_day22['biomass'] + eval_data_DQN_NoisyNet_day22['nuclear'] +\
              eval_data_DQN_NoisyNet_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[0, 1].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'] +\
              eval_data_DQN_NoisyNet_day22['biomass'] + eval_data_DQN_NoisyNet_day22['nuclear'],
                       eval_data_DQN_NoisyNet_day22['hydro'], label='HYDRO', color='green')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'] +\
              eval_data_DQN_NoisyNet_day22['biomass'],
                       eval_data_DQN_NoisyNet_day22['nuclear'], label='NUCLEAR', color='red')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'],
                       eval_data_DQN_NoisyNet_day22['biomass'], label='BIOMASS', color='violet')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'], eval_data_DQN_NoisyNet_day22['coal'],
                       label='COAL', color='seagreen')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'], label='CCGT', color='gray')
axs[0, 1].plot(T, eval_data_DQN_NoisyNet_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[0, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_NoisyNet_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[0, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[0, 1].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[0, 1].set_xticks([])
axs[0, 1].set_title('NN-DQN', size=20,
                    fontweight='bold')
#axs[0, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[0, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[0, 1] = plt.gca()
for spine in axs[0, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 1].xaxis.grid(False)
axs[0, 1].yaxis.grid(False)

# DQN+DUEL eval_data_DQN_DuelingNet_day22
axs[1, 0].set_facecolor("white")
axs[1, 0].spines[['top', 'right']].set_visible(False)
axs[1, 0].cla()
axs[1, 0].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[1, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_DuelingNet_day22['battery1'])
battery_negative = np.array(eval_data_DQN_DuelingNet_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_DuelingNet_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_DuelingNet_day22['unbalance']), 0)

axs[1, 0].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'] +\
              eval_data_DQN_DuelingNet_day22['biomass'] + eval_data_DQN_DuelingNet_day22['nuclear'] +\
              eval_data_DQN_DuelingNet_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'] +\
              eval_data_DQN_DuelingNet_day22['biomass'] + eval_data_DQN_DuelingNet_day22['nuclear'] +\
              eval_data_DQN_DuelingNet_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[1, 0].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'] +\
              eval_data_DQN_DuelingNet_day22['biomass'] + eval_data_DQN_DuelingNet_day22['nuclear'],
                       eval_data_DQN_DuelingNet_day22['hydro'], label='HYDRO', color='green')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'] +\
              eval_data_DQN_DuelingNet_day22['biomass'],
                       eval_data_DQN_DuelingNet_day22['nuclear'], label='NUCLEAR', color='red')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'],
                       eval_data_DQN_DuelingNet_day22['biomass'], label='BIOMASS', color='violet')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'], eval_data_DQN_DuelingNet_day22['coal'],
                       label='COAL', color='seagreen')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'], label='CCGT', color='gray')
axs[1, 0].plot(T, eval_data_DQN_DuelingNet_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[1, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_DuelingNet_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[1, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 0].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[1, 0].set_xticks([])
axs[1, 0].set_title('Duel-DQN', size=20,
                    fontweight='bold', y = 0.9)
#axs[1, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[1, 0].tick_params(axis='y', rotation=0, labelsize=20)
axs[1, 0] = plt.gca()
for spine in axs[1, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 0].xaxis.grid(False)
axs[1, 0].yaxis.grid(False)

# DDQN
axs[1, 1].set_facecolor("white")
axs[1, 1].spines[['top', 'right']].set_visible(False)
axs[1, 1].cla()
axs[1, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[1, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DDQN_day22['battery1'])
battery_negative = np.array(eval_data_DDQN_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DDQN_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DDQN_day22['unbalance']), 0)

axs[1, 1].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'] +\
              eval_data_DDQN_day22['biomass'] + eval_data_DDQN_day22['nuclear'] +\
              eval_data_DDQN_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'] +\
              eval_data_DDQN_day22['biomass'] + eval_data_DDQN_day22['nuclear'] +\
              eval_data_DDQN_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[1, 1].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'] +\
              eval_data_DDQN_day22['biomass'] + eval_data_DDQN_day22['nuclear'],
                       eval_data_DDQN_day22['hydro'], label='HYDRO', color='green')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'] +\
              eval_data_DDQN_day22['biomass'],
                       eval_data_DDQN_day22['nuclear'], label='NUCLEAR', color='red')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'],
                       eval_data_DDQN_day22['biomass'], label='BIOMASS', color='violet')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'], eval_data_DDQN_day22['coal'],
                       label='COAL', color='seagreen')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'], label='CCGT', color='gray')
axs[1, 1].plot(T, eval_data_DDQN_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[1, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DDQN_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[1, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 1].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[1, 1].set_xticks([])
axs[1, 1].set_title('DDQN', size=20,
                    fontweight='bold', y = 0.9)
#axs[1, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[1, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[1, 1] = plt.gca()
for spine in axs[1, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 1].xaxis.grid(False)
axs[1, 1].yaxis.grid(False)

# DQN+PER
axs[2, 0].set_facecolor("white")
axs[2, 0].spines[['top', 'right']].set_visible(False)
axs[2, 0].cla()
axs[2, 0].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[2, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_PER_day22['battery1'])
battery_negative = np.array(eval_data_DQN_PER_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_PER_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_PER_day22['unbalance']), 0)

axs[2, 0].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'] +\
              eval_data_DQN_PER_day22['biomass'] + eval_data_DQN_PER_day22['nuclear'] +\
              eval_data_DQN_PER_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'] +\
              eval_data_DQN_PER_day22['biomass'] + eval_data_DQN_PER_day22['nuclear'] +\
              eval_data_DQN_PER_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[2, 0].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'] +\
              eval_data_DQN_PER_day22['biomass'] + eval_data_DQN_PER_day22['nuclear'],
                       eval_data_DQN_PER_day22['hydro'], label='HYDRO', color='green')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'] +\
              eval_data_DQN_PER_day22['biomass'],
                       eval_data_DQN_PER_day22['nuclear'], label='NUCLEAR', color='red')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'],
                       eval_data_DQN_PER_day22['biomass'], label='BIOMASS', color='violet')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'], eval_data_DQN_PER_day22['coal'],
                       label='COAL', color='seagreen')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'], label='CCGT', color='gray')
axs[2, 0].plot(T, eval_data_DQN_PER_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[2, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_PER_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[2, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[2, 0].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[2, 0].set_xticks([])
axs[2, 0].set_title('PER-DQN', size=20,
                    fontweight='bold', y = 0.9)
#axs[2, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[2, 0].tick_params(axis='y', rotation=0, labelsize=20)
axs[2, 0] = plt.gca()
for spine in axs[2, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[2, 0].xaxis.grid(False)
axs[2, 0].yaxis.grid(False)

# DQN+NStep-Learning
axs[2, 1].set_facecolor("white")
axs[2, 1].spines[['top', 'right']].set_visible(False)
axs[2, 1].cla()
axs[2, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[2, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_NStep_Learning_day22['battery1'])
battery_negative = np.array(eval_data_DQN_NStep_Learning_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_NStep_Learning_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_NStep_Learning_day22['unbalance']), 0)

axs[2, 1].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'] +\
              eval_data_DQN_NStep_Learning_day22['biomass'] + eval_data_DQN_NStep_Learning_day22['nuclear'] +\
              eval_data_DQN_NStep_Learning_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'] +\
              eval_data_DQN_NStep_Learning_day22['biomass'] + eval_data_DQN_NStep_Learning_day22['nuclear'] +\
              eval_data_DQN_NStep_Learning_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[2, 1].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'] +\
              eval_data_DQN_NStep_Learning_day22['biomass'] + eval_data_DQN_NStep_Learning_day22['nuclear'],
                       eval_data_DQN_NStep_Learning_day22['hydro'], label='HYDRO', color='green')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'] +\
              eval_data_DQN_NStep_Learning_day22['biomass'],
                       eval_data_DQN_NStep_Learning_day22['nuclear'], label='NUCLEAR', color='red')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'],
                       eval_data_DQN_NStep_Learning_day22['biomass'], label='BIOMASS', color='violet')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'], eval_data_DQN_NStep_Learning_day22['coal'],
                       label='COAL', color='seagreen')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'], label='CCGT', color='gray')
axs[2, 1].plot(T, eval_data_DQN_NStep_Learning_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[2, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_NStep_Learning_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[2, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[2, 1].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[2, 1].set_xticks([])
axs[2, 1].set_title('MS-DQN', size=20,
                    fontweight='bold', y = 0.9)
#axs[2, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[2, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[2, 1] = plt.gca()
for spine in axs[2, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[2, 1].xaxis.grid(False)
axs[2, 1].yaxis.grid(False)

# DQN
axs[3, 0].set_facecolor("white")
axs[3, 0].spines[['top', 'right']].set_visible(False)
axs[3, 0].cla()
axs[3, 0].set_ylabel('Power (MW)', size=20, fontweight='bold')
axs[3, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_2_day22['battery1'])
battery_negative = np.array(eval_data_DQN_2_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_2_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_2_day22['unbalance']), 0)

axs[3, 0].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'] +\
              eval_data_DQN_2_day22['biomass'] + eval_data_DQN_2_day22['nuclear'] +\
              eval_data_DQN_2_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'] +\
              eval_data_DQN_2_day22['biomass'] + eval_data_DQN_2_day22['nuclear'] +\
              eval_data_DQN_2_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[3, 0].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'] +\
              eval_data_DQN_2_day22['biomass'] + eval_data_DQN_2_day22['nuclear'],
                       eval_data_DQN_2_day22['hydro'], label='HYDRO', color='green')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'] +\
              eval_data_DQN_2_day22['biomass'],
                       eval_data_DQN_2_day22['nuclear'], label='NUCLEAR', color='red')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'],
                       eval_data_DQN_2_day22['biomass'], label='BIOMASS', color='violet')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'], eval_data_DQN_2_day22['coal'],
                       label='COAL', color='seagreen')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'], label='CCGT', color='gray')
axs[3, 0].plot(T, eval_data_DQN_2_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[3, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_2_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[3, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[3, 0].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.46), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)

axs[3, 0].set_title('DQN', size=20,
                    fontweight='bold', y = 0.9)
axs[3, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[3, 0].tick_params(axis='y', rotation=0, labelsize=20)
axs[3, 0] = plt.gca()
for spine in axs[3, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[3, 0].xaxis.grid(False)
axs[3, 0].yaxis.grid(False)

# CategoricalDQN
axs[3, 1].set_facecolor("white")
axs[3, 1].spines[['top', 'right']].set_visible(False)
axs[3, 1].cla()
axs[3, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
axs[3, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_Categorical_DQN_day22['battery1'])
battery_negative = np.array(eval_data_Categorical_DQN_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_Categorical_DQN_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_Categorical_DQN_day22['unbalance']), 0)

axs[3, 1].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'] +\
              eval_data_Categorical_DQN_day22['biomass'] + eval_data_Categorical_DQN_day22['nuclear'] +\
              eval_data_Categorical_DQN_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'] +\
              eval_data_Categorical_DQN_day22['biomass'] + eval_data_Categorical_DQN_day22['nuclear'] +\
              eval_data_Categorical_DQN_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[3, 1].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'] +\
              eval_data_Categorical_DQN_day22['biomass'] + eval_data_Categorical_DQN_day22['nuclear'],
                       eval_data_Categorical_DQN_day22['hydro'], label='HYDRO', color='green')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'] +\
              eval_data_Categorical_DQN_day22['biomass'],
                       eval_data_Categorical_DQN_day22['nuclear'], label='NUCLEAR', color='red')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'],
                       eval_data_Categorical_DQN_day22['biomass'], label='BIOMASS', color='violet')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'], eval_data_Categorical_DQN_day22['coal'],
                       label='COAL', color='seagreen')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'], label='CCGT', color='gray')
axs[3, 1].plot(T, eval_data_Categorical_DQN_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[3, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_Categorical_DQN_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[3, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[3, 1].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.46), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)

axs[3, 1].set_title('Categorical-DQN', size=20,
                    fontweight='bold', y = 0.9)
axs[3, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[3, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[3, 1] = plt.gca()
for spine in axs[3, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[3, 1].xaxis.grid(False)
axs[3, 1].yaxis.grid(False)

# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Operational_Scheduling_Management_of_all_Models_During_Testing.png')
plt.tight_layout()
plt.show()

"""**Cummulative Operation Cost Savings Relative to The Baseline Network - DQN**"""

# Day 22
dqn22 = eval_data_DQN_2_day22['operation_cost']
rainbow22 = eval_data_Rainbow_DQN_day22['operation_cost']
dqn_nstep22 = eval_data_DQN_NStep_Learning_day22['operation_cost']
categorical_dqn22 = eval_data_Categorical_DQN_day22['operation_cost']
dqn_noise22 = eval_data_DQN_NoisyNet_day22['operation_cost']
dqn_duel22 = eval_data_DQN_DuelingNet_day22['operation_cost']
dqn_per22 = eval_data_DQN_PER_day22['operation_cost']
ddqn22 = eval_data_DDQN_day22['operation_cost']
minlp22 = base_result_Day22['step_cost']
# Day 23
dqn23 = eval_data_DQN_2_day23['operation_cost']
rainbow23 = eval_data_Rainbow_DQN_day23['operation_cost']
dqn_nstep23 = eval_data_DQN_NStep_Learning_day23['operation_cost']
categorical_dqn23 = eval_data_Categorical_DQN_day23['operation_cost']
dqn_noise23 = eval_data_DQN_NoisyNet_day23['operation_cost']
dqn_duel23 = eval_data_DQN_DuelingNet_day23['operation_cost']
dqn_per23 = eval_data_DQN_PER_day23['operation_cost']
ddqn23 = eval_data_DDQN_day23['operation_cost']
minlp23 = base_result_Day23['step_cost']
# Day 24
dqn24 = eval_data_DQN_2_day24['operation_cost']
rainbow24 = eval_data_Rainbow_DQN_day24['operation_cost']
dqn_nstep24 = eval_data_DQN_NStep_Learning_day24['operation_cost']
categorical_dqn24 = eval_data_Categorical_DQN_day24['operation_cost']
dqn_noise24 = eval_data_DQN_NoisyNet_day24['operation_cost']
dqn_duel24 = eval_data_DQN_DuelingNet_day24['operation_cost']
dqn_per24 = eval_data_DQN_PER_day24['operation_cost']
ddqn24 = eval_data_DDQN_day24['operation_cost']
minlp24 = base_result_Day24['step_cost']
# Day 25
dqn25 = eval_data_DQN_2_day25['operation_cost']
rainbow25 = eval_data_Rainbow_DQN_day25['operation_cost']
dqn_nstep25 = eval_data_DQN_NStep_Learning_day25['operation_cost']
categorical_dqn25 = eval_data_Categorical_DQN_day25['operation_cost']
dqn_noise25 = eval_data_DQN_NoisyNet_day25['operation_cost']
dqn_duel25 = eval_data_DQN_DuelingNet_day25['operation_cost']
dqn_per25 = eval_data_DQN_PER_day25['operation_cost']
ddqn25 = eval_data_DDQN_day25['operation_cost']
minlp25 = base_result_Day25['step_cost']
# Day 26
dqn26 = eval_data_DQN_2_day26['operation_cost']
rainbow26 = eval_data_Rainbow_DQN_day26['operation_cost']
dqn_nstep26 = eval_data_DQN_NStep_Learning_day26['operation_cost']
categorical_dqn26 = eval_data_Categorical_DQN_day26['operation_cost']
dqn_noise26 = eval_data_DQN_NoisyNet_day26['operation_cost']
dqn_duel26 = eval_data_DQN_DuelingNet_day26['operation_cost']
dqn_per26 = eval_data_DQN_PER_day26['operation_cost']
ddqn26 = eval_data_DDQN_day26['operation_cost']
minlp26 = base_result_Day26['step_cost']
# Day 27
dqn27 = eval_data_DQN_2_day27['operation_cost']
rainbow27 = eval_data_Rainbow_DQN_day27['operation_cost']
dqn_nstep27 = eval_data_DQN_NStep_Learning_day27['operation_cost']
categorical_dqn27 = eval_data_Categorical_DQN_day27['operation_cost']
dqn_noise27 = eval_data_DQN_NoisyNet_day27['operation_cost']
dqn_duel27 = eval_data_DQN_DuelingNet_day27['operation_cost']
dqn_per27 = eval_data_DQN_PER_day27['operation_cost']
ddqn27 = eval_data_DDQN_day27['operation_cost']
minlp27 = base_result_Day27['step_cost']
# Day 28
dqn28 = eval_data_DQN_2_day28['operation_cost']
rainbow28 = eval_data_Rainbow_DQN_day28['operation_cost']
dqn_nstep28 = eval_data_DQN_NStep_Learning_day28['operation_cost']
categorical_dqn28 = eval_data_Categorical_DQN_day28['operation_cost']
dqn_noise28 = eval_data_DQN_NoisyNet_day28['operation_cost']
dqn_duel28 = eval_data_DQN_DuelingNet_day28['operation_cost']
dqn_per28 = eval_data_DQN_PER_day28['operation_cost']
ddqn28 = eval_data_DDQN_day28['operation_cost']
minlp28 = base_result_Day28['step_cost']

# concatenate
dqn = pd.concat([dqn22, dqn23, dqn24, dqn25, dqn26, dqn27, dqn28], axis=0)
rainbow = pd.concat([rainbow22, rainbow23, rainbow24, rainbow25, rainbow26, rainbow27, rainbow28],
                    axis=0)
dqn_nstep = pd.concat([dqn_nstep22, dqn_nstep23, dqn_nstep24, dqn_nstep25, dqn_nstep26, dqn_nstep27, dqn_nstep28],
                      axis=0)
categorical_dqn = pd.concat([categorical_dqn22, categorical_dqn23, categorical_dqn24, categorical_dqn25,
                             categorical_dqn26, categorical_dqn27, categorical_dqn28],
                             axis=0)
dqn_noise = pd.concat([dqn_noise22, dqn_noise23, dqn_noise24, dqn_noise25, dqn_noise26,
                       dqn_noise27, dqn_noise28], axis=0)
dqn_duel = pd.concat([dqn_duel22, dqn_duel23, dqn_duel24, dqn_duel25, dqn_duel26,
                      dqn_duel27, dqn_duel28], axis=0)
dqn_per = pd.concat([dqn_per22, dqn_per23, dqn_per24, dqn_per25, dqn_per26,
                     dqn_per27, dqn_per28], axis=0)
ddqn = pd.concat([ddqn22, ddqn23, ddqn24, ddqn25, ddqn26, ddqn27, ddqn28], axis=0)
minlp = pd.concat([minlp22, minlp23, minlp24, minlp25, minlp26, minlp27,
                   minlp28], axis=0)

# Operation Cost Savings
dqn_savings = dqn - dqn
rainbow_savings = dqn - rainbow
dqn_nstep_savings = dqn - dqn_nstep
categorical_dqn_savings = dqn - categorical_dqn
dqn_noise_savings = dqn - dqn_noise
dqn_duel_savings = dqn - dqn_duel
dqn_per_savings = dqn - dqn_per
ddqn_savings = dqn - ddqn
minlp_savings = dqn - minlp

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (22, 20)
fig, axs = plt.subplots(1, 1)
plt.subplots_adjust(wspace=0.6, hspace=0.4)
plt.autoscale(tight=True)

T = np.array([i for i in range(168)])

axs.set_facecolor("white")
axs.spines[['top', 'right']].set_visible(False)
axs.cla()
axs.set_ylabel('Operation Cost Savings (£)', size=35, fontweight='bold')
axs.set_xlabel('Time (h)', size=35, fontweight='bold')

axs.plot(T, rainbow_savings, label='Rainbow-DQN',
            alpha=1.0, linewidth = 5.0, color = 'olive', drawstyle = 'steps-mid')
axs.plot(T, dqn_nstep_savings, label='MS-DQN',
            alpha=1.0, linewidth = 5.0, color = 'peachpuff', drawstyle = 'steps-mid')
axs.plot(T, categorical_dqn_savings, label='Categorical-DQN',
            alpha=1.0, linewidth = 5.0, color = 'peru', drawstyle = 'steps-mid')
axs.plot(T, dqn_noise_savings, label='NN-DQN',
            alpha=1.0, linewidth = 5.0, color = 'darkseagreen', drawstyle = 'steps-mid')
axs.plot(T, dqn_duel_savings, label='Duel-DQN',
            alpha=1.0, linewidth = 5.0, color = 'dodgerblue', drawstyle = 'steps-mid')
axs.plot(T, dqn_per_savings, label='PER-DQN',
            alpha=1.0, linewidth = 5.0, color = 'darkorange', drawstyle = 'steps-mid')
axs.plot(T, ddqn_savings, label='DDQN',
            alpha=1.0, linewidth = 5.0, color = 'navy', linestyle='-', drawstyle = 'steps-mid')
axs.plot(T, minlp_savings, label='MINLP-Baseline',
            alpha=1.0, linewidth = 5.0, color = 'gold', linestyle='-', drawstyle = 'steps-mid')
axs.plot(T, dqn_savings, label='DQN',
            alpha=1.0, linewidth = 7.0, color = 'black', linestyle='-.', drawstyle = 'steps-mid')

axs.tick_params(axis='x', rotation=30, labelsize=25)
axs.tick_params(axis='y', rotation=0, labelsize=25)
axs.legend(loc='best', ncol=3, frameon=True, fontsize='18',
        fancybox=True, framealpha=1, shadow=True, borderpad=2, labelspacing=0.3)
axs = plt.gca()
for spine in axs.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs.xaxis.grid(False)
axs.yaxis.grid(False)
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_OperationCost_Savings_During_Testing.png',
            format='svg', dpi=600, bbox_inches='tight')
plt.tight_layout()
plt.show()

"""**Compute All Algorithm's Ability to Utilize RES - Total Consumption Rate of RES**

Larger is better!
"""

DQN_cum_pv = sum(eval_data_DQN_2_day22['pv'])
DDQN_cum_pv = sum(eval_data_DDQN_day22['pv'])
DQN_PER_cum_pv = sum(eval_data_DQN_PER_day22['pv'])
DQN_DuelingNet_cum_pv = sum(eval_data_DQN_DuelingNet_day22['pv'])
DQN_NoisyNet_cum_pv = sum(eval_data_DQN_NoisyNet_day22['pv'])
Categorical_DQN_cum_pv = sum(eval_data_Categorical_DQN_day22['pv'])
DQN_NStep_Learning_cum_pv = sum(eval_data_DQN_NStep_Learning_day22['pv'])
Rainbow_DQN_cum_pv = sum(eval_data_Rainbow_DQN_day22['pv'])
MINLP_Baseline_pv = sum(base_result_Day22['pv'])

DQN_cum_onwind = sum(eval_data_DQN_2_day22['onwind'])
DDQN_cum_onwind = sum(eval_data_DDQN_day22['onwind'])
DQN_PER_cum_onwind = sum(eval_data_DQN_PER_day22['onwind'])
DQN_DuelingNet_cum_onwind = sum(eval_data_DQN_DuelingNet_day22['onwind'])
DQN_NoisyNet_cum_onwind = sum(eval_data_DQN_NoisyNet_day22['onwind'])
Categorical_DQN_cum_onwind = sum(eval_data_Categorical_DQN_day22['onwind'])
DQN_NStep_Learning_cum_onwind = sum(eval_data_DQN_NStep_Learning_day22['onwind'])
Rainbow_DQN_cum_onwind = sum(eval_data_Rainbow_DQN_day22['onwind'])
MINLP_Baseline_onwind = sum(base_result_Day22['wind'])

DQN_cum_offwind = sum(eval_data_DQN_2_day22['offwind'])
DDQN_cum_offwind = sum(eval_data_DDQN_day22['offwind'])
DQN_PER_cum_offwind = sum(eval_data_DQN_PER_day22['offwind'])
DQN_DuelingNet_cum_offwind = sum(eval_data_DQN_DuelingNet_day22['offwind'])
DQN_NoisyNet_cum_offwind = sum(eval_data_DQN_NoisyNet_day22['offwind'])
Categorical_DQN_cum_offwind = sum(eval_data_Categorical_DQN_day22['offwind'])
DQN_NStep_Learning_cum_offwind = sum(eval_data_DQN_NStep_Learning_day22['offwind'])
Rainbow_DQN_cum_offwind = sum(eval_data_Rainbow_DQN_day22['offwind'])
MINLP_Baseline_offwind = sum(base_result_Day22['offwind'])

DQN_RESComsumptionRate = (DQN_cum_pv + DQN_cum_onwind + DQN_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DDQN_RESComsumptionRate = (DDQN_cum_pv + DDQN_cum_onwind + DDQN_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DQN_PER_RESComsumptionRate = (DQN_PER_cum_pv + DQN_PER_cum_onwind + DQN_PER_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DQN_DuelingNet_RESComsumptionRate = (DQN_DuelingNet_cum_pv + DQN_DuelingNet_cum_onwind + DQN_DuelingNet_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DQN_NoisyNet_RESComsumptionRate = (DQN_NoisyNet_cum_pv + DQN_NoisyNet_cum_onwind + DQN_NoisyNet_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
Categorical_DQN_RESComsumptionRate = (Categorical_DQN_cum_pv + Categorical_DQN_cum_onwind + Categorical_DQN_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DQN_NStep_Learning_RESComsumptionRate = (DQN_NStep_Learning_cum_pv + DQN_NStep_Learning_cum_onwind + DQN_NStep_Learning_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
Rainbow_DQN_RESComsumptionRate = (Rainbow_DQN_cum_pv + Rainbow_DQN_cum_onwind + Rainbow_DQN_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
MINLP_Baseline_RESComsumptionRate = (MINLP_Baseline_pv + MINLP_Baseline_onwind + MINLP_Baseline_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)

RESComsumptionRate = [
    DQN_RESComsumptionRate, DQN_PER_RESComsumptionRate, DDQN_RESComsumptionRate,
    DQN_DuelingNet_RESComsumptionRate, DQN_NoisyNet_RESComsumptionRate,
    Categorical_DQN_RESComsumptionRate,
    DQN_NStep_Learning_RESComsumptionRate,
    Rainbow_DQN_RESComsumptionRate, MINLP_Baseline_RESComsumptionRate,
]

# Define agent names
agent_names = [
    "DQN", "PER-DQN", "DDQN", "Duel-DQN", "NN-DQN",
    "Cat-DQN",
    "MS-DQN",
    "Rainbow-DQN", 'MINLP-Baseline'
]

bar_width = 0.4

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (12, 8)
plt.subplots_adjust(wspace=0.5, hspace=0.5)

# Plotting

plt.subplot(1, 1, 1)
plt.cla()
plt.gca().spines[['top', 'right']].set_visible(False)
bars = plt.bar(agent_names, RESComsumptionRate, color='orange',
               width=bar_width, label='RES Comsumption Rate')
plt.xlabel('DRL Agent', size=35, fontweight='bold')
plt.ylabel('RES Comsumption Rate', size=30, fontweight='bold')
plt.xticks(rotation=45, ha='right', size=15, fontweight='bold')  # Rotate agent names for better readability
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')

plt.legend(loc="best", ncol=1, frameon=True, fontsize='18',
            fancybox=True, framealpha=1, shadow=True, borderpad=1)
ax2 = plt.gca()
for spine in ax2.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax2.xaxis.grid(False)
ax2.yaxis.grid(True)

# Draw line connecting the tops of the bars
max_values_op_costs = [bar.get_height() for bar in bars]
plt.plot(agent_names, max_values_op_costs, marker='o', color='k',
         linewidth=2.5, markersize=8)

output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Cumulative_RESComsumptionRate_All_Models_2021.png')
plt.tight_layout()
plt.show()

print(RESComsumptionRate)

"""###**Visualize the Testing Operation Cost and Grid Unbalance for All Models and The Baseline - WTPV-5%**

**Note:**

This is a Cummulative for 7 different days.

The Test is performed Using Data randomly sampled between December 22 and 31, 2021.

An Initial SOC of 0.3 and Days between 22nd - 28th December, 2021 are used for the Baseline Optmization.
"""

plt.figure(figsize=(15, 9))
plt.gca().set_facecolor("white")
plt.gca().spines[['top', 'right']].set_visible(False)

MINLP_Model_Op_Costs = pd.Series(
    MINLP_Model_Op_Costs, index=pd.date_range(
        start='2021-12-22', periods=len(
            MINLP_Model_Op_Costs), freq='D'))

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_2_Op_Cost, marker='*', linestyle='-', color='maroon',
         label='DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_Rainbow_DQN_Op_Cost, marker='*', linestyle='-',
         color='black', label='Rainbow-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_NStep_Learning_Op_Cost, marker='*', linestyle='-',
         color='purple', label='MS-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_Categorical_DQN_Op_Cost, marker='*', linestyle='-',
         color='red', label='Categorical-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_NoisyNet_Op_Cost, marker='*', linestyle='-',
         color='gold', label='NN-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_DuelingNet_Op_Cost, marker='*', linestyle='-',
         color='teal', label='Duel-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_PER_Op_Cost, marker='*', linestyle='-',
         color='navy', label='PER-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DDQN_Op_Cost, marker='*', linestyle='-',
         color='olive', label='DDQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         MINLP_Model_Op_Costs, marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=20)

plt.xlabel('Days', size=25, fontweight='bold')
plt.ylabel('Cummulative Operation Cost (£)', size=25, fontweight='bold')
plt.xticks(rotation=30, size=15, fontweight='bold')
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')
ax = plt.gca()
# Set linewidth and edge color for each spine
for spine in ax.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax.xaxis.grid(False)  # Remove x-axis grid lines
ax.yaxis.grid(True)
#plt.yscale('log')
plt.legend(loc='best', ncol=3, frameon=True, fontsize='14',
           fancybox=True, framealpha=1, shadow=True, borderpad=1)
# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_Cummulative_OperationCost_During_Testing.png')
plt.tight_layout()
plt.show()

plt.figure(figsize=(15, 9))
plt.gca().set_facecolor("white")
plt.gca().spines[['top', 'right']].set_visible(False)

plt.plot(eval_data_DQN_2_Unbalance, marker='*', linestyle='-', color='maroon',
         label='DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_Rainbow_DQN_Unbalance, marker='*', linestyle='-',
         color='black', label='Rainbow-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DQN_NStep_Learning_Unbalance, marker='*', linestyle='-',
         color='purple', label='MS-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_Categorical_DQN_Unbalance, marker='*', linestyle='-',
         color='red', label='Categorical-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DQN_NoisyNet_Unbalance, marker='*', linestyle='-',
         color='gold', label='NN-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DQN_DuelingNet_Unbalance, marker='*', linestyle='-',
         color='teal', label='Duel-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DQN_PER_Unbalance, marker='*', linestyle='-',
         color='navy', label='PER-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DDQN_Unbalance, marker='*', linestyle='-',
         color='olive', label='DDQN', linewidth=3.5, markersize=20)

plt.xlabel('Days', size=25, fontweight='bold')
plt.ylabel('Cummulative Grid Unbalance (MW)', size=25, fontweight='bold')
plt.xticks(rotation=30, size=15, fontweight='bold')
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')
ax = plt.gca()
# Set linewidth and edge color for each spine
for spine in ax.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax.xaxis.grid(False)  # Remove x-axis grid lines
ax.yaxis.grid(True)
#plt.yscale('log')
plt.legend(loc='best', ncol=3, frameon=True, fontsize='13',
           fancybox=True, framealpha=1, shadow=True, borderpad=1)

plt.axhline(y=0, color='k', linestyle='--', linewidth=3.5)
plt.text(3.2, 2.5, 'Excess Generation - Obtains Benefits', fontsize=25, fontweight='bold', ha='center')
plt.text(3.5, -20.5, 'Shedding Load - Obtains Penalty', fontsize=25, fontweight='bold', ha='center')

# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_Cummulative_GridUnbalance_During_Testing.png')
plt.tight_layout()
plt.show()

"""#**EXPERIMENTAL RESULT ANALYSIS - Operational Scheduling Management (Dispatch Decisions) For The Proposed Model**

**RAINBOW DQN MODEL**
"""

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (16, 12)
fig, axs = plt.subplots(2, 2)
plt.subplots_adjust(wspace=0.5, hspace=0.5)
plt.autoscale(tight=True)

T = np.array([i for i in range(24)])
# plot Netload and Price at first
axs[0, 0].cla()
axs[0, 0].set_facecolor("white")
axs[0, 0].spines[['top', 'right']].set_visible(False)
axs[0, 0].set_ylabel('Price (£/MWh)', size=20, fontweight='bold')
axs[0, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[0, 0].plot(T, eval_data_Rainbow_DQN_day22['price'], label='Price',
            color='orange', linewidth = 4.0, linestyle='solid', drawstyle = 'steps-mid')
#axs[0, 0].legend(loc='best', ncol=1, frameon=True, fontsize='12',
        #fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)
axs_netload = axs[0, 0].twinx()
axs_netload.set_facecolor("white")
axs_netload.spines[['top', 'right']].set_visible(False)
axs_netload.set_ylabel('Netload (MW)', size=20, fontweight='bold')
axs_netload.tick_params(axis='y', rotation=0, labelsize=20)
axs_netload.bar(T, eval_data_Rainbow_DQN_day22['netload'], label='Netload',
             color = 'navy', linewidth = 4.0, align = 'center', width = 0.4)

# Combine legends from both Axes
lines, labels = axs[0, 0].get_legend_handles_labels()
lines_netload, labels_netload = axs_netload.get_legend_handles_labels()
axs_netload.legend(lines + lines_netload, labels + labels_netload,
              loc='best', ncol=1, frameon=True, fontsize='14',
        fancybox=True, framealpha=1, shadow=True, borderpad=2, labelspacing=0.2)
axs[0, 0].set_title('Netload and Price', size=25, fontweight='bold')
axs[0, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[0, 0].tick_params(axis='y', rotation=0, labelsize=15)
axs[0, 0] = plt.gca()
for spine in axs[0, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 0].xaxis.grid(False)
axs[0, 0].yaxis.grid(False)

# Plot Generation and Netload in ax[2]
axs[0, 1].cla()
axs[0, 1].set_facecolor("white")
axs[0, 1].spines[['top', 'right']].set_visible(False)
axs[0, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
axs[0, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_Rainbow_DQN_day22['battery1'])
battery_negative = np.array(eval_data_Rainbow_DQN_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_Rainbow_DQN_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_Rainbow_DQN_day22['unbalance']), 0)

axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['ccgt'], label='CCGT')
axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['coal'], label='COAL',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'])
axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['biomass'], label='BIOMASS',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'])
axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['nuclear'], label='NUCLEAR',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'])
axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['hydro'], label='HYDRO',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'])

axs[0, 1].bar(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[0, 1].bar(T, -battery_negative, label = 'battery discharge', hatch='/',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'] +\
              eval_data_Rainbow_DQN_day22['hydro'])
axs[0, 1].bar(T, -imported_from_grid, label = 'imported from grid',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'] +\
              eval_data_Rainbow_DQN_day22['hydro'] - battery_negative)
axs[0, 1].bar(T, -exported_2_grid, label = 'exported to grid',
              bottom = -battery_positive)

axs[0, 1].plot(T, eval_data_Rainbow_DQN_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 3.0, linestyle='solid')
axs[0, 1].legend(loc='best', ncol=2, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

axs[0, 1].set_title('Outputs of Generating Units - Rainbow DQN Model', size=20, fontweight='bold')
axs[0, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[0, 1].tick_params(axis='y', rotation=0, labelsize=20)
#axs[1] = plt.gca()
for spine in axs[0, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 1].xaxis.grid(False)
axs[0, 1].yaxis.grid(False)

# Plot Generation By Baseline Optimal Solution
axs[1, 0].cla()
axs[1, 0].set_facecolor("white")
axs[1, 0].spines[['top', 'right']].set_visible(False)
axs[1, 0].set_ylabel('Power (MW)', size=25, fontweight='bold')
axs[1, 0].set_xlabel('Time (h)', size=25, fontweight='bold')
battery_positive = np.array(base_result_Day22['battery_energy_change'])
battery_negative = np.array(base_result_Day22['battery_energy_change'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.array(base_result_Day22['grid_import'])
exported_2_grid = np.array(base_result_Day22['grid_export'])

axs[1, 0].bar(T, base_result_Day22['ccgt'], label='CCGT')
axs[1, 0].bar(T, base_result_Day22['coal'], label='COAL',
              bottom = base_result_Day22['ccgt'])
axs[1, 0].bar(T, base_result_Day22['biomass'], label='BIOMASS',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'])
axs[1, 0].bar(T, base_result_Day22['nuclear'], label='NUCLEAR',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'] +\
              base_result_Day22['biomass'])
axs[1, 0].bar(T, base_result_Day22['hydro'], label='HYDRO',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'] +\
              base_result_Day22['biomass'] + base_result_Day22['nuclear'])

axs[1, 0].bar(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[1, 0].bar(T, -battery_negative, label = 'battery discharge', hatch='/',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'] +\
              base_result_Day22['biomass'] + base_result_Day22['nuclear'] +\
              base_result_Day22['hydro'])
axs[1, 0].bar(T, -imported_from_grid, label = 'imported from grid',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'] +\
              base_result_Day22['biomass'] + base_result_Day22['nuclear'] +\
              base_result_Day22['hydro'] - battery_negative)
axs[1, 0].bar(T, -exported_2_grid, label = 'exported to grid',
              bottom = -battery_positive)

axs[1, 0].plot(T, base_result_Day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs[1, 0].legend(loc='best', ncol=2, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

axs[1, 0].set_title('Outputs of Generating Units - Optimal Solution Model', size=20, fontweight='bold')
axs[1, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[1, 0].tick_params(axis='y', rotation=0, labelsize=20)
#axs[1] = plt.gca()
for spine in axs[1, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 0].xaxis.grid(False)
axs[1, 0].yaxis.grid(False)

# plot energy charge/discharge with price in ax[3].
axs[1, 1].cla()
axs[1, 1].set_facecolor("white")
axs[1, 1].spines[['top', 'right']].set_visible(False)
axs[1, 1].set_ylabel('Price (£/MWh)', size=25, fontweight='bold')
axs[1, 1].set_xlabel('Time (h)', size=25, fontweight='bold')

axs[1, 1].plot(T, eval_data_Rainbow_DQN_day22['price'], drawstyle='steps-mid', label='Price',
               color = 'red', linewidth = 4.0, linestyle='solid')
axs[1, 1].legend(loc='best', ncol=1, frameon=True, fontsize='12',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)
axs_soc = axs[1, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=25, fontweight='bold')
axs_soc.plot(T, eval_data_Rainbow_DQN_day22['soc'], drawstyle='steps-mid', label='SOC',
               color = 'grey', linewidth = 4.0, linestyle='solid')
axs_soc.plot(T, base_result_Day22['soc'], drawstyle='steps-mid', label='SOC-Baseline',
               color = 'sienna', linewidth = 4.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[1, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=1, frameon=True, fontsize='14',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

axs[1, 1].set_title('Energy Charge/Discharge With Price', size=25, fontweight='bold')
axs[1, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[1, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[1, 1] = plt.gca()
for spine in axs[1, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 1].xaxis.grid(False)
axs[1, 1].yaxis.grid(False)

# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Proposed_Model_Rainbow_DQN_Performance_During_Testing.png')
plt.tight_layout()
plt.show()

"""**HOURLY OPERATION COST COMPARISON AMONG ALL MODELS**"""

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (22, 20)
fig, axs = plt.subplots(2, 1)
plt.subplots_adjust(wspace=0.6, hspace=0.4)
plt.autoscale(tight=True)

T = np.array([i for i in range(24)])
# plot Netload and Price at first
axs[0].cla()
axs[0].set_facecolor("white")
axs[0].spines[['top', 'right']].set_visible(False)
axs[0].set_ylabel('Netload (MW)', size=35, fontweight='bold')
axs[0].set_xlabel('Time (h)', size=35, fontweight='bold')
axs[0].bar(T, eval_data_DQN_2_day22['netload'], label='Netload',
            color='orange', linewidth = 2.0, align = 'center', width = 0.4)
axs_netload = axs[0].twinx()
axs_netload.set_facecolor("white")
axs_netload.spines[['top', 'right']].set_visible(False)
axs_netload.set_ylabel('Price (£/MWh)', size=35, fontweight='bold')
axs_netload.tick_params(axis='y', rotation=0, labelsize=25)
axs_netload.plot(T, eval_data_DQN_2_day22['price'], label='Price',
             color = 'navy', linewidth = 6.0, linestyle='solid', drawstyle = 'steps-mid')

# Combine legends from both Axes
lines, labels = axs[0].get_legend_handles_labels()
lines_netload, labels_netload = axs_netload.get_legend_handles_labels()
axs[0].legend(lines + lines_netload, labels + labels_netload,
              loc='best', ncol=1, frameon=True, fontsize='20',
        fancybox=True, framealpha=1, shadow=True, borderpad=2, labelspacing=0.3)
axs[0].set_title('Netload and Price', size=35, fontweight='bold')
axs[0].tick_params(axis='x', rotation=30, labelsize=25)
axs[0].tick_params(axis='y', rotation=0, labelsize=25)
axs[0] = plt.gca()
for spine in axs[0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0].xaxis.grid(False)
axs[0].yaxis.grid(True)

# plot Model's Operation Cost here
axs[1].cla()
axs[1].set_facecolor("white")
axs[1].spines[['top', 'right']].set_visible(False)
axs[1].set_ylabel('Operation Cost (£)', size=35, fontweight='bold')
axs[1].set_xlabel('Time (h)', size=35, fontweight='bold')

axs[1].plot(T, eval_data_DQN_2_day22['operation_cost'], label='DQN',
            alpha=1.0, linewidth = 5.0, color = 'gold')
axs[1].plot(T, eval_data_Rainbow_DQN_day22['operation_cost'], label='Rainbow-DQN',
            alpha=1.0, linewidth = 5.0, color = 'olive', drawstyle = 'steps-mid')
axs[1].plot(T, eval_data_DQN_NStep_Learning_day22['operation_cost'], label='MS-DQN',
            alpha=1.0, linewidth = 5.0, color = 'peachpuff')
axs[1].plot(T, eval_data_Categorical_DQN_day22['operation_cost'], label='Categorical-DQN',
            alpha=1.0, linewidth = 5.0, color = 'peru')
axs[1].plot(T, eval_data_DQN_NoisyNet_day22['operation_cost'], label='NN-DQN',
            alpha=1.0, linewidth = 5.0, color = 'darkseagreen')
axs[1].plot(T, eval_data_DQN_DuelingNet_day22['operation_cost'], label='Duel-DQN',
            alpha=1.0, linewidth = 5.0, color = 'dodgerblue')
axs[1].plot(T, eval_data_DQN_PER_day22['operation_cost'], label='PER-DQN',
            alpha=1.0, linewidth = 5.0, color = 'darkorange')
axs[1].plot(T, eval_data_DDQN_day22['operation_cost'], label='DDQN',
            alpha=1.0, linewidth = 5.0, color = 'black', linestyle='-')
axs[1].plot(T, base_result_Day22['step_cost'], label='MINLP-Baseline',
            alpha=1.0, linewidth = 5.0, color = 'navy', linestyle='--')

axs[1].set_title('Hourly Operation Cost',
                  size=35, fontweight='bold')
axs[1].tick_params(axis='x', rotation=30, labelsize=25)
axs[1].tick_params(axis='y', rotation=0, labelsize=25)
axs[1].legend(loc='best', ncol=3, frameon=True, fontsize='16',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)
for spine in axs[1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1].xaxis.grid(False)
axs[1].yaxis.grid(True)
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_OperationCost_During_Testing.png',
            format='svg', dpi=600, bbox_inches='tight')
plt.tight_layout()
plt.show()

"""**Cummulative Hourly Operation Cost for All Algorithms**"""

DQN_cum_epi_opcost = sum(eval_data_DQN_2_day22['operation_cost'])
DDQN_cum_epi_opcost = sum(eval_data_DDQN_day22['operation_cost'])
DQN_PER_cum_epi_opcost = sum(eval_data_DQN_PER_day22['operation_cost'])
DQN_DuelingNet_cum_epi_opcost = sum(eval_data_DQN_DuelingNet_day22['operation_cost'])
DQN_NoisyNet_cum_epi_opcost = sum(eval_data_DQN_NoisyNet_day22['operation_cost'])
Categorical_DQN_cum_epi_opcost = sum(eval_data_Categorical_DQN_day22['operation_cost'])
DQN_NStep_Learning_cum_epi_opcost = sum(eval_data_DQN_NStep_Learning_day22['operation_cost'])
Rainbow_DQN_cum_epi_opcost = sum(eval_data_Rainbow_DQN_day22['operation_cost'])
MINLP_Baseline = sum(base_result_Day22['step_cost'])
# Define the cumulative values

cumulative_op_costs = [
    DQN_cum_epi_opcost, DQN_PER_cum_epi_opcost, DDQN_cum_epi_opcost,
    DQN_DuelingNet_cum_epi_opcost, DQN_NoisyNet_cum_epi_opcost,
    Categorical_DQN_cum_epi_opcost,
    DQN_NStep_Learning_cum_epi_opcost,
    Rainbow_DQN_cum_epi_opcost, MINLP_Baseline,
]

# Define agent names
agent_names = [
    "DQN", "PER-DQN", "DDQN", "Duel-DQN", "NN-DQN",
    "Cat-DQN",
    "MS-DQN",
    "Rainbow-DQN", 'MINLP-Baseline'
]

bar_width = 0.4

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (20, 15)
plt.subplots_adjust(wspace=0.5, hspace=0.5)

# Plotting

plt.subplot(2, 2, 1)
plt.cla()
plt.gca().spines[['top', 'right']].set_visible(False)
bars = plt.bar(agent_names, cumulative_op_costs, color='orange',
               width=bar_width, label='Cumulative Operation Cost')
plt.xlabel('DRL Agent', size=35, fontweight='bold')
plt.ylabel('Cumulative Operation Cost (£)', size=30, fontweight='bold')
plt.xticks(rotation=45, ha='right', size=15, fontweight='bold')  # Rotate agent names for better readability
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')

plt.legend(loc="best", ncol=1, frameon=True, fontsize='18',
            fancybox=True, framealpha=1, shadow=True, borderpad=1)
ax2 = plt.gca()
for spine in ax2.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax2.xaxis.grid(False)
ax2.yaxis.grid(True)

# Draw line connecting the tops of the bars
max_values_op_costs = [bar.get_height() for bar in bars]
plt.plot(agent_names, max_values_op_costs, marker='o', color='k',
         linewidth=2.5, markersize=8)

plt.subplot(2, 2, 2)
plt.cla()
plt.gca().spines[['top', 'right']].set_visible(False)
plt.plot(agent_names, cumulative_op_costs, marker='o', color='k',
         linewidth=2.5, markersize=8, label='Cumulative Operation Cost')
plt.xlabel('DRL Agent', size=35, fontweight='bold')
plt.ylabel('Cumulative Operation Cost (£)', size=30, fontweight='bold')
plt.xticks(rotation=45, ha='right', size=15, fontweight='bold')  # Rotate agent names for better readability
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')

plt.legend(loc="best", ncol=1, frameon=True, fontsize='18',
            fancybox=True, framealpha=1, shadow=True, borderpad=1)

ax1 = plt.gca()
for spine in ax1.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax1.xaxis.grid(False)
ax1.yaxis.grid(True)

output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Cumulative_Operation_Cost_All_Models_2021.png')
plt.tight_layout()
plt.show()

print(cumulative_op_costs)

"""###**Scheduled BESS Energy Charge and Discharge Vs SOC For All Models Compared to the Baseline**"""

plt.rcParams["figure.figsize"] = (15, 15)
fig, axs = plt.subplots(4, 2)
plt.subplots_adjust(wspace=0.5, hspace=0.5)
plt.autoscale(tight=True)

T = np.array([i for i in range(24)])

# RainBow Vs Baseline
axs[0, 0].set_facecolor("white")
axs[0, 0].spines[['top', 'right']].set_visible(False)
axs[0, 0].cla()
axs[0, 0].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[0, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[0, 0].plot(T, eval_data_Rainbow_DQN_day22['battery1'], marker='*', linestyle='-',
         color='red', label='Rainbow-DQN', linewidth=3.5, markersize=8)
axs[0, 0].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[0, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_Rainbow_DQN_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[0, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[0, 0].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[0, 0].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[0, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[0, 0].tick_params(axis='y', rotation=0, labelsize=15)

axs[0, 0] = plt.gca()
for spine in axs[0, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 0].xaxis.grid(False)
axs[0, 0].yaxis.grid(False)

# DQN+NOISE Vs Baseline
axs[0, 1].set_facecolor("white")
axs[0, 1].spines[['top', 'right']].set_visible(False)
axs[0, 1].cla()
axs[0, 1].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[0, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[0, 1].plot(T, eval_data_DQN_NoisyNet_day22['battery1'], marker='*', linestyle='-',
         color='red', label='NN-DQN', linewidth=3.5, markersize=8)
axs[0, 1].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[0, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_NoisyNet_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[0, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[0, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[0, 1].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[0, 1].tick_params(axis='x', rotation=30, labelsize=15)
axs[0, 1].tick_params(axis='y', rotation=0, labelsize=15)

axs[0, 1] = plt.gca()
for spine in axs[0, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 1].xaxis.grid(False)
axs[0, 1].yaxis.grid(False)

# DQN+DUEL Vs Baseline
axs[1, 0].set_facecolor("white")
axs[1, 0].spines[['top', 'right']].set_visible(False)
axs[1, 0].cla()
axs[1, 0].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[1, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[1, 0].plot(T, eval_data_DQN_DuelingNet_day22['battery1'], marker='*', linestyle='-',
         color='red', label='Duel-DQN', linewidth=3.5, markersize=8)
axs[1, 0].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[1, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_DuelingNet_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[1, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 0].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[1, 0].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[1, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[1, 0].tick_params(axis='y', rotation=0, labelsize=15)

axs[1, 0] = plt.gca()
for spine in axs[1, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 0].xaxis.grid(False)
axs[1, 0].yaxis.grid(False)

# DDQN Vs Baseline
axs[1, 1].set_facecolor("white")
axs[1, 1].spines[['top', 'right']].set_visible(False)
axs[1, 1].cla()
axs[1, 1].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[1, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[1, 1].plot(T, eval_data_DDQN_day22['battery1'], marker='*', linestyle='-',
         color='red', label='DDQN', linewidth=3.5, markersize=8)
axs[1, 1].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[1, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DDQN_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[1, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[1, 1].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[1, 1].tick_params(axis='x', rotation=30, labelsize=15)
axs[1, 1].tick_params(axis='y', rotation=0, labelsize=15)

axs[1, 1] = plt.gca()
for spine in axs[1, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 1].xaxis.grid(False)
axs[1, 1].yaxis.grid(False)

# DQN+PER Vs Baseline
axs[2, 0].set_facecolor("white")
axs[2, 0].spines[['top', 'right']].set_visible(False)
axs[2, 0].cla()
axs[2, 0].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[2, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[2, 0].plot(T, eval_data_DQN_PER_day22['battery1'], marker='*', linestyle='-',
         color='red', label='PER-DQN', linewidth=3.5, markersize=8)
axs[2, 0].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[2, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_PER_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[2, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[2, 0].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[2, 0].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[2, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[2, 0].tick_params(axis='y', rotation=0, labelsize=15)

axs[2, 0] = plt.gca()
for spine in axs[2, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[2, 0].xaxis.grid(False)
axs[2, 0].yaxis.grid(False)

# DQN+NStep-Learning Vs Baseline
axs[2, 1].set_facecolor("white")
axs[2, 1].spines[['top', 'right']].set_visible(False)
axs[2, 1].cla()
axs[2, 1].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[2, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[2, 1].plot(T, eval_data_DQN_NStep_Learning_day22['battery1'], marker='*', linestyle='-',
         color='red', label='MS-DQN', linewidth=3.5, markersize=8)
axs[2, 1].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[2, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_NStep_Learning_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[2, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[2, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[2, 1].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[2, 1].tick_params(axis='x', rotation=30, labelsize=15)
axs[2, 1].tick_params(axis='y', rotation=0, labelsize=15)

axs[2, 1] = plt.gca()
for spine in axs[2, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[2, 1].xaxis.grid(False)
axs[2, 1].yaxis.grid(False)

# DQN Vs Baseline
axs[3, 0].set_facecolor("white")
axs[3, 0].spines[['top', 'right']].set_visible(False)
axs[3, 0].cla()
axs[3, 0].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[3, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[3, 0].plot(T, eval_data_DQN_2_day22['battery1'], marker='*', linestyle='-',
         color='red', label='DQN', linewidth=3.5, markersize=8)
axs[3, 0].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[3, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_2_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[3, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[3, 0].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[3, 0].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[3, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[3, 0].tick_params(axis='y', rotation=0, labelsize=15)

axs[3, 0] = plt.gca()
for spine in axs[3, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[3, 0].xaxis.grid(False)
axs[3, 0].yaxis.grid(False)

# CategoricalDQN Vs Baseline
axs[3, 1].set_facecolor("white")
axs[3, 1].spines[['top', 'right']].set_visible(False)
axs[3, 1].cla()
axs[3, 1].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[3, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[3, 1].plot(T, eval_data_Categorical_DQN_day22['battery1'], marker='*', linestyle='-',
         color='red', label='Categorical-DQN', linewidth=3.5, markersize=8)
axs[3, 1].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[3, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_Categorical_DQN_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[3, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[3, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[3, 1].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[3, 1].tick_params(axis='x', rotation=30, labelsize=15)
axs[3, 1].tick_params(axis='y', rotation=0, labelsize=15)

axs[3, 1] = plt.gca()
for spine in axs[3, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[3, 1].xaxis.grid(False)
axs[3, 1].yaxis.grid(False)

# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_BESS_Change_VS_SOC_During_Testing.png')
plt.tight_layout()
plt.show()

plt.rcParams["figure.figsize"] = (15, 15)
fig, axs = plt.subplots(4, 2)
plt.subplots_adjust(wspace=0.8, hspace=0.8)
plt.autoscale(tight=True)

T = np.array([i for i in range(24)])

# RainBow
axs[0, 0].set_facecolor("white")
axs[0, 0].spines[['top', 'right']].set_visible(False)
axs[0, 0].cla()
axs[0, 0].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[0, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_Rainbow_DQN_day22['battery1'])
battery_negative = np.array(eval_data_Rainbow_DQN_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_Rainbow_DQN_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_Rainbow_DQN_day22['unbalance']), 0)

axs[0, 0].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple', alpha=0.3)
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'] +\
              eval_data_Rainbow_DQN_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'] +\
              eval_data_Rainbow_DQN_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[0, 0].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'],
                       eval_data_Rainbow_DQN_day22['hydro'], label='HYDRO', color='green')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'],
                       eval_data_Rainbow_DQN_day22['nuclear'], label='NUCLEAR', color='red')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'],
                       eval_data_Rainbow_DQN_day22['biomass'], label='BIOMASS', color='violet')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'], eval_data_Rainbow_DQN_day22['coal'],
                       label='COAL', color='seagreen')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'], label='CCGT', color='gray')
axs[0, 0].plot(T, eval_data_Rainbow_DQN_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[0, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_Rainbow_DQN_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[0, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[0, 0].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[0, 0].set_xticks([])
axs[0, 0].set_title('Rainbow DQN',
                    size=20, fontweight='bold')
#axs[0, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[0, 0].tick_params(axis='y', rotation=0, labelsize=20)
axs[0, 0] = plt.gca()
for spine in axs[0, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 0].xaxis.grid(False)
axs[0, 0].yaxis.grid(False)

# DQN+NOISE
axs[0, 1].set_facecolor("white")
axs[0, 1].spines[['top', 'right']].set_visible(False)
axs[0, 1].cla()
axs[0, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[0, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_NoisyNet_day22['battery1'])
battery_negative = np.array(eval_data_DQN_NoisyNet_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_NoisyNet_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_NoisyNet_day22['unbalance']), 0)

axs[0, 1].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'] +\
              eval_data_DQN_NoisyNet_day22['biomass'] + eval_data_DQN_NoisyNet_day22['nuclear'] +\
              eval_data_DQN_NoisyNet_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'] +\
              eval_data_DQN_NoisyNet_day22['biomass'] + eval_data_DQN_NoisyNet_day22['nuclear'] +\
              eval_data_DQN_NoisyNet_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[0, 1].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'] +\
              eval_data_DQN_NoisyNet_day22['biomass'] + eval_data_DQN_NoisyNet_day22['nuclear'],
                       eval_data_DQN_NoisyNet_day22['hydro'], label='HYDRO', color='green')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'] +\
              eval_data_DQN_NoisyNet_day22['biomass'],
                       eval_data_DQN_NoisyNet_day22['nuclear'], label='NUCLEAR', color='red')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'],
                       eval_data_DQN_NoisyNet_day22['biomass'], label='BIOMASS', color='violet')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'], eval_data_DQN_NoisyNet_day22['coal'],
                       label='COAL', color='seagreen')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'], label='CCGT', color='gray')
axs[0, 1].plot(T, eval_data_DQN_NoisyNet_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[0, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_NoisyNet_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[0, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[0, 1].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[0, 1].set_xticks([])
axs[0, 1].set_title('NN-DQN', size=20,
                    fontweight='bold')
#axs[0, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[0, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[0, 1] = plt.gca()
for spine in axs[0, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 1].xaxis.grid(False)
axs[0, 1].yaxis.grid(False)

# DQN+DUEL eval_data_DQN_DuelingNet_day22
axs[1, 0].set_facecolor("white")
axs[1, 0].spines[['top', 'right']].set_visible(False)
axs[1, 0].cla()
axs[1, 0].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[1, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_DuelingNet_day22['battery1'])
battery_negative = np.array(eval_data_DQN_DuelingNet_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_DuelingNet_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_DuelingNet_day22['unbalance']), 0)

axs[1, 0].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'] +\
              eval_data_DQN_DuelingNet_day22['biomass'] + eval_data_DQN_DuelingNet_day22['nuclear'] +\
              eval_data_DQN_DuelingNet_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'] +\
              eval_data_DQN_DuelingNet_day22['biomass'] + eval_data_DQN_DuelingNet_day22['nuclear'] +\
              eval_data_DQN_DuelingNet_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[1, 0].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'] +\
              eval_data_DQN_DuelingNet_day22['biomass'] + eval_data_DQN_DuelingNet_day22['nuclear'],
                       eval_data_DQN_DuelingNet_day22['hydro'], label='HYDRO', color='green')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'] +\
              eval_data_DQN_DuelingNet_day22['biomass'],
                       eval_data_DQN_DuelingNet_day22['nuclear'], label='NUCLEAR', color='red')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'],
                       eval_data_DQN_DuelingNet_day22['biomass'], label='BIOMASS', color='violet')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'], eval_data_DQN_DuelingNet_day22['coal'],
                       label='COAL', color='seagreen')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'], label='CCGT', color='gray')
axs[1, 0].plot(T, eval_data_DQN_DuelingNet_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[1, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_DuelingNet_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[1, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 0].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[1, 0].set_xticks([])
axs[1, 0].set_title('Duel-DQN', size=20,
                    fontweight='bold', y = 0.9)
#axs[1, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[1, 0].tick_params(axis='y', rotation=0, labelsize=20)
axs[1, 0] = plt.gca()
for spine in axs[1, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 0].xaxis.grid(False)
axs[1, 0].yaxis.grid(False)

# DDQN
axs[1, 1].set_facecolor("white")
axs[1, 1].spines[['top', 'right']].set_visible(False)
axs[1, 1].cla()
axs[1, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[1, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DDQN_day22['battery1'])
battery_negative = np.array(eval_data_DDQN_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DDQN_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DDQN_day22['unbalance']), 0)

axs[1, 1].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'] +\
              eval_data_DDQN_day22['biomass'] + eval_data_DDQN_day22['nuclear'] +\
              eval_data_DDQN_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'] +\
              eval_data_DDQN_day22['biomass'] + eval_data_DDQN_day22['nuclear'] +\
              eval_data_DDQN_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[1, 1].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'] +\
              eval_data_DDQN_day22['biomass'] + eval_data_DDQN_day22['nuclear'],
                       eval_data_DDQN_day22['hydro'], label='HYDRO', color='green')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'] +\
              eval_data_DDQN_day22['biomass'],
                       eval_data_DDQN_day22['nuclear'], label='NUCLEAR', color='red')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'],
                       eval_data_DDQN_day22['biomass'], label='BIOMASS', color='violet')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'], eval_data_DDQN_day22['coal'],
                       label='COAL', color='seagreen')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'], label='CCGT', color='gray')
axs[1, 1].plot(T, eval_data_DDQN_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[1, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DDQN_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[1, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 1].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[1, 1].set_xticks([])
axs[1, 1].set_title('DDQN', size=20,
                    fontweight='bold', y = 0.9)
#axs[1, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[1, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[1, 1] = plt.gca()
for spine in axs[1, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 1].xaxis.grid(False)
axs[1, 1].yaxis.grid(False)

# DQN+PER
axs[2, 0].set_facecolor("white")
axs[2, 0].spines[['top', 'right']].set_visible(False)
axs[2, 0].cla()
axs[2, 0].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[2, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_PER_day22['battery1'])
battery_negative = np.array(eval_data_DQN_PER_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_PER_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_PER_day22['unbalance']), 0)

axs[2, 0].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'] +\
              eval_data_DQN_PER_day22['biomass'] + eval_data_DQN_PER_day22['nuclear'] +\
              eval_data_DQN_PER_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'] +\
              eval_data_DQN_PER_day22['biomass'] + eval_data_DQN_PER_day22['nuclear'] +\
              eval_data_DQN_PER_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[2, 0].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'] +\
              eval_data_DQN_PER_day22['biomass'] + eval_data_DQN_PER_day22['nuclear'],
                       eval_data_DQN_PER_day22['hydro'], label='HYDRO', color='green')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'] +\
              eval_data_DQN_PER_day22['biomass'],
                       eval_data_DQN_PER_day22['nuclear'], label='NUCLEAR', color='red')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'],
                       eval_data_DQN_PER_day22['biomass'], label='BIOMASS', color='violet')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'], eval_data_DQN_PER_day22['coal'],
                       label='COAL', color='seagreen')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'], label='CCGT', color='gray')
axs[2, 0].plot(T, eval_data_DQN_PER_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[2, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_PER_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[2, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[2, 0].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[2, 0].set_xticks([])
axs[2, 0].set_title('PER-DQN', size=20,
                    fontweight='bold', y = 0.9)
#axs[2, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[2, 0].tick_params(axis='y', rotation=0, labelsize=20)
axs[2, 0] = plt.gca()
for spine in axs[2, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[2, 0].xaxis.grid(False)
axs[2, 0].yaxis.grid(False)

# DQN+NStep-Learning
axs[2, 1].set_facecolor("white")
axs[2, 1].spines[['top', 'right']].set_visible(False)
axs[2, 1].cla()
axs[2, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[2, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_NStep_Learning_day22['battery1'])
battery_negative = np.array(eval_data_DQN_NStep_Learning_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_NStep_Learning_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_NStep_Learning_day22['unbalance']), 0)

axs[2, 1].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'] +\
              eval_data_DQN_NStep_Learning_day22['biomass'] + eval_data_DQN_NStep_Learning_day22['nuclear'] +\
              eval_data_DQN_NStep_Learning_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'] +\
              eval_data_DQN_NStep_Learning_day22['biomass'] + eval_data_DQN_NStep_Learning_day22['nuclear'] +\
              eval_data_DQN_NStep_Learning_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[2, 1].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'] +\
              eval_data_DQN_NStep_Learning_day22['biomass'] + eval_data_DQN_NStep_Learning_day22['nuclear'],
                       eval_data_DQN_NStep_Learning_day22['hydro'], label='HYDRO', color='green')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'] +\
              eval_data_DQN_NStep_Learning_day22['biomass'],
                       eval_data_DQN_NStep_Learning_day22['nuclear'], label='NUCLEAR', color='red')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'],
                       eval_data_DQN_NStep_Learning_day22['biomass'], label='BIOMASS', color='violet')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'], eval_data_DQN_NStep_Learning_day22['coal'],
                       label='COAL', color='seagreen')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'], label='CCGT', color='gray')
axs[2, 1].plot(T, eval_data_DQN_NStep_Learning_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[2, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_NStep_Learning_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[2, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[2, 1].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[2, 1].set_xticks([])
axs[2, 1].set_title('MS-DQN', size=20,
                    fontweight='bold', y = 0.9)
#axs[2, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[2, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[2, 1] = plt.gca()
for spine in axs[2, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[2, 1].xaxis.grid(False)
axs[2, 1].yaxis.grid(False)

# DQN
axs[3, 0].set_facecolor("white")
axs[3, 0].spines[['top', 'right']].set_visible(False)
axs[3, 0].cla()
axs[3, 0].set_ylabel('Power (MW)', size=20, fontweight='bold')
axs[3, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_2_day22['battery1'])
battery_negative = np.array(eval_data_DQN_2_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_2_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_2_day22['unbalance']), 0)

axs[3, 0].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'] +\
              eval_data_DQN_2_day22['biomass'] + eval_data_DQN_2_day22['nuclear'] +\
              eval_data_DQN_2_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'] +\
              eval_data_DQN_2_day22['biomass'] + eval_data_DQN_2_day22['nuclear'] +\
              eval_data_DQN_2_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[3, 0].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'] +\
              eval_data_DQN_2_day22['biomass'] + eval_data_DQN_2_day22['nuclear'],
                       eval_data_DQN_2_day22['hydro'], label='HYDRO', color='green')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'] +\
              eval_data_DQN_2_day22['biomass'],
                       eval_data_DQN_2_day22['nuclear'], label='NUCLEAR', color='red')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'],
                       eval_data_DQN_2_day22['biomass'], label='BIOMASS', color='violet')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'], eval_data_DQN_2_day22['coal'],
                       label='COAL', color='seagreen')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'], label='CCGT', color='gray')
axs[3, 0].plot(T, eval_data_DQN_2_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[3, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_2_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[3, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[3, 0].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.46), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)

axs[3, 0].set_title('DQN', size=20,
                    fontweight='bold', y = 0.9)
axs[3, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[3, 0].tick_params(axis='y', rotation=0, labelsize=20)
axs[3, 0] = plt.gca()
for spine in axs[3, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[3, 0].xaxis.grid(False)
axs[3, 0].yaxis.grid(False)

# CategoricalDQN
axs[3, 1].set_facecolor("white")
axs[3, 1].spines[['top', 'right']].set_visible(False)
axs[3, 1].cla()
axs[3, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
axs[3, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_Categorical_DQN_day22['battery1'])
battery_negative = np.array(eval_data_Categorical_DQN_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_Categorical_DQN_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_Categorical_DQN_day22['unbalance']), 0)

axs[3, 1].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'] +\
              eval_data_Categorical_DQN_day22['biomass'] + eval_data_Categorical_DQN_day22['nuclear'] +\
              eval_data_Categorical_DQN_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'] +\
              eval_data_Categorical_DQN_day22['biomass'] + eval_data_Categorical_DQN_day22['nuclear'] +\
              eval_data_Categorical_DQN_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[3, 1].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'] +\
              eval_data_Categorical_DQN_day22['biomass'] + eval_data_Categorical_DQN_day22['nuclear'],
                       eval_data_Categorical_DQN_day22['hydro'], label='HYDRO', color='green')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'] +\
              eval_data_Categorical_DQN_day22['biomass'],
                       eval_data_Categorical_DQN_day22['nuclear'], label='NUCLEAR', color='red')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'],
                       eval_data_Categorical_DQN_day22['biomass'], label='BIOMASS', color='violet')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'], eval_data_Categorical_DQN_day22['coal'],
                       label='COAL', color='seagreen')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'], label='CCGT', color='gray')
axs[3, 1].plot(T, eval_data_Categorical_DQN_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[3, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_Categorical_DQN_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[3, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[3, 1].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.46), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)

axs[3, 1].set_title('Categorical-DQN', size=20,
                    fontweight='bold', y = 0.9)
axs[3, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[3, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[3, 1] = plt.gca()
for spine in axs[3, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[3, 1].xaxis.grid(False)
axs[3, 1].yaxis.grid(False)

# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Operational_Scheduling_Management_of_all_Models_During_Testing.png')
plt.tight_layout()
plt.show()

"""**Cummulative Operation Cost Savings Relative to The Baseline Network - DQN**"""

# Day 22
dqn22 = eval_data_DQN_2_day22['operation_cost']
rainbow22 = eval_data_Rainbow_DQN_day22['operation_cost']
dqn_nstep22 = eval_data_DQN_NStep_Learning_day22['operation_cost']
categorical_dqn22 = eval_data_Categorical_DQN_day22['operation_cost']
dqn_noise22 = eval_data_DQN_NoisyNet_day22['operation_cost']
dqn_duel22 = eval_data_DQN_DuelingNet_day22['operation_cost']
dqn_per22 = eval_data_DQN_PER_day22['operation_cost']
ddqn22 = eval_data_DDQN_day22['operation_cost']
minlp22 = base_result_Day22['step_cost']
# Day 23
dqn23 = eval_data_DQN_2_day23['operation_cost']
rainbow23 = eval_data_Rainbow_DQN_day23['operation_cost']
dqn_nstep23 = eval_data_DQN_NStep_Learning_day23['operation_cost']
categorical_dqn23 = eval_data_Categorical_DQN_day23['operation_cost']
dqn_noise23 = eval_data_DQN_NoisyNet_day23['operation_cost']
dqn_duel23 = eval_data_DQN_DuelingNet_day23['operation_cost']
dqn_per23 = eval_data_DQN_PER_day23['operation_cost']
ddqn23 = eval_data_DDQN_day23['operation_cost']
minlp23 = base_result_Day23['step_cost']
# Day 24
dqn24 = eval_data_DQN_2_day24['operation_cost']
rainbow24 = eval_data_Rainbow_DQN_day24['operation_cost']
dqn_nstep24 = eval_data_DQN_NStep_Learning_day24['operation_cost']
categorical_dqn24 = eval_data_Categorical_DQN_day24['operation_cost']
dqn_noise24 = eval_data_DQN_NoisyNet_day24['operation_cost']
dqn_duel24 = eval_data_DQN_DuelingNet_day24['operation_cost']
dqn_per24 = eval_data_DQN_PER_day24['operation_cost']
ddqn24 = eval_data_DDQN_day24['operation_cost']
minlp24 = base_result_Day24['step_cost']
# Day 25
dqn25 = eval_data_DQN_2_day25['operation_cost']
rainbow25 = eval_data_Rainbow_DQN_day25['operation_cost']
dqn_nstep25 = eval_data_DQN_NStep_Learning_day25['operation_cost']
categorical_dqn25 = eval_data_Categorical_DQN_day25['operation_cost']
dqn_noise25 = eval_data_DQN_NoisyNet_day25['operation_cost']
dqn_duel25 = eval_data_DQN_DuelingNet_day25['operation_cost']
dqn_per25 = eval_data_DQN_PER_day25['operation_cost']
ddqn25 = eval_data_DDQN_day25['operation_cost']
minlp25 = base_result_Day25['step_cost']
# Day 26
dqn26 = eval_data_DQN_2_day26['operation_cost']
rainbow26 = eval_data_Rainbow_DQN_day26['operation_cost']
dqn_nstep26 = eval_data_DQN_NStep_Learning_day26['operation_cost']
categorical_dqn26 = eval_data_Categorical_DQN_day26['operation_cost']
dqn_noise26 = eval_data_DQN_NoisyNet_day26['operation_cost']
dqn_duel26 = eval_data_DQN_DuelingNet_day26['operation_cost']
dqn_per26 = eval_data_DQN_PER_day26['operation_cost']
ddqn26 = eval_data_DDQN_day26['operation_cost']
minlp26 = base_result_Day26['step_cost']
# Day 27
dqn27 = eval_data_DQN_2_day27['operation_cost']
rainbow27 = eval_data_Rainbow_DQN_day27['operation_cost']
dqn_nstep27 = eval_data_DQN_NStep_Learning_day27['operation_cost']
categorical_dqn27 = eval_data_Categorical_DQN_day27['operation_cost']
dqn_noise27 = eval_data_DQN_NoisyNet_day27['operation_cost']
dqn_duel27 = eval_data_DQN_DuelingNet_day27['operation_cost']
dqn_per27 = eval_data_DQN_PER_day27['operation_cost']
ddqn27 = eval_data_DDQN_day27['operation_cost']
minlp27 = base_result_Day27['step_cost']
# Day 28
dqn28 = eval_data_DQN_2_day28['operation_cost']
rainbow28 = eval_data_Rainbow_DQN_day28['operation_cost']
dqn_nstep28 = eval_data_DQN_NStep_Learning_day28['operation_cost']
categorical_dqn28 = eval_data_Categorical_DQN_day28['operation_cost']
dqn_noise28 = eval_data_DQN_NoisyNet_day28['operation_cost']
dqn_duel28 = eval_data_DQN_DuelingNet_day28['operation_cost']
dqn_per28 = eval_data_DQN_PER_day28['operation_cost']
ddqn28 = eval_data_DDQN_day28['operation_cost']
minlp28 = base_result_Day28['step_cost']

# concatenate
dqn = pd.concat([dqn22, dqn23, dqn24, dqn25, dqn26, dqn27, dqn28], axis=0)
rainbow = pd.concat([rainbow22, rainbow23, rainbow24, rainbow25, rainbow26, rainbow27, rainbow28],
                    axis=0)
dqn_nstep = pd.concat([dqn_nstep22, dqn_nstep23, dqn_nstep24, dqn_nstep25, dqn_nstep26, dqn_nstep27, dqn_nstep28],
                      axis=0)
categorical_dqn = pd.concat([categorical_dqn22, categorical_dqn23, categorical_dqn24, categorical_dqn25,
                             categorical_dqn26, categorical_dqn27, categorical_dqn28],
                             axis=0)
dqn_noise = pd.concat([dqn_noise22, dqn_noise23, dqn_noise24, dqn_noise25, dqn_noise26,
                       dqn_noise27, dqn_noise28], axis=0)
dqn_duel = pd.concat([dqn_duel22, dqn_duel23, dqn_duel24, dqn_duel25, dqn_duel26,
                      dqn_duel27, dqn_duel28], axis=0)
dqn_per = pd.concat([dqn_per22, dqn_per23, dqn_per24, dqn_per25, dqn_per26,
                     dqn_per27, dqn_per28], axis=0)
ddqn = pd.concat([ddqn22, ddqn23, ddqn24, ddqn25, ddqn26, ddqn27, ddqn28], axis=0)
minlp = pd.concat([minlp22, minlp23, minlp24, minlp25, minlp26, minlp27,
                   minlp28], axis=0)

# Operation Cost Savings
dqn_savings = dqn - dqn
rainbow_savings = dqn - rainbow
dqn_nstep_savings = dqn - dqn_nstep
categorical_dqn_savings = dqn - categorical_dqn
dqn_noise_savings = dqn - dqn_noise
dqn_duel_savings = dqn - dqn_duel
dqn_per_savings = dqn - dqn_per
ddqn_savings = dqn - ddqn
minlp_savings = dqn - minlp

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (22, 20)
fig, axs = plt.subplots(1, 1)
plt.subplots_adjust(wspace=0.6, hspace=0.4)
plt.autoscale(tight=True)

T = np.array([i for i in range(168)])

axs.set_facecolor("white")
axs.spines[['top', 'right']].set_visible(False)
axs.cla()
axs.set_ylabel('Operation Cost Savings (£)', size=35, fontweight='bold')
axs.set_xlabel('Time (h)', size=35, fontweight='bold')

axs.plot(T, rainbow_savings, label='Rainbow-DQN',
            alpha=1.0, linewidth = 5.0, color = 'olive', drawstyle = 'steps-mid')
axs.plot(T, dqn_nstep_savings, label='MS-DQN',
            alpha=1.0, linewidth = 5.0, color = 'peachpuff', drawstyle = 'steps-mid')
axs.plot(T, categorical_dqn_savings, label='Categorical-DQN',
            alpha=1.0, linewidth = 5.0, color = 'peru', drawstyle = 'steps-mid')
axs.plot(T, dqn_noise_savings, label='NN-DQN',
            alpha=1.0, linewidth = 5.0, color = 'darkseagreen', drawstyle = 'steps-mid')
axs.plot(T, dqn_duel_savings, label='Duel-DQN',
            alpha=1.0, linewidth = 5.0, color = 'dodgerblue', drawstyle = 'steps-mid')
axs.plot(T, dqn_per_savings, label='PER-DQN',
            alpha=1.0, linewidth = 5.0, color = 'darkorange', drawstyle = 'steps-mid')
axs.plot(T, ddqn_savings, label='DDQN',
            alpha=1.0, linewidth = 5.0, color = 'navy', linestyle='-', drawstyle = 'steps-mid')
axs.plot(T, minlp_savings, label='MINLP-Baseline',
            alpha=1.0, linewidth = 5.0, color = 'gold', linestyle='-', drawstyle = 'steps-mid')
axs.plot(T, dqn_savings, label='DQN',
            alpha=1.0, linewidth = 7.0, color = 'black', linestyle='-.', drawstyle = 'steps-mid')

axs.tick_params(axis='x', rotation=30, labelsize=25)
axs.tick_params(axis='y', rotation=0, labelsize=25)
axs.legend(loc='best', ncol=3, frameon=True, fontsize='18',
        fancybox=True, framealpha=1, shadow=True, borderpad=2, labelspacing=0.3)
axs = plt.gca()
for spine in axs.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs.xaxis.grid(False)
axs.yaxis.grid(False)
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_OperationCost_Savings_During_Testing.png',
            format='svg', dpi=600, bbox_inches='tight')
plt.tight_layout()
plt.show()

"""**Compute All Algorithm's Ability to Utilize RES - Total Consumption Rate of RES**

Larger is better!
"""

DQN_cum_pv = sum(eval_data_DQN_2_day22['pv'])
DDQN_cum_pv = sum(eval_data_DDQN_day22['pv'])
DQN_PER_cum_pv = sum(eval_data_DQN_PER_day22['pv'])
DQN_DuelingNet_cum_pv = sum(eval_data_DQN_DuelingNet_day22['pv'])
DQN_NoisyNet_cum_pv = sum(eval_data_DQN_NoisyNet_day22['pv'])
Categorical_DQN_cum_pv = sum(eval_data_Categorical_DQN_day22['pv'])
DQN_NStep_Learning_cum_pv = sum(eval_data_DQN_NStep_Learning_day22['pv'])
Rainbow_DQN_cum_pv = sum(eval_data_Rainbow_DQN_day22['pv'])
MINLP_Baseline_pv = sum(base_result_Day22['pv'])

DQN_cum_onwind = sum(eval_data_DQN_2_day22['onwind'])
DDQN_cum_onwind = sum(eval_data_DDQN_day22['onwind'])
DQN_PER_cum_onwind = sum(eval_data_DQN_PER_day22['onwind'])
DQN_DuelingNet_cum_onwind = sum(eval_data_DQN_DuelingNet_day22['onwind'])
DQN_NoisyNet_cum_onwind = sum(eval_data_DQN_NoisyNet_day22['onwind'])
Categorical_DQN_cum_onwind = sum(eval_data_Categorical_DQN_day22['onwind'])
DQN_NStep_Learning_cum_onwind = sum(eval_data_DQN_NStep_Learning_day22['onwind'])
Rainbow_DQN_cum_onwind = sum(eval_data_Rainbow_DQN_day22['onwind'])
MINLP_Baseline_onwind = sum(base_result_Day22['wind'])

DQN_cum_offwind = sum(eval_data_DQN_2_day22['offwind'])
DDQN_cum_offwind = sum(eval_data_DDQN_day22['offwind'])
DQN_PER_cum_offwind = sum(eval_data_DQN_PER_day22['offwind'])
DQN_DuelingNet_cum_offwind = sum(eval_data_DQN_DuelingNet_day22['offwind'])
DQN_NoisyNet_cum_offwind = sum(eval_data_DQN_NoisyNet_day22['offwind'])
Categorical_DQN_cum_offwind = sum(eval_data_Categorical_DQN_day22['offwind'])
DQN_NStep_Learning_cum_offwind = sum(eval_data_DQN_NStep_Learning_day22['offwind'])
Rainbow_DQN_cum_offwind = sum(eval_data_Rainbow_DQN_day22['offwind'])
MINLP_Baseline_offwind = sum(base_result_Day22['offwind'])

DQN_RESComsumptionRate = (DQN_cum_pv + DQN_cum_onwind + DQN_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DDQN_RESComsumptionRate = (DDQN_cum_pv + DDQN_cum_onwind + DDQN_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DQN_PER_RESComsumptionRate = (DQN_PER_cum_pv + DQN_PER_cum_onwind + DQN_PER_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DQN_DuelingNet_RESComsumptionRate = (DQN_DuelingNet_cum_pv + DQN_DuelingNet_cum_onwind + DQN_DuelingNet_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DQN_NoisyNet_RESComsumptionRate = (DQN_NoisyNet_cum_pv + DQN_NoisyNet_cum_onwind + DQN_NoisyNet_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
Categorical_DQN_RESComsumptionRate = (Categorical_DQN_cum_pv + Categorical_DQN_cum_onwind + Categorical_DQN_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DQN_NStep_Learning_RESComsumptionRate = (DQN_NStep_Learning_cum_pv + DQN_NStep_Learning_cum_onwind + DQN_NStep_Learning_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
Rainbow_DQN_RESComsumptionRate = (Rainbow_DQN_cum_pv + Rainbow_DQN_cum_onwind + Rainbow_DQN_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
MINLP_Baseline_RESComsumptionRate = (MINLP_Baseline_pv + MINLP_Baseline_onwind + MINLP_Baseline_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)

RESComsumptionRate = [
    DQN_RESComsumptionRate, DQN_PER_RESComsumptionRate, DDQN_RESComsumptionRate,
    DQN_DuelingNet_RESComsumptionRate, DQN_NoisyNet_RESComsumptionRate,
    Categorical_DQN_RESComsumptionRate,
    DQN_NStep_Learning_RESComsumptionRate,
    Rainbow_DQN_RESComsumptionRate, MINLP_Baseline_RESComsumptionRate,
]

# Define agent names
agent_names = [
    "DQN", "PER-DQN", "DDQN", "Duel-DQN", "NN-DQN",
    "Cat-DQN",
    "MS-DQN",
    "Rainbow-DQN", 'MINLP-Baseline'
]

bar_width = 0.4

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (12, 8)
plt.subplots_adjust(wspace=0.5, hspace=0.5)

# Plotting

plt.subplot(1, 1, 1)
plt.cla()
plt.gca().spines[['top', 'right']].set_visible(False)
bars = plt.bar(agent_names, RESComsumptionRate, color='orange',
               width=bar_width, label='RES Comsumption Rate')
plt.xlabel('DRL Agent', size=35, fontweight='bold')
plt.ylabel('RES Comsumption Rate', size=30, fontweight='bold')
plt.xticks(rotation=45, ha='right', size=15, fontweight='bold')  # Rotate agent names for better readability
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')

plt.legend(loc="best", ncol=1, frameon=True, fontsize='18',
            fancybox=True, framealpha=1, shadow=True, borderpad=1)
ax2 = plt.gca()
for spine in ax2.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax2.xaxis.grid(False)
ax2.yaxis.grid(True)

# Draw line connecting the tops of the bars
max_values_op_costs = [bar.get_height() for bar in bars]
plt.plot(agent_names, max_values_op_costs, marker='o', color='k',
         linewidth=2.5, markersize=8)

output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Cumulative_RESComsumptionRate_All_Models_2021.png')
plt.tight_layout()
plt.show()

print(RESComsumptionRate)

"""###**Visualize the Testing Operation Cost and Grid Unbalance for All Models and The Baseline - WTPV-10%**

**Note:**

This is a Cummulative for 7 different days.

The Test is performed Using Data randomly sampled between December 22 and 31, 2021.

An Initial SOC of 0.3 and Days between 22nd - 28th December, 2021 are used for the Baseline Optmization.
"""

plt.figure(figsize=(15, 9))
plt.gca().set_facecolor("white")
plt.gca().spines[['top', 'right']].set_visible(False)

MINLP_Model_Op_Costs = pd.Series(
    MINLP_Model_Op_Costs, index=pd.date_range(
        start='2021-12-22', periods=len(
            MINLP_Model_Op_Costs), freq='D'))

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_2_Op_Cost, marker='*', linestyle='-', color='maroon',
         label='DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_Rainbow_DQN_Op_Cost, marker='*', linestyle='-',
         color='black', label='Rainbow-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_NStep_Learning_Op_Cost, marker='*', linestyle='-',
         color='purple', label='MS-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_Categorical_DQN_Op_Cost, marker='*', linestyle='-',
         color='red', label='Categorical-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_NoisyNet_Op_Cost, marker='*', linestyle='-',
         color='gold', label='NN-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_DuelingNet_Op_Cost, marker='*', linestyle='-',
         color='teal', label='Duel-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_PER_Op_Cost, marker='*', linestyle='-',
         color='navy', label='PER-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DDQN_Op_Cost, marker='*', linestyle='-',
         color='olive', label='DDQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         MINLP_Model_Op_Costs, marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=20)

plt.xlabel('Days', size=25, fontweight='bold')
plt.ylabel('Cummulative Operation Cost (£)', size=25, fontweight='bold')
plt.xticks(rotation=30, size=15, fontweight='bold')
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')
ax = plt.gca()
# Set linewidth and edge color for each spine
for spine in ax.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax.xaxis.grid(False)  # Remove x-axis grid lines
ax.yaxis.grid(True)
#plt.yscale('log')
plt.legend(loc='best', ncol=3, frameon=True, fontsize='14',
           fancybox=True, framealpha=1, shadow=True, borderpad=1)
# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_Cummulative_OperationCost_During_Testing.png')
plt.tight_layout()
plt.show()

plt.figure(figsize=(15, 9))
plt.gca().set_facecolor("white")
plt.gca().spines[['top', 'right']].set_visible(False)

plt.plot(eval_data_DQN_2_Unbalance, marker='*', linestyle='-', color='maroon',
         label='DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_Rainbow_DQN_Unbalance, marker='*', linestyle='-',
         color='black', label='Rainbow-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DQN_NStep_Learning_Unbalance, marker='*', linestyle='-',
         color='purple', label='MS-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_Categorical_DQN_Unbalance, marker='*', linestyle='-',
         color='red', label='Categorical-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DQN_NoisyNet_Unbalance, marker='*', linestyle='-',
         color='gold', label='NN-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DQN_DuelingNet_Unbalance, marker='*', linestyle='-',
         color='teal', label='Duel-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DQN_PER_Unbalance, marker='*', linestyle='-',
         color='navy', label='PER-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DDQN_Unbalance, marker='*', linestyle='-',
         color='olive', label='DDQN', linewidth=3.5, markersize=20)

plt.xlabel('Days', size=25, fontweight='bold')
plt.ylabel('Cummulative Grid Unbalance (MW)', size=25, fontweight='bold')
plt.xticks(rotation=30, size=15, fontweight='bold')
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')
ax = plt.gca()
# Set linewidth and edge color for each spine
for spine in ax.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax.xaxis.grid(False)  # Remove x-axis grid lines
ax.yaxis.grid(True)
#plt.yscale('log')
plt.legend(loc='best', ncol=3, frameon=True, fontsize='13',
           fancybox=True, framealpha=1, shadow=True, borderpad=1)

plt.axhline(y=0, color='k', linestyle='--', linewidth=3.5)
plt.text(3.2, 2.5, 'Excess Generation - Obtains Benefits', fontsize=25, fontweight='bold', ha='center')
plt.text(3.5, -20.5, 'Shedding Load - Obtains Penalty', fontsize=25, fontweight='bold', ha='center')

# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_Cummulative_GridUnbalance_During_Testing.png')
plt.tight_layout()
plt.show()

"""#**EXPERIMENTAL RESULT ANALYSIS - Operational Scheduling Management (Dispatch Decisions) For The Proposed Model**

**RAINBOW DQN MODEL**
"""

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (16, 12)
fig, axs = plt.subplots(2, 2)
plt.subplots_adjust(wspace=0.5, hspace=0.5)
plt.autoscale(tight=True)

T = np.array([i for i in range(24)])
# plot Netload and Price at first
axs[0, 0].cla()
axs[0, 0].set_facecolor("white")
axs[0, 0].spines[['top', 'right']].set_visible(False)
axs[0, 0].set_ylabel('Price (£/MWh)', size=20, fontweight='bold')
axs[0, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[0, 0].plot(T, eval_data_Rainbow_DQN_day22['price'], label='Price',
            color='orange', linewidth = 4.0, linestyle='solid', drawstyle = 'steps-mid')
#axs[0, 0].legend(loc='best', ncol=1, frameon=True, fontsize='12',
        #fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)
axs_netload = axs[0, 0].twinx()
axs_netload.set_facecolor("white")
axs_netload.spines[['top', 'right']].set_visible(False)
axs_netload.set_ylabel('Netload (MW)', size=20, fontweight='bold')
axs_netload.tick_params(axis='y', rotation=0, labelsize=20)
axs_netload.bar(T, eval_data_Rainbow_DQN_day22['netload'], label='Netload',
             color = 'navy', linewidth = 4.0, align = 'center', width = 0.4)

# Combine legends from both Axes
lines, labels = axs[0, 0].get_legend_handles_labels()
lines_netload, labels_netload = axs_netload.get_legend_handles_labels()
axs_netload.legend(lines + lines_netload, labels + labels_netload,
              loc='best', ncol=1, frameon=True, fontsize='14',
        fancybox=True, framealpha=1, shadow=True, borderpad=2, labelspacing=0.2)
axs[0, 0].set_title('Netload and Price', size=25, fontweight='bold')
axs[0, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[0, 0].tick_params(axis='y', rotation=0, labelsize=15)
axs[0, 0] = plt.gca()
for spine in axs[0, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 0].xaxis.grid(False)
axs[0, 0].yaxis.grid(False)

# Plot Generation and Netload in ax[2]
axs[0, 1].cla()
axs[0, 1].set_facecolor("white")
axs[0, 1].spines[['top', 'right']].set_visible(False)
axs[0, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
axs[0, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_Rainbow_DQN_day22['battery1'])
battery_negative = np.array(eval_data_Rainbow_DQN_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_Rainbow_DQN_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_Rainbow_DQN_day22['unbalance']), 0)

axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['ccgt'], label='CCGT')
axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['coal'], label='COAL',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'])
axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['biomass'], label='BIOMASS',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'])
axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['nuclear'], label='NUCLEAR',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'])
axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['hydro'], label='HYDRO',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'])

axs[0, 1].bar(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[0, 1].bar(T, -battery_negative, label = 'battery discharge', hatch='/',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'] +\
              eval_data_Rainbow_DQN_day22['hydro'])
axs[0, 1].bar(T, -imported_from_grid, label = 'imported from grid',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'] +\
              eval_data_Rainbow_DQN_day22['hydro'] - battery_negative)
axs[0, 1].bar(T, -exported_2_grid, label = 'exported to grid',
              bottom = -battery_positive)

axs[0, 1].plot(T, eval_data_Rainbow_DQN_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 3.0, linestyle='solid')
axs[0, 1].legend(loc='best', ncol=2, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

axs[0, 1].set_title('Outputs of Generating Units - Rainbow DQN Model', size=20, fontweight='bold')
axs[0, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[0, 1].tick_params(axis='y', rotation=0, labelsize=20)
#axs[1] = plt.gca()
for spine in axs[0, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 1].xaxis.grid(False)
axs[0, 1].yaxis.grid(False)

# Plot Generation By Baseline Optimal Solution
axs[1, 0].cla()
axs[1, 0].set_facecolor("white")
axs[1, 0].spines[['top', 'right']].set_visible(False)
axs[1, 0].set_ylabel('Power (MW)', size=25, fontweight='bold')
axs[1, 0].set_xlabel('Time (h)', size=25, fontweight='bold')
battery_positive = np.array(base_result_Day22['battery_energy_change'])
battery_negative = np.array(base_result_Day22['battery_energy_change'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.array(base_result_Day22['grid_import'])
exported_2_grid = np.array(base_result_Day22['grid_export'])

axs[1, 0].bar(T, base_result_Day22['ccgt'], label='CCGT')
axs[1, 0].bar(T, base_result_Day22['coal'], label='COAL',
              bottom = base_result_Day22['ccgt'])
axs[1, 0].bar(T, base_result_Day22['biomass'], label='BIOMASS',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'])
axs[1, 0].bar(T, base_result_Day22['nuclear'], label='NUCLEAR',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'] +\
              base_result_Day22['biomass'])
axs[1, 0].bar(T, base_result_Day22['hydro'], label='HYDRO',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'] +\
              base_result_Day22['biomass'] + base_result_Day22['nuclear'])

axs[1, 0].bar(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[1, 0].bar(T, -battery_negative, label = 'battery discharge', hatch='/',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'] +\
              base_result_Day22['biomass'] + base_result_Day22['nuclear'] +\
              base_result_Day22['hydro'])
axs[1, 0].bar(T, -imported_from_grid, label = 'imported from grid',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'] +\
              base_result_Day22['biomass'] + base_result_Day22['nuclear'] +\
              base_result_Day22['hydro'] - battery_negative)
axs[1, 0].bar(T, -exported_2_grid, label = 'exported to grid',
              bottom = -battery_positive)

axs[1, 0].plot(T, base_result_Day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs[1, 0].legend(loc='best', ncol=2, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

axs[1, 0].set_title('Outputs of Generating Units - Optimal Solution Model', size=20, fontweight='bold')
axs[1, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[1, 0].tick_params(axis='y', rotation=0, labelsize=20)
#axs[1] = plt.gca()
for spine in axs[1, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 0].xaxis.grid(False)
axs[1, 0].yaxis.grid(False)

# plot energy charge/discharge with price in ax[3].
axs[1, 1].cla()
axs[1, 1].set_facecolor("white")
axs[1, 1].spines[['top', 'right']].set_visible(False)
axs[1, 1].set_ylabel('Price (£/MWh)', size=25, fontweight='bold')
axs[1, 1].set_xlabel('Time (h)', size=25, fontweight='bold')

axs[1, 1].plot(T, eval_data_Rainbow_DQN_day22['price'], drawstyle='steps-mid', label='Price',
               color = 'red', linewidth = 4.0, linestyle='solid')
axs[1, 1].legend(loc='best', ncol=1, frameon=True, fontsize='12',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)
axs_soc = axs[1, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=25, fontweight='bold')
axs_soc.plot(T, eval_data_Rainbow_DQN_day22['soc'], drawstyle='steps-mid', label='SOC',
               color = 'grey', linewidth = 4.0, linestyle='solid')
axs_soc.plot(T, base_result_Day22['soc'], drawstyle='steps-mid', label='SOC-Baseline',
               color = 'sienna', linewidth = 4.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[1, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=1, frameon=True, fontsize='14',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

axs[1, 1].set_title('Energy Charge/Discharge With Price', size=25, fontweight='bold')
axs[1, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[1, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[1, 1] = plt.gca()
for spine in axs[1, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 1].xaxis.grid(False)
axs[1, 1].yaxis.grid(False)

# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Proposed_Model_Rainbow_DQN_Performance_During_Testing.png')
plt.tight_layout()
plt.show()

"""**HOURLY OPERATION COST COMPARISON AMONG ALL MODELS**"""

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (22, 20)
fig, axs = plt.subplots(2, 1)
plt.subplots_adjust(wspace=0.6, hspace=0.4)
plt.autoscale(tight=True)

T = np.array([i for i in range(24)])
# plot Netload and Price at first
axs[0].cla()
axs[0].set_facecolor("white")
axs[0].spines[['top', 'right']].set_visible(False)
axs[0].set_ylabel('Netload (MW)', size=35, fontweight='bold')
axs[0].set_xlabel('Time (h)', size=35, fontweight='bold')
axs[0].bar(T, eval_data_DQN_2_day22['netload'], label='Netload',
            color='orange', linewidth = 2.0, align = 'center', width = 0.4)
axs_netload = axs[0].twinx()
axs_netload.set_facecolor("white")
axs_netload.spines[['top', 'right']].set_visible(False)
axs_netload.set_ylabel('Price (£/MWh)', size=35, fontweight='bold')
axs_netload.tick_params(axis='y', rotation=0, labelsize=25)
axs_netload.plot(T, eval_data_DQN_2_day22['price'], label='Price',
             color = 'navy', linewidth = 6.0, linestyle='solid', drawstyle = 'steps-mid')

# Combine legends from both Axes
lines, labels = axs[0].get_legend_handles_labels()
lines_netload, labels_netload = axs_netload.get_legend_handles_labels()
axs[0].legend(lines + lines_netload, labels + labels_netload,
              loc='best', ncol=1, frameon=True, fontsize='20',
        fancybox=True, framealpha=1, shadow=True, borderpad=2, labelspacing=0.3)
axs[0].set_title('Netload and Price', size=35, fontweight='bold')
axs[0].tick_params(axis='x', rotation=30, labelsize=25)
axs[0].tick_params(axis='y', rotation=0, labelsize=25)
axs[0] = plt.gca()
for spine in axs[0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0].xaxis.grid(False)
axs[0].yaxis.grid(True)

# plot Model's Operation Cost here
axs[1].cla()
axs[1].set_facecolor("white")
axs[1].spines[['top', 'right']].set_visible(False)
axs[1].set_ylabel('Operation Cost (£)', size=35, fontweight='bold')
axs[1].set_xlabel('Time (h)', size=35, fontweight='bold')

axs[1].plot(T, eval_data_DQN_2_day22['operation_cost'], label='DQN',
            alpha=1.0, linewidth = 5.0, color = 'gold')
axs[1].plot(T, eval_data_Rainbow_DQN_day22['operation_cost'], label='Rainbow-DQN',
            alpha=1.0, linewidth = 5.0, color = 'olive', drawstyle = 'steps-mid')
axs[1].plot(T, eval_data_DQN_NStep_Learning_day22['operation_cost'], label='MS-DQN',
            alpha=1.0, linewidth = 5.0, color = 'peachpuff')
axs[1].plot(T, eval_data_Categorical_DQN_day22['operation_cost'], label='Categorical-DQN',
            alpha=1.0, linewidth = 5.0, color = 'peru')
axs[1].plot(T, eval_data_DQN_NoisyNet_day22['operation_cost'], label='NN-DQN',
            alpha=1.0, linewidth = 5.0, color = 'darkseagreen')
axs[1].plot(T, eval_data_DQN_DuelingNet_day22['operation_cost'], label='Duel-DQN',
            alpha=1.0, linewidth = 5.0, color = 'dodgerblue')
axs[1].plot(T, eval_data_DQN_PER_day22['operation_cost'], label='PER-DQN',
            alpha=1.0, linewidth = 5.0, color = 'darkorange')
axs[1].plot(T, eval_data_DDQN_day22['operation_cost'], label='DDQN',
            alpha=1.0, linewidth = 5.0, color = 'black', linestyle='-')
axs[1].plot(T, base_result_Day22['step_cost'], label='MINLP-Baseline',
            alpha=1.0, linewidth = 5.0, color = 'navy', linestyle='--')

axs[1].set_title('Hourly Operation Cost',
                  size=35, fontweight='bold')
axs[1].tick_params(axis='x', rotation=30, labelsize=25)
axs[1].tick_params(axis='y', rotation=0, labelsize=25)
axs[1].legend(loc='best', ncol=3, frameon=True, fontsize='16',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)
for spine in axs[1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1].xaxis.grid(False)
axs[1].yaxis.grid(True)
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_OperationCost_During_Testing.png',
            format='svg', dpi=600, bbox_inches='tight')
plt.tight_layout()
plt.show()

"""**Cummulative Hourly Operation Cost for All Algorithms**"""

DQN_cum_epi_opcost = sum(eval_data_DQN_2_day22['operation_cost'])
DDQN_cum_epi_opcost = sum(eval_data_DDQN_day22['operation_cost'])
DQN_PER_cum_epi_opcost = sum(eval_data_DQN_PER_day22['operation_cost'])
DQN_DuelingNet_cum_epi_opcost = sum(eval_data_DQN_DuelingNet_day22['operation_cost'])
DQN_NoisyNet_cum_epi_opcost = sum(eval_data_DQN_NoisyNet_day22['operation_cost'])
Categorical_DQN_cum_epi_opcost = sum(eval_data_Categorical_DQN_day22['operation_cost'])
DQN_NStep_Learning_cum_epi_opcost = sum(eval_data_DQN_NStep_Learning_day22['operation_cost'])
Rainbow_DQN_cum_epi_opcost = sum(eval_data_Rainbow_DQN_day22['operation_cost'])
MINLP_Baseline = sum(base_result_Day22['step_cost'])
# Define the cumulative values

cumulative_op_costs = [
    DQN_cum_epi_opcost, DQN_PER_cum_epi_opcost, DDQN_cum_epi_opcost,
    DQN_DuelingNet_cum_epi_opcost, DQN_NoisyNet_cum_epi_opcost,
    Categorical_DQN_cum_epi_opcost,
    DQN_NStep_Learning_cum_epi_opcost,
    Rainbow_DQN_cum_epi_opcost, MINLP_Baseline,
]

# Define agent names
agent_names = [
    "DQN", "PER-DQN", "DDQN", "Duel-DQN", "NN-DQN",
    "Cat-DQN",
    "MS-DQN",
    "Rainbow-DQN", 'MINLP-Baseline'
]

bar_width = 0.4

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (20, 15)
plt.subplots_adjust(wspace=0.5, hspace=0.5)

# Plotting

plt.subplot(2, 2, 1)
plt.cla()
plt.gca().spines[['top', 'right']].set_visible(False)
bars = plt.bar(agent_names, cumulative_op_costs, color='orange',
               width=bar_width, label='Cumulative Operation Cost')
plt.xlabel('DRL Agent', size=35, fontweight='bold')
plt.ylabel('Cumulative Operation Cost (£)', size=30, fontweight='bold')
plt.xticks(rotation=45, ha='right', size=15, fontweight='bold')  # Rotate agent names for better readability
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')

plt.legend(loc="best", ncol=1, frameon=True, fontsize='18',
            fancybox=True, framealpha=1, shadow=True, borderpad=1)
ax2 = plt.gca()
for spine in ax2.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax2.xaxis.grid(False)
ax2.yaxis.grid(True)

# Draw line connecting the tops of the bars
max_values_op_costs = [bar.get_height() for bar in bars]
plt.plot(agent_names, max_values_op_costs, marker='o', color='k',
         linewidth=2.5, markersize=8)

plt.subplot(2, 2, 2)
plt.cla()
plt.gca().spines[['top', 'right']].set_visible(False)
plt.plot(agent_names, cumulative_op_costs, marker='o', color='k',
         linewidth=2.5, markersize=8, label='Cumulative Operation Cost')
plt.xlabel('DRL Agent', size=35, fontweight='bold')
plt.ylabel('Cumulative Operation Cost (£)', size=30, fontweight='bold')
plt.xticks(rotation=45, ha='right', size=15, fontweight='bold')  # Rotate agent names for better readability
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')

plt.legend(loc="best", ncol=1, frameon=True, fontsize='18',
            fancybox=True, framealpha=1, shadow=True, borderpad=1)

ax1 = plt.gca()
for spine in ax1.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax1.xaxis.grid(False)
ax1.yaxis.grid(True)

output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Cumulative_Operation_Cost_All_Models_2021.png')
plt.tight_layout()
plt.show()

print(cumulative_op_costs)

"""###**Scheduled BESS Energy Charge and Discharge Vs SOC For All Models Compared to the Baseline**"""

plt.rcParams["figure.figsize"] = (15, 15)
fig, axs = plt.subplots(4, 2)
plt.subplots_adjust(wspace=0.5, hspace=0.5)
plt.autoscale(tight=True)

T = np.array([i for i in range(24)])

# RainBow Vs Baseline
axs[0, 0].set_facecolor("white")
axs[0, 0].spines[['top', 'right']].set_visible(False)
axs[0, 0].cla()
axs[0, 0].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[0, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[0, 0].plot(T, eval_data_Rainbow_DQN_day22['battery1'], marker='*', linestyle='-',
         color='red', label='Rainbow-DQN', linewidth=3.5, markersize=8)
axs[0, 0].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[0, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_Rainbow_DQN_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[0, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[0, 0].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[0, 0].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[0, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[0, 0].tick_params(axis='y', rotation=0, labelsize=15)

axs[0, 0] = plt.gca()
for spine in axs[0, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 0].xaxis.grid(False)
axs[0, 0].yaxis.grid(False)

# DQN+NOISE Vs Baseline
axs[0, 1].set_facecolor("white")
axs[0, 1].spines[['top', 'right']].set_visible(False)
axs[0, 1].cla()
axs[0, 1].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[0, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[0, 1].plot(T, eval_data_DQN_NoisyNet_day22['battery1'], marker='*', linestyle='-',
         color='red', label='NN-DQN', linewidth=3.5, markersize=8)
axs[0, 1].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[0, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_NoisyNet_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[0, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[0, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[0, 1].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[0, 1].tick_params(axis='x', rotation=30, labelsize=15)
axs[0, 1].tick_params(axis='y', rotation=0, labelsize=15)

axs[0, 1] = plt.gca()
for spine in axs[0, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 1].xaxis.grid(False)
axs[0, 1].yaxis.grid(False)

# DQN+DUEL Vs Baseline
axs[1, 0].set_facecolor("white")
axs[1, 0].spines[['top', 'right']].set_visible(False)
axs[1, 0].cla()
axs[1, 0].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[1, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[1, 0].plot(T, eval_data_DQN_DuelingNet_day22['battery1'], marker='*', linestyle='-',
         color='red', label='Duel-DQN', linewidth=3.5, markersize=8)
axs[1, 0].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[1, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_DuelingNet_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[1, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 0].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[1, 0].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[1, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[1, 0].tick_params(axis='y', rotation=0, labelsize=15)

axs[1, 0] = plt.gca()
for spine in axs[1, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 0].xaxis.grid(False)
axs[1, 0].yaxis.grid(False)

# DDQN Vs Baseline
axs[1, 1].set_facecolor("white")
axs[1, 1].spines[['top', 'right']].set_visible(False)
axs[1, 1].cla()
axs[1, 1].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[1, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[1, 1].plot(T, eval_data_DDQN_day22['battery1'], marker='*', linestyle='-',
         color='red', label='DDQN', linewidth=3.5, markersize=8)
axs[1, 1].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[1, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DDQN_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[1, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[1, 1].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[1, 1].tick_params(axis='x', rotation=30, labelsize=15)
axs[1, 1].tick_params(axis='y', rotation=0, labelsize=15)

axs[1, 1] = plt.gca()
for spine in axs[1, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 1].xaxis.grid(False)
axs[1, 1].yaxis.grid(False)

# DQN+PER Vs Baseline
axs[2, 0].set_facecolor("white")
axs[2, 0].spines[['top', 'right']].set_visible(False)
axs[2, 0].cla()
axs[2, 0].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[2, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[2, 0].plot(T, eval_data_DQN_PER_day22['battery1'], marker='*', linestyle='-',
         color='red', label='PER-DQN', linewidth=3.5, markersize=8)
axs[2, 0].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[2, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_PER_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[2, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[2, 0].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[2, 0].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[2, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[2, 0].tick_params(axis='y', rotation=0, labelsize=15)

axs[2, 0] = plt.gca()
for spine in axs[2, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[2, 0].xaxis.grid(False)
axs[2, 0].yaxis.grid(False)

# DQN+NStep-Learning Vs Baseline
axs[2, 1].set_facecolor("white")
axs[2, 1].spines[['top', 'right']].set_visible(False)
axs[2, 1].cla()
axs[2, 1].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[2, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[2, 1].plot(T, eval_data_DQN_NStep_Learning_day22['battery1'], marker='*', linestyle='-',
         color='red', label='MS-DQN', linewidth=3.5, markersize=8)
axs[2, 1].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[2, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_NStep_Learning_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[2, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[2, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[2, 1].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[2, 1].tick_params(axis='x', rotation=30, labelsize=15)
axs[2, 1].tick_params(axis='y', rotation=0, labelsize=15)

axs[2, 1] = plt.gca()
for spine in axs[2, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[2, 1].xaxis.grid(False)
axs[2, 1].yaxis.grid(False)

# DQN Vs Baseline
axs[3, 0].set_facecolor("white")
axs[3, 0].spines[['top', 'right']].set_visible(False)
axs[3, 0].cla()
axs[3, 0].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[3, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[3, 0].plot(T, eval_data_DQN_2_day22['battery1'], marker='*', linestyle='-',
         color='red', label='DQN', linewidth=3.5, markersize=8)
axs[3, 0].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[3, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_2_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[3, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[3, 0].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[3, 0].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[3, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[3, 0].tick_params(axis='y', rotation=0, labelsize=15)

axs[3, 0] = plt.gca()
for spine in axs[3, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[3, 0].xaxis.grid(False)
axs[3, 0].yaxis.grid(False)

# CategoricalDQN Vs Baseline
axs[3, 1].set_facecolor("white")
axs[3, 1].spines[['top', 'right']].set_visible(False)
axs[3, 1].cla()
axs[3, 1].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[3, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[3, 1].plot(T, eval_data_Categorical_DQN_day22['battery1'], marker='*', linestyle='-',
         color='red', label='Categorical-DQN', linewidth=3.5, markersize=8)
axs[3, 1].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[3, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_Categorical_DQN_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[3, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[3, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[3, 1].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[3, 1].tick_params(axis='x', rotation=30, labelsize=15)
axs[3, 1].tick_params(axis='y', rotation=0, labelsize=15)

axs[3, 1] = plt.gca()
for spine in axs[3, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[3, 1].xaxis.grid(False)
axs[3, 1].yaxis.grid(False)

# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_BESS_Change_VS_SOC_During_Testing.png')
plt.tight_layout()
plt.show()

plt.rcParams["figure.figsize"] = (15, 15)
fig, axs = plt.subplots(4, 2)
plt.subplots_adjust(wspace=0.8, hspace=0.8)
plt.autoscale(tight=True)

T = np.array([i for i in range(24)])

# RainBow
axs[0, 0].set_facecolor("white")
axs[0, 0].spines[['top', 'right']].set_visible(False)
axs[0, 0].cla()
axs[0, 0].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[0, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_Rainbow_DQN_day22['battery1'])
battery_negative = np.array(eval_data_Rainbow_DQN_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_Rainbow_DQN_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_Rainbow_DQN_day22['unbalance']), 0)

axs[0, 0].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple', alpha=0.3)
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'] +\
              eval_data_Rainbow_DQN_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'] +\
              eval_data_Rainbow_DQN_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[0, 0].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'],
                       eval_data_Rainbow_DQN_day22['hydro'], label='HYDRO', color='green')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'],
                       eval_data_Rainbow_DQN_day22['nuclear'], label='NUCLEAR', color='red')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'],
                       eval_data_Rainbow_DQN_day22['biomass'], label='BIOMASS', color='violet')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'], eval_data_Rainbow_DQN_day22['coal'],
                       label='COAL', color='seagreen')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'], label='CCGT', color='gray')
axs[0, 0].plot(T, eval_data_Rainbow_DQN_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[0, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_Rainbow_DQN_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[0, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[0, 0].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[0, 0].set_xticks([])
axs[0, 0].set_title('Rainbow DQN',
                    size=20, fontweight='bold')
#axs[0, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[0, 0].tick_params(axis='y', rotation=0, labelsize=20)
axs[0, 0] = plt.gca()
for spine in axs[0, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 0].xaxis.grid(False)
axs[0, 0].yaxis.grid(False)

# DQN+NOISE
axs[0, 1].set_facecolor("white")
axs[0, 1].spines[['top', 'right']].set_visible(False)
axs[0, 1].cla()
axs[0, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[0, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_NoisyNet_day22['battery1'])
battery_negative = np.array(eval_data_DQN_NoisyNet_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_NoisyNet_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_NoisyNet_day22['unbalance']), 0)

axs[0, 1].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'] +\
              eval_data_DQN_NoisyNet_day22['biomass'] + eval_data_DQN_NoisyNet_day22['nuclear'] +\
              eval_data_DQN_NoisyNet_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'] +\
              eval_data_DQN_NoisyNet_day22['biomass'] + eval_data_DQN_NoisyNet_day22['nuclear'] +\
              eval_data_DQN_NoisyNet_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[0, 1].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'] +\
              eval_data_DQN_NoisyNet_day22['biomass'] + eval_data_DQN_NoisyNet_day22['nuclear'],
                       eval_data_DQN_NoisyNet_day22['hydro'], label='HYDRO', color='green')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'] +\
              eval_data_DQN_NoisyNet_day22['biomass'],
                       eval_data_DQN_NoisyNet_day22['nuclear'], label='NUCLEAR', color='red')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'],
                       eval_data_DQN_NoisyNet_day22['biomass'], label='BIOMASS', color='violet')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'], eval_data_DQN_NoisyNet_day22['coal'],
                       label='COAL', color='seagreen')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'], label='CCGT', color='gray')
axs[0, 1].plot(T, eval_data_DQN_NoisyNet_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[0, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_NoisyNet_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[0, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[0, 1].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[0, 1].set_xticks([])
axs[0, 1].set_title('NN-DQN', size=20,
                    fontweight='bold')
#axs[0, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[0, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[0, 1] = plt.gca()
for spine in axs[0, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 1].xaxis.grid(False)
axs[0, 1].yaxis.grid(False)

# DQN+DUEL eval_data_DQN_DuelingNet_day22
axs[1, 0].set_facecolor("white")
axs[1, 0].spines[['top', 'right']].set_visible(False)
axs[1, 0].cla()
axs[1, 0].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[1, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_DuelingNet_day22['battery1'])
battery_negative = np.array(eval_data_DQN_DuelingNet_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_DuelingNet_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_DuelingNet_day22['unbalance']), 0)

axs[1, 0].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'] +\
              eval_data_DQN_DuelingNet_day22['biomass'] + eval_data_DQN_DuelingNet_day22['nuclear'] +\
              eval_data_DQN_DuelingNet_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'] +\
              eval_data_DQN_DuelingNet_day22['biomass'] + eval_data_DQN_DuelingNet_day22['nuclear'] +\
              eval_data_DQN_DuelingNet_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[1, 0].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'] +\
              eval_data_DQN_DuelingNet_day22['biomass'] + eval_data_DQN_DuelingNet_day22['nuclear'],
                       eval_data_DQN_DuelingNet_day22['hydro'], label='HYDRO', color='green')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'] +\
              eval_data_DQN_DuelingNet_day22['biomass'],
                       eval_data_DQN_DuelingNet_day22['nuclear'], label='NUCLEAR', color='red')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'],
                       eval_data_DQN_DuelingNet_day22['biomass'], label='BIOMASS', color='violet')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'], eval_data_DQN_DuelingNet_day22['coal'],
                       label='COAL', color='seagreen')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'], label='CCGT', color='gray')
axs[1, 0].plot(T, eval_data_DQN_DuelingNet_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[1, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_DuelingNet_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[1, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 0].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[1, 0].set_xticks([])
axs[1, 0].set_title('Duel-DQN', size=20,
                    fontweight='bold', y = 0.9)
#axs[1, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[1, 0].tick_params(axis='y', rotation=0, labelsize=20)
axs[1, 0] = plt.gca()
for spine in axs[1, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 0].xaxis.grid(False)
axs[1, 0].yaxis.grid(False)

# DDQN
axs[1, 1].set_facecolor("white")
axs[1, 1].spines[['top', 'right']].set_visible(False)
axs[1, 1].cla()
axs[1, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[1, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DDQN_day22['battery1'])
battery_negative = np.array(eval_data_DDQN_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DDQN_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DDQN_day22['unbalance']), 0)

axs[1, 1].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'] +\
              eval_data_DDQN_day22['biomass'] + eval_data_DDQN_day22['nuclear'] +\
              eval_data_DDQN_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'] +\
              eval_data_DDQN_day22['biomass'] + eval_data_DDQN_day22['nuclear'] +\
              eval_data_DDQN_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[1, 1].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'] +\
              eval_data_DDQN_day22['biomass'] + eval_data_DDQN_day22['nuclear'],
                       eval_data_DDQN_day22['hydro'], label='HYDRO', color='green')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'] +\
              eval_data_DDQN_day22['biomass'],
                       eval_data_DDQN_day22['nuclear'], label='NUCLEAR', color='red')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'],
                       eval_data_DDQN_day22['biomass'], label='BIOMASS', color='violet')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'], eval_data_DDQN_day22['coal'],
                       label='COAL', color='seagreen')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'], label='CCGT', color='gray')
axs[1, 1].plot(T, eval_data_DDQN_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[1, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DDQN_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[1, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 1].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[1, 1].set_xticks([])
axs[1, 1].set_title('DDQN', size=20,
                    fontweight='bold', y = 0.9)
#axs[1, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[1, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[1, 1] = plt.gca()
for spine in axs[1, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 1].xaxis.grid(False)
axs[1, 1].yaxis.grid(False)

# DQN+PER
axs[2, 0].set_facecolor("white")
axs[2, 0].spines[['top', 'right']].set_visible(False)
axs[2, 0].cla()
axs[2, 0].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[2, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_PER_day22['battery1'])
battery_negative = np.array(eval_data_DQN_PER_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_PER_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_PER_day22['unbalance']), 0)

axs[2, 0].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'] +\
              eval_data_DQN_PER_day22['biomass'] + eval_data_DQN_PER_day22['nuclear'] +\
              eval_data_DQN_PER_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'] +\
              eval_data_DQN_PER_day22['biomass'] + eval_data_DQN_PER_day22['nuclear'] +\
              eval_data_DQN_PER_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[2, 0].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'] +\
              eval_data_DQN_PER_day22['biomass'] + eval_data_DQN_PER_day22['nuclear'],
                       eval_data_DQN_PER_day22['hydro'], label='HYDRO', color='green')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'] +\
              eval_data_DQN_PER_day22['biomass'],
                       eval_data_DQN_PER_day22['nuclear'], label='NUCLEAR', color='red')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'],
                       eval_data_DQN_PER_day22['biomass'], label='BIOMASS', color='violet')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'], eval_data_DQN_PER_day22['coal'],
                       label='COAL', color='seagreen')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'], label='CCGT', color='gray')
axs[2, 0].plot(T, eval_data_DQN_PER_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[2, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_PER_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[2, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[2, 0].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[2, 0].set_xticks([])
axs[2, 0].set_title('PER-DQN', size=20,
                    fontweight='bold', y = 0.9)
#axs[2, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[2, 0].tick_params(axis='y', rotation=0, labelsize=20)
axs[2, 0] = plt.gca()
for spine in axs[2, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[2, 0].xaxis.grid(False)
axs[2, 0].yaxis.grid(False)

# DQN+NStep-Learning
axs[2, 1].set_facecolor("white")
axs[2, 1].spines[['top', 'right']].set_visible(False)
axs[2, 1].cla()
axs[2, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[2, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_NStep_Learning_day22['battery1'])
battery_negative = np.array(eval_data_DQN_NStep_Learning_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_NStep_Learning_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_NStep_Learning_day22['unbalance']), 0)

axs[2, 1].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'] +\
              eval_data_DQN_NStep_Learning_day22['biomass'] + eval_data_DQN_NStep_Learning_day22['nuclear'] +\
              eval_data_DQN_NStep_Learning_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'] +\
              eval_data_DQN_NStep_Learning_day22['biomass'] + eval_data_DQN_NStep_Learning_day22['nuclear'] +\
              eval_data_DQN_NStep_Learning_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[2, 1].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'] +\
              eval_data_DQN_NStep_Learning_day22['biomass'] + eval_data_DQN_NStep_Learning_day22['nuclear'],
                       eval_data_DQN_NStep_Learning_day22['hydro'], label='HYDRO', color='green')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'] +\
              eval_data_DQN_NStep_Learning_day22['biomass'],
                       eval_data_DQN_NStep_Learning_day22['nuclear'], label='NUCLEAR', color='red')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'],
                       eval_data_DQN_NStep_Learning_day22['biomass'], label='BIOMASS', color='violet')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'], eval_data_DQN_NStep_Learning_day22['coal'],
                       label='COAL', color='seagreen')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'], label='CCGT', color='gray')
axs[2, 1].plot(T, eval_data_DQN_NStep_Learning_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[2, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_NStep_Learning_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[2, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[2, 1].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[2, 1].set_xticks([])
axs[2, 1].set_title('MS-DQN', size=20,
                    fontweight='bold', y = 0.9)
#axs[2, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[2, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[2, 1] = plt.gca()
for spine in axs[2, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[2, 1].xaxis.grid(False)
axs[2, 1].yaxis.grid(False)

# DQN
axs[3, 0].set_facecolor("white")
axs[3, 0].spines[['top', 'right']].set_visible(False)
axs[3, 0].cla()
axs[3, 0].set_ylabel('Power (MW)', size=20, fontweight='bold')
axs[3, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_2_day22['battery1'])
battery_negative = np.array(eval_data_DQN_2_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_2_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_2_day22['unbalance']), 0)

axs[3, 0].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'] +\
              eval_data_DQN_2_day22['biomass'] + eval_data_DQN_2_day22['nuclear'] +\
              eval_data_DQN_2_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'] +\
              eval_data_DQN_2_day22['biomass'] + eval_data_DQN_2_day22['nuclear'] +\
              eval_data_DQN_2_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[3, 0].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'] +\
              eval_data_DQN_2_day22['biomass'] + eval_data_DQN_2_day22['nuclear'],
                       eval_data_DQN_2_day22['hydro'], label='HYDRO', color='green')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'] +\
              eval_data_DQN_2_day22['biomass'],
                       eval_data_DQN_2_day22['nuclear'], label='NUCLEAR', color='red')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'],
                       eval_data_DQN_2_day22['biomass'], label='BIOMASS', color='violet')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'], eval_data_DQN_2_day22['coal'],
                       label='COAL', color='seagreen')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'], label='CCGT', color='gray')
axs[3, 0].plot(T, eval_data_DQN_2_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[3, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_2_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[3, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[3, 0].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.46), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)

axs[3, 0].set_title('DQN', size=20,
                    fontweight='bold', y = 0.9)
axs[3, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[3, 0].tick_params(axis='y', rotation=0, labelsize=20)
axs[3, 0] = plt.gca()
for spine in axs[3, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[3, 0].xaxis.grid(False)
axs[3, 0].yaxis.grid(False)

# CategoricalDQN
axs[3, 1].set_facecolor("white")
axs[3, 1].spines[['top', 'right']].set_visible(False)
axs[3, 1].cla()
axs[3, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
axs[3, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_Categorical_DQN_day22['battery1'])
battery_negative = np.array(eval_data_Categorical_DQN_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_Categorical_DQN_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_Categorical_DQN_day22['unbalance']), 0)

axs[3, 1].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'] +\
              eval_data_Categorical_DQN_day22['biomass'] + eval_data_Categorical_DQN_day22['nuclear'] +\
              eval_data_Categorical_DQN_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'] +\
              eval_data_Categorical_DQN_day22['biomass'] + eval_data_Categorical_DQN_day22['nuclear'] +\
              eval_data_Categorical_DQN_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[3, 1].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'] +\
              eval_data_Categorical_DQN_day22['biomass'] + eval_data_Categorical_DQN_day22['nuclear'],
                       eval_data_Categorical_DQN_day22['hydro'], label='HYDRO', color='green')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'] +\
              eval_data_Categorical_DQN_day22['biomass'],
                       eval_data_Categorical_DQN_day22['nuclear'], label='NUCLEAR', color='red')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'],
                       eval_data_Categorical_DQN_day22['biomass'], label='BIOMASS', color='violet')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'], eval_data_Categorical_DQN_day22['coal'],
                       label='COAL', color='seagreen')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'], label='CCGT', color='gray')
axs[3, 1].plot(T, eval_data_Categorical_DQN_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[3, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_Categorical_DQN_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[3, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[3, 1].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.46), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)

axs[3, 1].set_title('Categorical-DQN', size=20,
                    fontweight='bold', y = 0.9)
axs[3, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[3, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[3, 1] = plt.gca()
for spine in axs[3, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[3, 1].xaxis.grid(False)
axs[3, 1].yaxis.grid(False)

# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Operational_Scheduling_Management_of_all_Models_During_Testing.png')
plt.tight_layout()
plt.show()

"""**Cummulative Operation Cost Savings Relative to The Baseline Network - DQN**"""

# Day 22
dqn22 = eval_data_DQN_2_day22['operation_cost']
rainbow22 = eval_data_Rainbow_DQN_day22['operation_cost']
dqn_nstep22 = eval_data_DQN_NStep_Learning_day22['operation_cost']
categorical_dqn22 = eval_data_Categorical_DQN_day22['operation_cost']
dqn_noise22 = eval_data_DQN_NoisyNet_day22['operation_cost']
dqn_duel22 = eval_data_DQN_DuelingNet_day22['operation_cost']
dqn_per22 = eval_data_DQN_PER_day22['operation_cost']
ddqn22 = eval_data_DDQN_day22['operation_cost']
minlp22 = base_result_Day22['step_cost']
# Day 23
dqn23 = eval_data_DQN_2_day23['operation_cost']
rainbow23 = eval_data_Rainbow_DQN_day23['operation_cost']
dqn_nstep23 = eval_data_DQN_NStep_Learning_day23['operation_cost']
categorical_dqn23 = eval_data_Categorical_DQN_day23['operation_cost']
dqn_noise23 = eval_data_DQN_NoisyNet_day23['operation_cost']
dqn_duel23 = eval_data_DQN_DuelingNet_day23['operation_cost']
dqn_per23 = eval_data_DQN_PER_day23['operation_cost']
ddqn23 = eval_data_DDQN_day23['operation_cost']
minlp23 = base_result_Day23['step_cost']
# Day 24
dqn24 = eval_data_DQN_2_day24['operation_cost']
rainbow24 = eval_data_Rainbow_DQN_day24['operation_cost']
dqn_nstep24 = eval_data_DQN_NStep_Learning_day24['operation_cost']
categorical_dqn24 = eval_data_Categorical_DQN_day24['operation_cost']
dqn_noise24 = eval_data_DQN_NoisyNet_day24['operation_cost']
dqn_duel24 = eval_data_DQN_DuelingNet_day24['operation_cost']
dqn_per24 = eval_data_DQN_PER_day24['operation_cost']
ddqn24 = eval_data_DDQN_day24['operation_cost']
minlp24 = base_result_Day24['step_cost']
# Day 25
dqn25 = eval_data_DQN_2_day25['operation_cost']
rainbow25 = eval_data_Rainbow_DQN_day25['operation_cost']
dqn_nstep25 = eval_data_DQN_NStep_Learning_day25['operation_cost']
categorical_dqn25 = eval_data_Categorical_DQN_day25['operation_cost']
dqn_noise25 = eval_data_DQN_NoisyNet_day25['operation_cost']
dqn_duel25 = eval_data_DQN_DuelingNet_day25['operation_cost']
dqn_per25 = eval_data_DQN_PER_day25['operation_cost']
ddqn25 = eval_data_DDQN_day25['operation_cost']
minlp25 = base_result_Day25['step_cost']
# Day 26
dqn26 = eval_data_DQN_2_day26['operation_cost']
rainbow26 = eval_data_Rainbow_DQN_day26['operation_cost']
dqn_nstep26 = eval_data_DQN_NStep_Learning_day26['operation_cost']
categorical_dqn26 = eval_data_Categorical_DQN_day26['operation_cost']
dqn_noise26 = eval_data_DQN_NoisyNet_day26['operation_cost']
dqn_duel26 = eval_data_DQN_DuelingNet_day26['operation_cost']
dqn_per26 = eval_data_DQN_PER_day26['operation_cost']
ddqn26 = eval_data_DDQN_day26['operation_cost']
minlp26 = base_result_Day26['step_cost']
# Day 27
dqn27 = eval_data_DQN_2_day27['operation_cost']
rainbow27 = eval_data_Rainbow_DQN_day27['operation_cost']
dqn_nstep27 = eval_data_DQN_NStep_Learning_day27['operation_cost']
categorical_dqn27 = eval_data_Categorical_DQN_day27['operation_cost']
dqn_noise27 = eval_data_DQN_NoisyNet_day27['operation_cost']
dqn_duel27 = eval_data_DQN_DuelingNet_day27['operation_cost']
dqn_per27 = eval_data_DQN_PER_day27['operation_cost']
ddqn27 = eval_data_DDQN_day27['operation_cost']
minlp27 = base_result_Day27['step_cost']
# Day 28
dqn28 = eval_data_DQN_2_day28['operation_cost']
rainbow28 = eval_data_Rainbow_DQN_day28['operation_cost']
dqn_nstep28 = eval_data_DQN_NStep_Learning_day28['operation_cost']
categorical_dqn28 = eval_data_Categorical_DQN_day28['operation_cost']
dqn_noise28 = eval_data_DQN_NoisyNet_day28['operation_cost']
dqn_duel28 = eval_data_DQN_DuelingNet_day28['operation_cost']
dqn_per28 = eval_data_DQN_PER_day28['operation_cost']
ddqn28 = eval_data_DDQN_day28['operation_cost']
minlp28 = base_result_Day28['step_cost']

# concatenate
dqn = pd.concat([dqn22, dqn23, dqn24, dqn25, dqn26, dqn27, dqn28], axis=0)
rainbow = pd.concat([rainbow22, rainbow23, rainbow24, rainbow25, rainbow26, rainbow27, rainbow28],
                    axis=0)
dqn_nstep = pd.concat([dqn_nstep22, dqn_nstep23, dqn_nstep24, dqn_nstep25, dqn_nstep26, dqn_nstep27, dqn_nstep28],
                      axis=0)
categorical_dqn = pd.concat([categorical_dqn22, categorical_dqn23, categorical_dqn24, categorical_dqn25,
                             categorical_dqn26, categorical_dqn27, categorical_dqn28],
                             axis=0)
dqn_noise = pd.concat([dqn_noise22, dqn_noise23, dqn_noise24, dqn_noise25, dqn_noise26,
                       dqn_noise27, dqn_noise28], axis=0)
dqn_duel = pd.concat([dqn_duel22, dqn_duel23, dqn_duel24, dqn_duel25, dqn_duel26,
                      dqn_duel27, dqn_duel28], axis=0)
dqn_per = pd.concat([dqn_per22, dqn_per23, dqn_per24, dqn_per25, dqn_per26,
                     dqn_per27, dqn_per28], axis=0)
ddqn = pd.concat([ddqn22, ddqn23, ddqn24, ddqn25, ddqn26, ddqn27, ddqn28], axis=0)
minlp = pd.concat([minlp22, minlp23, minlp24, minlp25, minlp26, minlp27,
                   minlp28], axis=0)

# Operation Cost Savings
dqn_savings = dqn - dqn
rainbow_savings = dqn - rainbow
dqn_nstep_savings = dqn - dqn_nstep
categorical_dqn_savings = dqn - categorical_dqn
dqn_noise_savings = dqn - dqn_noise
dqn_duel_savings = dqn - dqn_duel
dqn_per_savings = dqn - dqn_per
ddqn_savings = dqn - ddqn
minlp_savings = dqn - minlp

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (22, 20)
fig, axs = plt.subplots(1, 1)
plt.subplots_adjust(wspace=0.6, hspace=0.4)
plt.autoscale(tight=True)

T = np.array([i for i in range(168)])

axs.set_facecolor("white")
axs.spines[['top', 'right']].set_visible(False)
axs.cla()
axs.set_ylabel('Operation Cost Savings (£)', size=35, fontweight='bold')
axs.set_xlabel('Time (h)', size=35, fontweight='bold')

axs.plot(T, rainbow_savings, label='Rainbow-DQN',
            alpha=1.0, linewidth = 5.0, color = 'olive', drawstyle = 'steps-mid')
axs.plot(T, dqn_nstep_savings, label='MS-DQN',
            alpha=1.0, linewidth = 5.0, color = 'peachpuff', drawstyle = 'steps-mid')
axs.plot(T, categorical_dqn_savings, label='Categorical-DQN',
            alpha=1.0, linewidth = 5.0, color = 'peru', drawstyle = 'steps-mid')
axs.plot(T, dqn_noise_savings, label='NN-DQN',
            alpha=1.0, linewidth = 5.0, color = 'darkseagreen', drawstyle = 'steps-mid')
axs.plot(T, dqn_duel_savings, label='Duel-DQN',
            alpha=1.0, linewidth = 5.0, color = 'dodgerblue', drawstyle = 'steps-mid')
axs.plot(T, dqn_per_savings, label='PER-DQN',
            alpha=1.0, linewidth = 5.0, color = 'darkorange', drawstyle = 'steps-mid')
axs.plot(T, ddqn_savings, label='DDQN',
            alpha=1.0, linewidth = 5.0, color = 'navy', linestyle='-', drawstyle = 'steps-mid')
axs.plot(T, minlp_savings, label='MINLP-Baseline',
            alpha=1.0, linewidth = 5.0, color = 'gold', linestyle='-', drawstyle = 'steps-mid')
axs.plot(T, dqn_savings, label='DQN',
            alpha=1.0, linewidth = 7.0, color = 'black', linestyle='-.', drawstyle = 'steps-mid')

axs.tick_params(axis='x', rotation=30, labelsize=25)
axs.tick_params(axis='y', rotation=0, labelsize=25)
axs.legend(loc='best', ncol=3, frameon=True, fontsize='18',
        fancybox=True, framealpha=1, shadow=True, borderpad=2, labelspacing=0.3)
axs = plt.gca()
for spine in axs.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs.xaxis.grid(False)
axs.yaxis.grid(False)
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_OperationCost_Savings_During_Testing.png',
            format='svg', dpi=600, bbox_inches='tight')
plt.tight_layout()
plt.show()

"""**Compute All Algorithm's Ability to Utilize RES - Total Consumption Rate of RES**

Larger is better!
"""

DQN_cum_pv = sum(eval_data_DQN_2_day22['pv'])
DDQN_cum_pv = sum(eval_data_DDQN_day22['pv'])
DQN_PER_cum_pv = sum(eval_data_DQN_PER_day22['pv'])
DQN_DuelingNet_cum_pv = sum(eval_data_DQN_DuelingNet_day22['pv'])
DQN_NoisyNet_cum_pv = sum(eval_data_DQN_NoisyNet_day22['pv'])
Categorical_DQN_cum_pv = sum(eval_data_Categorical_DQN_day22['pv'])
DQN_NStep_Learning_cum_pv = sum(eval_data_DQN_NStep_Learning_day22['pv'])
Rainbow_DQN_cum_pv = sum(eval_data_Rainbow_DQN_day22['pv'])
MINLP_Baseline_pv = sum(base_result_Day22['pv'])

DQN_cum_onwind = sum(eval_data_DQN_2_day22['onwind'])
DDQN_cum_onwind = sum(eval_data_DDQN_day22['onwind'])
DQN_PER_cum_onwind = sum(eval_data_DQN_PER_day22['onwind'])
DQN_DuelingNet_cum_onwind = sum(eval_data_DQN_DuelingNet_day22['onwind'])
DQN_NoisyNet_cum_onwind = sum(eval_data_DQN_NoisyNet_day22['onwind'])
Categorical_DQN_cum_onwind = sum(eval_data_Categorical_DQN_day22['onwind'])
DQN_NStep_Learning_cum_onwind = sum(eval_data_DQN_NStep_Learning_day22['onwind'])
Rainbow_DQN_cum_onwind = sum(eval_data_Rainbow_DQN_day22['onwind'])
MINLP_Baseline_onwind = sum(base_result_Day22['wind'])

DQN_cum_offwind = sum(eval_data_DQN_2_day22['offwind'])
DDQN_cum_offwind = sum(eval_data_DDQN_day22['offwind'])
DQN_PER_cum_offwind = sum(eval_data_DQN_PER_day22['offwind'])
DQN_DuelingNet_cum_offwind = sum(eval_data_DQN_DuelingNet_day22['offwind'])
DQN_NoisyNet_cum_offwind = sum(eval_data_DQN_NoisyNet_day22['offwind'])
Categorical_DQN_cum_offwind = sum(eval_data_Categorical_DQN_day22['offwind'])
DQN_NStep_Learning_cum_offwind = sum(eval_data_DQN_NStep_Learning_day22['offwind'])
Rainbow_DQN_cum_offwind = sum(eval_data_Rainbow_DQN_day22['offwind'])
MINLP_Baseline_offwind = sum(base_result_Day22['offwind'])

DQN_RESComsumptionRate = (DQN_cum_pv + DQN_cum_onwind + DQN_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DDQN_RESComsumptionRate = (DDQN_cum_pv + DDQN_cum_onwind + DDQN_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DQN_PER_RESComsumptionRate = (DQN_PER_cum_pv + DQN_PER_cum_onwind + DQN_PER_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DQN_DuelingNet_RESComsumptionRate = (DQN_DuelingNet_cum_pv + DQN_DuelingNet_cum_onwind + DQN_DuelingNet_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DQN_NoisyNet_RESComsumptionRate = (DQN_NoisyNet_cum_pv + DQN_NoisyNet_cum_onwind + DQN_NoisyNet_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
Categorical_DQN_RESComsumptionRate = (Categorical_DQN_cum_pv + Categorical_DQN_cum_onwind + Categorical_DQN_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DQN_NStep_Learning_RESComsumptionRate = (DQN_NStep_Learning_cum_pv + DQN_NStep_Learning_cum_onwind + DQN_NStep_Learning_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
Rainbow_DQN_RESComsumptionRate = (Rainbow_DQN_cum_pv + Rainbow_DQN_cum_onwind + Rainbow_DQN_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
MINLP_Baseline_RESComsumptionRate = (MINLP_Baseline_pv + MINLP_Baseline_onwind + MINLP_Baseline_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)

RESComsumptionRate = [
    DQN_RESComsumptionRate, DQN_PER_RESComsumptionRate, DDQN_RESComsumptionRate,
    DQN_DuelingNet_RESComsumptionRate, DQN_NoisyNet_RESComsumptionRate,
    Categorical_DQN_RESComsumptionRate,
    DQN_NStep_Learning_RESComsumptionRate,
    Rainbow_DQN_RESComsumptionRate, MINLP_Baseline_RESComsumptionRate,
]

# Define agent names
agent_names = [
    "DQN", "PER-DQN", "DDQN", "Duel-DQN", "NN-DQN",
    "Cat-DQN",
    "MS-DQN",
    "Rainbow-DQN", 'MINLP-Baseline'
]

bar_width = 0.4

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (12, 8)
plt.subplots_adjust(wspace=0.5, hspace=0.5)

# Plotting

plt.subplot(1, 1, 1)
plt.cla()
plt.gca().spines[['top', 'right']].set_visible(False)
bars = plt.bar(agent_names, RESComsumptionRate, color='orange',
               width=bar_width, label='RES Comsumption Rate')
plt.xlabel('DRL Agent', size=35, fontweight='bold')
plt.ylabel('RES Comsumption Rate', size=30, fontweight='bold')
plt.xticks(rotation=45, ha='right', size=15, fontweight='bold')  # Rotate agent names for better readability
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')

plt.legend(loc="best", ncol=1, frameon=True, fontsize='18',
            fancybox=True, framealpha=1, shadow=True, borderpad=1)
ax2 = plt.gca()
for spine in ax2.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax2.xaxis.grid(False)
ax2.yaxis.grid(True)

# Draw line connecting the tops of the bars
max_values_op_costs = [bar.get_height() for bar in bars]
plt.plot(agent_names, max_values_op_costs, marker='o', color='k',
         linewidth=2.5, markersize=8)

output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Cumulative_RESComsumptionRate_All_Models_2021.png')
plt.tight_layout()
plt.show()

print(RESComsumptionRate)

"""###**Visualize the Testing Operation Cost and Grid Unbalance for All Models and The Baseline - WTPV-15%**

**Note:**

This is a Cummulative for 7 different days.

The Test is performed Using Data randomly sampled between December 22 and 31, 2021.

An Initial SOC of 0.3 and Days between 22nd - 28th December, 2021 are used for the Baseline Optmization.
"""

plt.figure(figsize=(15, 9))
plt.gca().set_facecolor("white")
plt.gca().spines[['top', 'right']].set_visible(False)

MINLP_Model_Op_Costs = pd.Series(
    MINLP_Model_Op_Costs, index=pd.date_range(
        start='2021-12-22', periods=len(
            MINLP_Model_Op_Costs), freq='D'))

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_2_Op_Cost, marker='*', linestyle='-', color='maroon',
         label='DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_Rainbow_DQN_Op_Cost, marker='*', linestyle='-',
         color='black', label='Rainbow-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_NStep_Learning_Op_Cost, marker='*', linestyle='-',
         color='purple', label='MS-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_Categorical_DQN_Op_Cost, marker='*', linestyle='-',
         color='red', label='Categorical-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_NoisyNet_Op_Cost, marker='*', linestyle='-',
         color='gold', label='NN-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_DuelingNet_Op_Cost, marker='*', linestyle='-',
         color='teal', label='Duel-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DQN_PER_Op_Cost, marker='*', linestyle='-',
         color='navy', label='PER-DQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         eval_data_DDQN_Op_Cost, marker='*', linestyle='-',
         color='olive', label='DDQN', linewidth=3.5, markersize=20)

plt.plot(MINLP_Model_Op_Costs.index,
         MINLP_Model_Op_Costs, marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=20)

plt.xlabel('Days', size=25, fontweight='bold')
plt.ylabel('Cummulative Operation Cost (£)', size=25, fontweight='bold')
plt.xticks(rotation=30, size=15, fontweight='bold')
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')
ax = plt.gca()
# Set linewidth and edge color for each spine
for spine in ax.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax.xaxis.grid(False)  # Remove x-axis grid lines
ax.yaxis.grid(True)
#plt.yscale('log')
plt.legend(loc='best', ncol=3, frameon=True, fontsize='14',
           fancybox=True, framealpha=1, shadow=True, borderpad=1)
# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_Cummulative_OperationCost_During_Testing.png')
plt.tight_layout()
plt.show()

plt.figure(figsize=(15, 9))
plt.gca().set_facecolor("white")
plt.gca().spines[['top', 'right']].set_visible(False)

plt.plot(eval_data_DQN_2_Unbalance, marker='*', linestyle='-', color='maroon',
         label='DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_Rainbow_DQN_Unbalance, marker='*', linestyle='-',
         color='black', label='Rainbow-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DQN_NStep_Learning_Unbalance, marker='*', linestyle='-',
         color='purple', label='MS-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_Categorical_DQN_Unbalance, marker='*', linestyle='-',
         color='red', label='Categorical-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DQN_NoisyNet_Unbalance, marker='*', linestyle='-',
         color='gold', label='NN-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DQN_DuelingNet_Unbalance, marker='*', linestyle='-',
         color='teal', label='Duel-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DQN_PER_Unbalance, marker='*', linestyle='-',
         color='navy', label='PER-DQN', linewidth=3.5, markersize=20)

plt.plot(eval_data_DDQN_Unbalance, marker='*', linestyle='-',
         color='olive', label='DDQN', linewidth=3.5, markersize=20)

plt.xlabel('Days', size=25, fontweight='bold')
plt.ylabel('Cummulative Grid Unbalance (MW)', size=25, fontweight='bold')
plt.xticks(rotation=30, size=15, fontweight='bold')
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')
ax = plt.gca()
# Set linewidth and edge color for each spine
for spine in ax.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax.xaxis.grid(False)  # Remove x-axis grid lines
ax.yaxis.grid(True)
#plt.yscale('log')
plt.legend(loc='best', ncol=3, frameon=True, fontsize='13',
           fancybox=True, framealpha=1, shadow=True, borderpad=1)

plt.axhline(y=0, color='k', linestyle='--', linewidth=3.5)
plt.text(3.2, 2.5, 'Excess Generation - Obtains Benefits', fontsize=25, fontweight='bold', ha='center')
plt.text(3.5, -20.5, 'Shedding Load - Obtains Penalty', fontsize=25, fontweight='bold', ha='center')

# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_Cummulative_GridUnbalance_During_Testing.png')
plt.tight_layout()
plt.show()

"""#**EXPERIMENTAL RESULT ANALYSIS - Operational Scheduling Management (Dispatch Decisions) For The Proposed Model**

**RAINBOW DQN MODEL**
"""

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (16, 12)
fig, axs = plt.subplots(2, 2)
plt.subplots_adjust(wspace=0.5, hspace=0.5)
plt.autoscale(tight=True)

T = np.array([i for i in range(24)])
# plot Netload and Price at first
axs[0, 0].cla()
axs[0, 0].set_facecolor("white")
axs[0, 0].spines[['top', 'right']].set_visible(False)
axs[0, 0].set_ylabel('Price (£/MWh)', size=20, fontweight='bold')
axs[0, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[0, 0].plot(T, eval_data_Rainbow_DQN_day22['price'], label='Price',
            color='orange', linewidth = 4.0, linestyle='solid', drawstyle = 'steps-mid')
#axs[0, 0].legend(loc='best', ncol=1, frameon=True, fontsize='12',
        #fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)
axs_netload = axs[0, 0].twinx()
axs_netload.set_facecolor("white")
axs_netload.spines[['top', 'right']].set_visible(False)
axs_netload.set_ylabel('Netload (MW)', size=20, fontweight='bold')
axs_netload.tick_params(axis='y', rotation=0, labelsize=20)
axs_netload.bar(T, eval_data_Rainbow_DQN_day22['netload'], label='Netload',
             color = 'navy', linewidth = 4.0, align = 'center', width = 0.4)

# Combine legends from both Axes
lines, labels = axs[0, 0].get_legend_handles_labels()
lines_netload, labels_netload = axs_netload.get_legend_handles_labels()
axs_netload.legend(lines + lines_netload, labels + labels_netload,
              loc='best', ncol=1, frameon=True, fontsize='14',
        fancybox=True, framealpha=1, shadow=True, borderpad=2, labelspacing=0.2)
axs[0, 0].set_title('Netload and Price', size=25, fontweight='bold')
axs[0, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[0, 0].tick_params(axis='y', rotation=0, labelsize=15)
axs[0, 0] = plt.gca()
for spine in axs[0, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 0].xaxis.grid(False)
axs[0, 0].yaxis.grid(False)

# Plot Generation and Netload in ax[2]
axs[0, 1].cla()
axs[0, 1].set_facecolor("white")
axs[0, 1].spines[['top', 'right']].set_visible(False)
axs[0, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
axs[0, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_Rainbow_DQN_day22['battery1'])
battery_negative = np.array(eval_data_Rainbow_DQN_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_Rainbow_DQN_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_Rainbow_DQN_day22['unbalance']), 0)

axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['ccgt'], label='CCGT')
axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['coal'], label='COAL',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'])
axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['biomass'], label='BIOMASS',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'])
axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['nuclear'], label='NUCLEAR',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'])
axs[0, 1].bar(T, eval_data_Rainbow_DQN_day22['hydro'], label='HYDRO',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'])

axs[0, 1].bar(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[0, 1].bar(T, -battery_negative, label = 'battery discharge', hatch='/',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'] +\
              eval_data_Rainbow_DQN_day22['hydro'])
axs[0, 1].bar(T, -imported_from_grid, label = 'imported from grid',
              bottom = eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'] +\
              eval_data_Rainbow_DQN_day22['hydro'] - battery_negative)
axs[0, 1].bar(T, -exported_2_grid, label = 'exported to grid',
              bottom = -battery_positive)

axs[0, 1].plot(T, eval_data_Rainbow_DQN_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 3.0, linestyle='solid')
axs[0, 1].legend(loc='best', ncol=2, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

axs[0, 1].set_title('Outputs of Generating Units - Rainbow DQN Model', size=20, fontweight='bold')
axs[0, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[0, 1].tick_params(axis='y', rotation=0, labelsize=20)
#axs[1] = plt.gca()
for spine in axs[0, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 1].xaxis.grid(False)
axs[0, 1].yaxis.grid(False)

# Plot Generation By Baseline Optimal Solution
axs[1, 0].cla()
axs[1, 0].set_facecolor("white")
axs[1, 0].spines[['top', 'right']].set_visible(False)
axs[1, 0].set_ylabel('Power (MW)', size=25, fontweight='bold')
axs[1, 0].set_xlabel('Time (h)', size=25, fontweight='bold')
battery_positive = np.array(base_result_Day22['battery_energy_change'])
battery_negative = np.array(base_result_Day22['battery_energy_change'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.array(base_result_Day22['grid_import'])
exported_2_grid = np.array(base_result_Day22['grid_export'])

axs[1, 0].bar(T, base_result_Day22['ccgt'], label='CCGT')
axs[1, 0].bar(T, base_result_Day22['coal'], label='COAL',
              bottom = base_result_Day22['ccgt'])
axs[1, 0].bar(T, base_result_Day22['biomass'], label='BIOMASS',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'])
axs[1, 0].bar(T, base_result_Day22['nuclear'], label='NUCLEAR',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'] +\
              base_result_Day22['biomass'])
axs[1, 0].bar(T, base_result_Day22['hydro'], label='HYDRO',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'] +\
              base_result_Day22['biomass'] + base_result_Day22['nuclear'])

axs[1, 0].bar(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[1, 0].bar(T, -battery_negative, label = 'battery discharge', hatch='/',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'] +\
              base_result_Day22['biomass'] + base_result_Day22['nuclear'] +\
              base_result_Day22['hydro'])
axs[1, 0].bar(T, -imported_from_grid, label = 'imported from grid',
              bottom = base_result_Day22['ccgt'] + base_result_Day22['coal'] +\
              base_result_Day22['biomass'] + base_result_Day22['nuclear'] +\
              base_result_Day22['hydro'] - battery_negative)
axs[1, 0].bar(T, -exported_2_grid, label = 'exported to grid',
              bottom = -battery_positive)

axs[1, 0].plot(T, base_result_Day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs[1, 0].legend(loc='best', ncol=2, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

axs[1, 0].set_title('Outputs of Generating Units - Optimal Solution Model', size=20, fontweight='bold')
axs[1, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[1, 0].tick_params(axis='y', rotation=0, labelsize=20)
#axs[1] = plt.gca()
for spine in axs[1, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 0].xaxis.grid(False)
axs[1, 0].yaxis.grid(False)

# plot energy charge/discharge with price in ax[3].
axs[1, 1].cla()
axs[1, 1].set_facecolor("white")
axs[1, 1].spines[['top', 'right']].set_visible(False)
axs[1, 1].set_ylabel('Price (£/MWh)', size=25, fontweight='bold')
axs[1, 1].set_xlabel('Time (h)', size=25, fontweight='bold')

axs[1, 1].plot(T, eval_data_Rainbow_DQN_day22['price'], drawstyle='steps-mid', label='Price',
               color = 'red', linewidth = 4.0, linestyle='solid')
axs[1, 1].legend(loc='best', ncol=1, frameon=True, fontsize='12',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)
axs_soc = axs[1, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=25, fontweight='bold')
axs_soc.plot(T, eval_data_Rainbow_DQN_day22['soc'], drawstyle='steps-mid', label='SOC',
               color = 'grey', linewidth = 4.0, linestyle='solid')
axs_soc.plot(T, base_result_Day22['soc'], drawstyle='steps-mid', label='SOC-Baseline',
               color = 'sienna', linewidth = 4.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[1, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=1, frameon=True, fontsize='14',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

axs[1, 1].set_title('Energy Charge/Discharge With Price', size=25, fontweight='bold')
axs[1, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[1, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[1, 1] = plt.gca()
for spine in axs[1, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 1].xaxis.grid(False)
axs[1, 1].yaxis.grid(False)

# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Proposed_Model_Rainbow_DQN_Performance_During_Testing.png')
plt.tight_layout()
plt.show()

"""**HOURLY OPERATION COST COMPARISON AMONG ALL MODELS**"""

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (22, 20)
fig, axs = plt.subplots(2, 1)
plt.subplots_adjust(wspace=0.6, hspace=0.4)
plt.autoscale(tight=True)

T = np.array([i for i in range(24)])
# plot Netload and Price at first
axs[0].cla()
axs[0].set_facecolor("white")
axs[0].spines[['top', 'right']].set_visible(False)
axs[0].set_ylabel('Netload (MW)', size=35, fontweight='bold')
axs[0].set_xlabel('Time (h)', size=35, fontweight='bold')
axs[0].bar(T, eval_data_DQN_2_day22['netload'], label='Netload',
            color='orange', linewidth = 2.0, align = 'center', width = 0.4)
axs_netload = axs[0].twinx()
axs_netload.set_facecolor("white")
axs_netload.spines[['top', 'right']].set_visible(False)
axs_netload.set_ylabel('Price (£/MWh)', size=35, fontweight='bold')
axs_netload.tick_params(axis='y', rotation=0, labelsize=25)
axs_netload.plot(T, eval_data_DQN_2_day22['price'], label='Price',
             color = 'navy', linewidth = 6.0, linestyle='solid', drawstyle = 'steps-mid')

# Combine legends from both Axes
lines, labels = axs[0].get_legend_handles_labels()
lines_netload, labels_netload = axs_netload.get_legend_handles_labels()
axs[0].legend(lines + lines_netload, labels + labels_netload,
              loc='best', ncol=1, frameon=True, fontsize='20',
        fancybox=True, framealpha=1, shadow=True, borderpad=2, labelspacing=0.3)
axs[0].set_title('Netload and Price', size=35, fontweight='bold')
axs[0].tick_params(axis='x', rotation=30, labelsize=25)
axs[0].tick_params(axis='y', rotation=0, labelsize=25)
axs[0] = plt.gca()
for spine in axs[0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0].xaxis.grid(False)
axs[0].yaxis.grid(True)

# plot Model's Operation Cost here
axs[1].cla()
axs[1].set_facecolor("white")
axs[1].spines[['top', 'right']].set_visible(False)
axs[1].set_ylabel('Operation Cost (£)', size=35, fontweight='bold')
axs[1].set_xlabel('Time (h)', size=35, fontweight='bold')

axs[1].plot(T, eval_data_DQN_2_day22['operation_cost'], label='DQN',
            alpha=1.0, linewidth = 5.0, color = 'gold')
axs[1].plot(T, eval_data_Rainbow_DQN_day22['operation_cost'], label='Rainbow-DQN',
            alpha=1.0, linewidth = 5.0, color = 'olive', drawstyle = 'steps-mid')
axs[1].plot(T, eval_data_DQN_NStep_Learning_day22['operation_cost'], label='MS-DQN',
            alpha=1.0, linewidth = 5.0, color = 'peachpuff')
axs[1].plot(T, eval_data_Categorical_DQN_day22['operation_cost'], label='Categorical-DQN',
            alpha=1.0, linewidth = 5.0, color = 'peru')
axs[1].plot(T, eval_data_DQN_NoisyNet_day22['operation_cost'], label='NN-DQN',
            alpha=1.0, linewidth = 5.0, color = 'darkseagreen')
axs[1].plot(T, eval_data_DQN_DuelingNet_day22['operation_cost'], label='Duel-DQN',
            alpha=1.0, linewidth = 5.0, color = 'dodgerblue')
axs[1].plot(T, eval_data_DQN_PER_day22['operation_cost'], label='PER-DQN',
            alpha=1.0, linewidth = 5.0, color = 'darkorange')
axs[1].plot(T, eval_data_DDQN_day22['operation_cost'], label='DDQN',
            alpha=1.0, linewidth = 5.0, color = 'black', linestyle='-')
axs[1].plot(T, base_result_Day22['step_cost'], label='MINLP-Baseline',
            alpha=1.0, linewidth = 5.0, color = 'navy', linestyle='--')

axs[1].set_title('Hourly Operation Cost',
                  size=35, fontweight='bold')
axs[1].tick_params(axis='x', rotation=30, labelsize=25)
axs[1].tick_params(axis='y', rotation=0, labelsize=25)
axs[1].legend(loc='best', ncol=3, frameon=True, fontsize='16',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)
for spine in axs[1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1].xaxis.grid(False)
axs[1].yaxis.grid(True)
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_OperationCost_During_Testing.png',
            format='svg', dpi=600, bbox_inches='tight')
plt.tight_layout()
plt.show()

"""**Cummulative Hourly Operation Cost for All Algorithms**"""

DQN_cum_epi_opcost = sum(eval_data_DQN_2_day22['operation_cost'])
DDQN_cum_epi_opcost = sum(eval_data_DDQN_day22['operation_cost'])
DQN_PER_cum_epi_opcost = sum(eval_data_DQN_PER_day22['operation_cost'])
DQN_DuelingNet_cum_epi_opcost = sum(eval_data_DQN_DuelingNet_day22['operation_cost'])
DQN_NoisyNet_cum_epi_opcost = sum(eval_data_DQN_NoisyNet_day22['operation_cost'])
Categorical_DQN_cum_epi_opcost = sum(eval_data_Categorical_DQN_day22['operation_cost'])
DQN_NStep_Learning_cum_epi_opcost = sum(eval_data_DQN_NStep_Learning_day22['operation_cost'])
Rainbow_DQN_cum_epi_opcost = sum(eval_data_Rainbow_DQN_day22['operation_cost'])
MINLP_Baseline = sum(base_result_Day22['step_cost'])
# Define the cumulative values

cumulative_op_costs = [
    DQN_cum_epi_opcost, DQN_PER_cum_epi_opcost, DDQN_cum_epi_opcost,
    DQN_DuelingNet_cum_epi_opcost, DQN_NoisyNet_cum_epi_opcost,
    Categorical_DQN_cum_epi_opcost,
    DQN_NStep_Learning_cum_epi_opcost,
    Rainbow_DQN_cum_epi_opcost, MINLP_Baseline,
]

# Define agent names
agent_names = [
    "DQN", "PER-DQN", "DDQN", "Duel-DQN", "NN-DQN",
    "Cat-DQN",
    "MS-DQN",
    "Rainbow-DQN", 'MINLP-Baseline'
]

bar_width = 0.4

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (20, 15)
plt.subplots_adjust(wspace=0.5, hspace=0.5)

# Plotting

plt.subplot(2, 2, 1)
plt.cla()
plt.gca().spines[['top', 'right']].set_visible(False)
bars = plt.bar(agent_names, cumulative_op_costs, color='orange',
               width=bar_width, label='Cumulative Operation Cost')
plt.xlabel('DRL Agent', size=35, fontweight='bold')
plt.ylabel('Cumulative Operation Cost (£)', size=30, fontweight='bold')
plt.xticks(rotation=45, ha='right', size=15, fontweight='bold')  # Rotate agent names for better readability
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')

plt.legend(loc="best", ncol=1, frameon=True, fontsize='18',
            fancybox=True, framealpha=1, shadow=True, borderpad=1)
ax2 = plt.gca()
for spine in ax2.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax2.xaxis.grid(False)
ax2.yaxis.grid(True)

# Draw line connecting the tops of the bars
max_values_op_costs = [bar.get_height() for bar in bars]
plt.plot(agent_names, max_values_op_costs, marker='o', color='k',
         linewidth=2.5, markersize=8)

plt.subplot(2, 2, 2)
plt.cla()
plt.gca().spines[['top', 'right']].set_visible(False)
plt.plot(agent_names, cumulative_op_costs, marker='o', color='k',
         linewidth=2.5, markersize=8, label='Cumulative Operation Cost')
plt.xlabel('DRL Agent', size=35, fontweight='bold')
plt.ylabel('Cumulative Operation Cost (£)', size=30, fontweight='bold')
plt.xticks(rotation=45, ha='right', size=15, fontweight='bold')  # Rotate agent names for better readability
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')

plt.legend(loc="best", ncol=1, frameon=True, fontsize='18',
            fancybox=True, framealpha=1, shadow=True, borderpad=1)

ax1 = plt.gca()
for spine in ax1.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax1.xaxis.grid(False)
ax1.yaxis.grid(True)

output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Cumulative_Operation_Cost_All_Models_2021.png')
plt.tight_layout()
plt.show()

print(cumulative_op_costs)

"""###**Scheduled BESS Energy Charge and Discharge Vs SOC For All Models Compared to the Baseline**"""

plt.rcParams["figure.figsize"] = (15, 15)
fig, axs = plt.subplots(4, 2)
plt.subplots_adjust(wspace=0.5, hspace=0.5)
plt.autoscale(tight=True)

T = np.array([i for i in range(24)])

# RainBow Vs Baseline
axs[0, 0].set_facecolor("white")
axs[0, 0].spines[['top', 'right']].set_visible(False)
axs[0, 0].cla()
axs[0, 0].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[0, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[0, 0].plot(T, eval_data_Rainbow_DQN_day22['battery1'], marker='*', linestyle='-',
         color='red', label='Rainbow-DQN', linewidth=3.5, markersize=8)
axs[0, 0].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[0, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_Rainbow_DQN_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[0, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[0, 0].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[0, 0].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[0, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[0, 0].tick_params(axis='y', rotation=0, labelsize=15)

axs[0, 0] = plt.gca()
for spine in axs[0, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 0].xaxis.grid(False)
axs[0, 0].yaxis.grid(False)

# DQN+NOISE Vs Baseline
axs[0, 1].set_facecolor("white")
axs[0, 1].spines[['top', 'right']].set_visible(False)
axs[0, 1].cla()
axs[0, 1].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[0, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[0, 1].plot(T, eval_data_DQN_NoisyNet_day22['battery1'], marker='*', linestyle='-',
         color='red', label='NN-DQN', linewidth=3.5, markersize=8)
axs[0, 1].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[0, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_NoisyNet_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[0, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[0, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[0, 1].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[0, 1].tick_params(axis='x', rotation=30, labelsize=15)
axs[0, 1].tick_params(axis='y', rotation=0, labelsize=15)

axs[0, 1] = plt.gca()
for spine in axs[0, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 1].xaxis.grid(False)
axs[0, 1].yaxis.grid(False)

# DQN+DUEL Vs Baseline
axs[1, 0].set_facecolor("white")
axs[1, 0].spines[['top', 'right']].set_visible(False)
axs[1, 0].cla()
axs[1, 0].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[1, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[1, 0].plot(T, eval_data_DQN_DuelingNet_day22['battery1'], marker='*', linestyle='-',
         color='red', label='Duel-DQN', linewidth=3.5, markersize=8)
axs[1, 0].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[1, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_DuelingNet_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[1, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 0].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[1, 0].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[1, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[1, 0].tick_params(axis='y', rotation=0, labelsize=15)

axs[1, 0] = plt.gca()
for spine in axs[1, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 0].xaxis.grid(False)
axs[1, 0].yaxis.grid(False)

# DDQN Vs Baseline
axs[1, 1].set_facecolor("white")
axs[1, 1].spines[['top', 'right']].set_visible(False)
axs[1, 1].cla()
axs[1, 1].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[1, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[1, 1].plot(T, eval_data_DDQN_day22['battery1'], marker='*', linestyle='-',
         color='red', label='DDQN', linewidth=3.5, markersize=8)
axs[1, 1].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[1, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DDQN_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[1, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[1, 1].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[1, 1].tick_params(axis='x', rotation=30, labelsize=15)
axs[1, 1].tick_params(axis='y', rotation=0, labelsize=15)

axs[1, 1] = plt.gca()
for spine in axs[1, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 1].xaxis.grid(False)
axs[1, 1].yaxis.grid(False)

# DQN+PER Vs Baseline
axs[2, 0].set_facecolor("white")
axs[2, 0].spines[['top', 'right']].set_visible(False)
axs[2, 0].cla()
axs[2, 0].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[2, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[2, 0].plot(T, eval_data_DQN_PER_day22['battery1'], marker='*', linestyle='-',
         color='red', label='PER-DQN', linewidth=3.5, markersize=8)
axs[2, 0].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[2, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_PER_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[2, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[2, 0].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[2, 0].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[2, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[2, 0].tick_params(axis='y', rotation=0, labelsize=15)

axs[2, 0] = plt.gca()
for spine in axs[2, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[2, 0].xaxis.grid(False)
axs[2, 0].yaxis.grid(False)

# DQN+NStep-Learning Vs Baseline
axs[2, 1].set_facecolor("white")
axs[2, 1].spines[['top', 'right']].set_visible(False)
axs[2, 1].cla()
axs[2, 1].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[2, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[2, 1].plot(T, eval_data_DQN_NStep_Learning_day22['battery1'], marker='*', linestyle='-',
         color='red', label='MS-DQN', linewidth=3.5, markersize=8)
axs[2, 1].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[2, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_NStep_Learning_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[2, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[2, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[2, 1].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[2, 1].tick_params(axis='x', rotation=30, labelsize=15)
axs[2, 1].tick_params(axis='y', rotation=0, labelsize=15)

axs[2, 1] = plt.gca()
for spine in axs[2, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[2, 1].xaxis.grid(False)
axs[2, 1].yaxis.grid(False)

# DQN Vs Baseline
axs[3, 0].set_facecolor("white")
axs[3, 0].spines[['top', 'right']].set_visible(False)
axs[3, 0].cla()
axs[3, 0].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[3, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[3, 0].plot(T, eval_data_DQN_2_day22['battery1'], marker='*', linestyle='-',
         color='red', label='DQN', linewidth=3.5, markersize=8)
axs[3, 0].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[3, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_DQN_2_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[3, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[3, 0].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[3, 0].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[3, 0].tick_params(axis='x', rotation=30, labelsize=15)
axs[3, 0].tick_params(axis='y', rotation=0, labelsize=15)

axs[3, 0] = plt.gca()
for spine in axs[3, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[3, 0].xaxis.grid(False)
axs[3, 0].yaxis.grid(False)

# CategoricalDQN Vs Baseline
axs[3, 1].set_facecolor("white")
axs[3, 1].spines[['top', 'right']].set_visible(False)
axs[3, 1].cla()
axs[3, 1].set_ylabel('Energy Change (MW)', size=20, fontweight='bold')
axs[3, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
axs[3, 1].plot(T, eval_data_Categorical_DQN_day22['battery1'], marker='*', linestyle='-',
         color='red', label='Categorical-DQN', linewidth=3.5, markersize=8)
axs[3, 1].plot(T, base_result_Day22['battery_energy_change'], marker='*', linestyle='--',
         color='green', label='Optimal Solution', linewidth=3.5, markersize=8)
axs_soc = axs[3, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('SOC', size=20, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=20)
axs_soc.plot(T, eval_data_Categorical_DQN_day22['soc'], label='SOC',
             color = 'navy', linewidth = 2.0)

# Combine legends from both Axes
lines, labels = axs[3, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[3, 1].legend(lines + lines_soc, labels + labels_soc,
              loc='best', ncol=3, frameon=True, fontsize='10',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.2)

#axs[3, 1].set_title('BESS Energy Change and SOC', size=20, fontweight='bold')
axs[3, 1].tick_params(axis='x', rotation=30, labelsize=15)
axs[3, 1].tick_params(axis='y', rotation=0, labelsize=15)

axs[3, 1] = plt.gca()
for spine in axs[3, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[3, 1].xaxis.grid(False)
axs[3, 1].yaxis.grid(False)

# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_BESS_Change_VS_SOC_During_Testing.png')
plt.tight_layout()
plt.show()

plt.rcParams["figure.figsize"] = (15, 15)
fig, axs = plt.subplots(4, 2)
plt.subplots_adjust(wspace=0.8, hspace=0.8)
plt.autoscale(tight=True)

T = np.array([i for i in range(24)])

# RainBow
axs[0, 0].set_facecolor("white")
axs[0, 0].spines[['top', 'right']].set_visible(False)
axs[0, 0].cla()
axs[0, 0].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[0, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_Rainbow_DQN_day22['battery1'])
battery_negative = np.array(eval_data_Rainbow_DQN_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_Rainbow_DQN_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_Rainbow_DQN_day22['unbalance']), 0)

axs[0, 0].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple', alpha=0.3)
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'] +\
              eval_data_Rainbow_DQN_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'] +\
              eval_data_Rainbow_DQN_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[0, 0].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'] + eval_data_Rainbow_DQN_day22['nuclear'],
                       eval_data_Rainbow_DQN_day22['hydro'], label='HYDRO', color='green')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'] +\
              eval_data_Rainbow_DQN_day22['biomass'],
                       eval_data_Rainbow_DQN_day22['nuclear'], label='NUCLEAR', color='red')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'] + eval_data_Rainbow_DQN_day22['coal'],
                       eval_data_Rainbow_DQN_day22['biomass'], label='BIOMASS', color='violet')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'], eval_data_Rainbow_DQN_day22['coal'],
                       label='COAL', color='seagreen')
axs[0, 0].fill_between(T, eval_data_Rainbow_DQN_day22['ccgt'], label='CCGT', color='gray')
axs[0, 0].plot(T, eval_data_Rainbow_DQN_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[0, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_Rainbow_DQN_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[0, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[0, 0].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[0, 0].set_xticks([])
axs[0, 0].set_title('Rainbow DQN',
                    size=20, fontweight='bold')
#axs[0, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[0, 0].tick_params(axis='y', rotation=0, labelsize=20)
axs[0, 0] = plt.gca()
for spine in axs[0, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 0].xaxis.grid(False)
axs[0, 0].yaxis.grid(False)

# DQN+NOISE
axs[0, 1].set_facecolor("white")
axs[0, 1].spines[['top', 'right']].set_visible(False)
axs[0, 1].cla()
axs[0, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[0, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_NoisyNet_day22['battery1'])
battery_negative = np.array(eval_data_DQN_NoisyNet_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_NoisyNet_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_NoisyNet_day22['unbalance']), 0)

axs[0, 1].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'] +\
              eval_data_DQN_NoisyNet_day22['biomass'] + eval_data_DQN_NoisyNet_day22['nuclear'] +\
              eval_data_DQN_NoisyNet_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'] +\
              eval_data_DQN_NoisyNet_day22['biomass'] + eval_data_DQN_NoisyNet_day22['nuclear'] +\
              eval_data_DQN_NoisyNet_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[0, 1].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'] +\
              eval_data_DQN_NoisyNet_day22['biomass'] + eval_data_DQN_NoisyNet_day22['nuclear'],
                       eval_data_DQN_NoisyNet_day22['hydro'], label='HYDRO', color='green')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'] +\
              eval_data_DQN_NoisyNet_day22['biomass'],
                       eval_data_DQN_NoisyNet_day22['nuclear'], label='NUCLEAR', color='red')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'] + eval_data_DQN_NoisyNet_day22['coal'],
                       eval_data_DQN_NoisyNet_day22['biomass'], label='BIOMASS', color='violet')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'], eval_data_DQN_NoisyNet_day22['coal'],
                       label='COAL', color='seagreen')
axs[0, 1].fill_between(T, eval_data_DQN_NoisyNet_day22['ccgt'], label='CCGT', color='gray')
axs[0, 1].plot(T, eval_data_DQN_NoisyNet_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[0, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_NoisyNet_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[0, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[0, 1].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[0, 1].set_xticks([])
axs[0, 1].set_title('NN-DQN', size=20,
                    fontweight='bold')
#axs[0, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[0, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[0, 1] = plt.gca()
for spine in axs[0, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[0, 1].xaxis.grid(False)
axs[0, 1].yaxis.grid(False)

# DQN+DUEL eval_data_DQN_DuelingNet_day22
axs[1, 0].set_facecolor("white")
axs[1, 0].spines[['top', 'right']].set_visible(False)
axs[1, 0].cla()
axs[1, 0].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[1, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_DuelingNet_day22['battery1'])
battery_negative = np.array(eval_data_DQN_DuelingNet_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_DuelingNet_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_DuelingNet_day22['unbalance']), 0)

axs[1, 0].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'] +\
              eval_data_DQN_DuelingNet_day22['biomass'] + eval_data_DQN_DuelingNet_day22['nuclear'] +\
              eval_data_DQN_DuelingNet_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'] +\
              eval_data_DQN_DuelingNet_day22['biomass'] + eval_data_DQN_DuelingNet_day22['nuclear'] +\
              eval_data_DQN_DuelingNet_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[1, 0].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'] +\
              eval_data_DQN_DuelingNet_day22['biomass'] + eval_data_DQN_DuelingNet_day22['nuclear'],
                       eval_data_DQN_DuelingNet_day22['hydro'], label='HYDRO', color='green')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'] +\
              eval_data_DQN_DuelingNet_day22['biomass'],
                       eval_data_DQN_DuelingNet_day22['nuclear'], label='NUCLEAR', color='red')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'] + eval_data_DQN_DuelingNet_day22['coal'],
                       eval_data_DQN_DuelingNet_day22['biomass'], label='BIOMASS', color='violet')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'], eval_data_DQN_DuelingNet_day22['coal'],
                       label='COAL', color='seagreen')
axs[1, 0].fill_between(T, eval_data_DQN_DuelingNet_day22['ccgt'], label='CCGT', color='gray')
axs[1, 0].plot(T, eval_data_DQN_DuelingNet_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[1, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_DuelingNet_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[1, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 0].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[1, 0].set_xticks([])
axs[1, 0].set_title('Duel-DQN', size=20,
                    fontweight='bold', y = 0.9)
#axs[1, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[1, 0].tick_params(axis='y', rotation=0, labelsize=20)
axs[1, 0] = plt.gca()
for spine in axs[1, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 0].xaxis.grid(False)
axs[1, 0].yaxis.grid(False)

# DDQN
axs[1, 1].set_facecolor("white")
axs[1, 1].spines[['top', 'right']].set_visible(False)
axs[1, 1].cla()
axs[1, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[1, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DDQN_day22['battery1'])
battery_negative = np.array(eval_data_DDQN_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DDQN_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DDQN_day22['unbalance']), 0)

axs[1, 1].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'] +\
              eval_data_DDQN_day22['biomass'] + eval_data_DDQN_day22['nuclear'] +\
              eval_data_DDQN_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'] +\
              eval_data_DDQN_day22['biomass'] + eval_data_DDQN_day22['nuclear'] +\
              eval_data_DDQN_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[1, 1].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'] +\
              eval_data_DDQN_day22['biomass'] + eval_data_DDQN_day22['nuclear'],
                       eval_data_DDQN_day22['hydro'], label='HYDRO', color='green')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'] +\
              eval_data_DDQN_day22['biomass'],
                       eval_data_DDQN_day22['nuclear'], label='NUCLEAR', color='red')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'] + eval_data_DDQN_day22['coal'],
                       eval_data_DDQN_day22['biomass'], label='BIOMASS', color='violet')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'], eval_data_DDQN_day22['coal'],
                       label='COAL', color='seagreen')
axs[1, 1].fill_between(T, eval_data_DDQN_day22['ccgt'], label='CCGT', color='gray')
axs[1, 1].plot(T, eval_data_DDQN_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[1, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DDQN_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[1, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[1, 1].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[1, 1].set_xticks([])
axs[1, 1].set_title('DDQN', size=20,
                    fontweight='bold', y = 0.9)
#axs[1, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[1, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[1, 1] = plt.gca()
for spine in axs[1, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[1, 1].xaxis.grid(False)
axs[1, 1].yaxis.grid(False)

# DQN+PER
axs[2, 0].set_facecolor("white")
axs[2, 0].spines[['top', 'right']].set_visible(False)
axs[2, 0].cla()
axs[2, 0].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[2, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_PER_day22['battery1'])
battery_negative = np.array(eval_data_DQN_PER_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_PER_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_PER_day22['unbalance']), 0)

axs[2, 0].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'] +\
              eval_data_DQN_PER_day22['biomass'] + eval_data_DQN_PER_day22['nuclear'] +\
              eval_data_DQN_PER_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'] +\
              eval_data_DQN_PER_day22['biomass'] + eval_data_DQN_PER_day22['nuclear'] +\
              eval_data_DQN_PER_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[2, 0].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'] +\
              eval_data_DQN_PER_day22['biomass'] + eval_data_DQN_PER_day22['nuclear'],
                       eval_data_DQN_PER_day22['hydro'], label='HYDRO', color='green')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'] +\
              eval_data_DQN_PER_day22['biomass'],
                       eval_data_DQN_PER_day22['nuclear'], label='NUCLEAR', color='red')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'] + eval_data_DQN_PER_day22['coal'],
                       eval_data_DQN_PER_day22['biomass'], label='BIOMASS', color='violet')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'], eval_data_DQN_PER_day22['coal'],
                       label='COAL', color='seagreen')
axs[2, 0].fill_between(T, eval_data_DQN_PER_day22['ccgt'], label='CCGT', color='gray')
axs[2, 0].plot(T, eval_data_DQN_PER_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[2, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_PER_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[2, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[2, 0].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[2, 0].set_xticks([])
axs[2, 0].set_title('PER-DQN', size=20,
                    fontweight='bold', y = 0.9)
#axs[2, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[2, 0].tick_params(axis='y', rotation=0, labelsize=20)
axs[2, 0] = plt.gca()
for spine in axs[2, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[2, 0].xaxis.grid(False)
axs[2, 0].yaxis.grid(False)

# DQN+NStep-Learning
axs[2, 1].set_facecolor("white")
axs[2, 1].spines[['top', 'right']].set_visible(False)
axs[2, 1].cla()
axs[2, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
#axs[2, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_NStep_Learning_day22['battery1'])
battery_negative = np.array(eval_data_DQN_NStep_Learning_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_NStep_Learning_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_NStep_Learning_day22['unbalance']), 0)

axs[2, 1].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'] +\
              eval_data_DQN_NStep_Learning_day22['biomass'] + eval_data_DQN_NStep_Learning_day22['nuclear'] +\
              eval_data_DQN_NStep_Learning_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'] +\
              eval_data_DQN_NStep_Learning_day22['biomass'] + eval_data_DQN_NStep_Learning_day22['nuclear'] +\
              eval_data_DQN_NStep_Learning_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[2, 1].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'] +\
              eval_data_DQN_NStep_Learning_day22['biomass'] + eval_data_DQN_NStep_Learning_day22['nuclear'],
                       eval_data_DQN_NStep_Learning_day22['hydro'], label='HYDRO', color='green')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'] +\
              eval_data_DQN_NStep_Learning_day22['biomass'],
                       eval_data_DQN_NStep_Learning_day22['nuclear'], label='NUCLEAR', color='red')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'] + eval_data_DQN_NStep_Learning_day22['coal'],
                       eval_data_DQN_NStep_Learning_day22['biomass'], label='BIOMASS', color='violet')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'], eval_data_DQN_NStep_Learning_day22['coal'],
                       label='COAL', color='seagreen')
axs[2, 1].fill_between(T, eval_data_DQN_NStep_Learning_day22['ccgt'], label='CCGT', color='gray')
axs[2, 1].plot(T, eval_data_DQN_NStep_Learning_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[2, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_NStep_Learning_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[2, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[2, 1].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.2), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)
axs[2, 1].set_xticks([])
axs[2, 1].set_title('MS-DQN', size=20,
                    fontweight='bold', y = 0.9)
#axs[2, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[2, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[2, 1] = plt.gca()
for spine in axs[2, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[2, 1].xaxis.grid(False)
axs[2, 1].yaxis.grid(False)

# DQN
axs[3, 0].set_facecolor("white")
axs[3, 0].spines[['top', 'right']].set_visible(False)
axs[3, 0].cla()
axs[3, 0].set_ylabel('Power (MW)', size=20, fontweight='bold')
axs[3, 0].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_DQN_2_day22['battery1'])
battery_negative = np.array(eval_data_DQN_2_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_DQN_2_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_DQN_2_day22['unbalance']), 0)

axs[3, 0].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'] +\
              eval_data_DQN_2_day22['biomass'] + eval_data_DQN_2_day22['nuclear'] +\
              eval_data_DQN_2_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'] +\
              eval_data_DQN_2_day22['biomass'] + eval_data_DQN_2_day22['nuclear'] +\
              eval_data_DQN_2_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[3, 0].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'] +\
              eval_data_DQN_2_day22['biomass'] + eval_data_DQN_2_day22['nuclear'],
                       eval_data_DQN_2_day22['hydro'], label='HYDRO', color='green')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'] +\
              eval_data_DQN_2_day22['biomass'],
                       eval_data_DQN_2_day22['nuclear'], label='NUCLEAR', color='red')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'] + eval_data_DQN_2_day22['coal'],
                       eval_data_DQN_2_day22['biomass'], label='BIOMASS', color='violet')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'], eval_data_DQN_2_day22['coal'],
                       label='COAL', color='seagreen')
axs[3, 0].fill_between(T, eval_data_DQN_2_day22['ccgt'], label='CCGT', color='gray')
axs[3, 0].plot(T, eval_data_DQN_2_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[3, 0].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_DQN_2_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[3, 0].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[3, 0].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.46), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)

axs[3, 0].set_title('DQN', size=20,
                    fontweight='bold', y = 0.9)
axs[3, 0].tick_params(axis='x', rotation=30, labelsize=20)
axs[3, 0].tick_params(axis='y', rotation=0, labelsize=20)
axs[3, 0] = plt.gca()
for spine in axs[3, 0].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[3, 0].xaxis.grid(False)
axs[3, 0].yaxis.grid(False)

# CategoricalDQN
axs[3, 1].set_facecolor("white")
axs[3, 1].spines[['top', 'right']].set_visible(False)
axs[3, 1].cla()
axs[3, 1].set_ylabel('Power (MW)', size=20, fontweight='bold')
axs[3, 1].set_xlabel('Time (h)', size=20, fontweight='bold')
battery_positive = np.array(eval_data_Categorical_DQN_day22['battery1'])
battery_negative = np.array(eval_data_Categorical_DQN_day22['battery1'])
battery_negative = np.minimum(battery_negative, 0)#  discharge
battery_positive = np.maximum(battery_positive, 0)# charge

# deal with power exchange within the figure
imported_from_grid = np.minimum(np.array(eval_data_Categorical_DQN_day22['unbalance']), 0)
exported_2_grid = np.maximum(np.array(eval_data_Categorical_DQN_day22['unbalance']), 0)

axs[3, 1].fill_between(T, -battery_positive, -exported_2_grid, label = 'exported to grid',
                       color='purple')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'] +\
              eval_data_Categorical_DQN_day22['biomass'] + eval_data_Categorical_DQN_day22['nuclear'] +\
              eval_data_Categorical_DQN_day22['hydro'] - battery_negative,
                       -imported_from_grid, label = 'imported from grid', color='brown')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'] +\
              eval_data_Categorical_DQN_day22['biomass'] + eval_data_Categorical_DQN_day22['nuclear'] +\
              eval_data_Categorical_DQN_day22['hydro'],
                       -battery_negative, label = 'battery discharge', hatch='/', color='pink')
axs[3, 1].fill_between(T, -battery_positive, color='blue', hatch='/',
              label = 'battery charge')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'] +\
              eval_data_Categorical_DQN_day22['biomass'] + eval_data_Categorical_DQN_day22['nuclear'],
                       eval_data_Categorical_DQN_day22['hydro'], label='HYDRO', color='green')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'] +\
              eval_data_Categorical_DQN_day22['biomass'],
                       eval_data_Categorical_DQN_day22['nuclear'], label='NUCLEAR', color='red')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'] + eval_data_Categorical_DQN_day22['coal'],
                       eval_data_Categorical_DQN_day22['biomass'], label='BIOMASS', color='violet')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'], eval_data_Categorical_DQN_day22['coal'],
                       label='COAL', color='seagreen')
axs[3, 1].fill_between(T, eval_data_Categorical_DQN_day22['ccgt'], label='CCGT', color='gray')
axs[3, 1].plot(T, eval_data_Categorical_DQN_day22['netload'], drawstyle = 'steps-mid',
               label = 'Netload', color = 'k', linewidth = 4.0, linestyle='solid')
axs_soc = axs[3, 1].twinx()
axs_soc.set_facecolor("white")
axs_soc.spines[['top', 'right']].set_visible(False)
axs_soc.set_ylabel('Price(£/MWh)', size=15, fontweight='bold')
axs_soc.tick_params(axis='y', rotation=0, labelsize=15)
axs_soc.plot(T, eval_data_Categorical_DQN_day22['price'], drawstyle = 'steps-mid',
               label = 'Price', color = 'teal', linewidth = 1.0, linestyle='solid')
# Combine legends from both Axes
lines, labels = axs[3, 1].get_legend_handles_labels()
lines_soc, labels_soc = axs_soc.get_legend_handles_labels()
axs[3, 1].legend(lines + lines_soc, labels + labels_soc,
              loc=(0.05, -0.46), ncol=4, frameon=True, fontsize='8',
        fancybox=True, framealpha=1, shadow=True, borderpad=1, labelspacing=0.1)

axs[3, 1].set_title('Categorical-DQN', size=20,
                    fontweight='bold', y = 0.9)
axs[3, 1].tick_params(axis='x', rotation=30, labelsize=20)
axs[3, 1].tick_params(axis='y', rotation=0, labelsize=20)
axs[3, 1] = plt.gca()
for spine in axs[3, 1].spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs[3, 1].xaxis.grid(False)
axs[3, 1].yaxis.grid(False)

# Save the plot to a directory in Google Drive
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Operational_Scheduling_Management_of_all_Models_During_Testing.png')
plt.tight_layout()
plt.show()

"""**Cummulative Operation Cost Savings Relative to The Baseline Network - DQN**"""

# Day 22
dqn22 = eval_data_DQN_2_day22['operation_cost']
rainbow22 = eval_data_Rainbow_DQN_day22['operation_cost']
dqn_nstep22 = eval_data_DQN_NStep_Learning_day22['operation_cost']
categorical_dqn22 = eval_data_Categorical_DQN_day22['operation_cost']
dqn_noise22 = eval_data_DQN_NoisyNet_day22['operation_cost']
dqn_duel22 = eval_data_DQN_DuelingNet_day22['operation_cost']
dqn_per22 = eval_data_DQN_PER_day22['operation_cost']
ddqn22 = eval_data_DDQN_day22['operation_cost']
minlp22 = base_result_Day22['step_cost']
# Day 23
dqn23 = eval_data_DQN_2_day23['operation_cost']
rainbow23 = eval_data_Rainbow_DQN_day23['operation_cost']
dqn_nstep23 = eval_data_DQN_NStep_Learning_day23['operation_cost']
categorical_dqn23 = eval_data_Categorical_DQN_day23['operation_cost']
dqn_noise23 = eval_data_DQN_NoisyNet_day23['operation_cost']
dqn_duel23 = eval_data_DQN_DuelingNet_day23['operation_cost']
dqn_per23 = eval_data_DQN_PER_day23['operation_cost']
ddqn23 = eval_data_DDQN_day23['operation_cost']
minlp23 = base_result_Day23['step_cost']
# Day 24
dqn24 = eval_data_DQN_2_day24['operation_cost']
rainbow24 = eval_data_Rainbow_DQN_day24['operation_cost']
dqn_nstep24 = eval_data_DQN_NStep_Learning_day24['operation_cost']
categorical_dqn24 = eval_data_Categorical_DQN_day24['operation_cost']
dqn_noise24 = eval_data_DQN_NoisyNet_day24['operation_cost']
dqn_duel24 = eval_data_DQN_DuelingNet_day24['operation_cost']
dqn_per24 = eval_data_DQN_PER_day24['operation_cost']
ddqn24 = eval_data_DDQN_day24['operation_cost']
minlp24 = base_result_Day24['step_cost']
# Day 25
dqn25 = eval_data_DQN_2_day25['operation_cost']
rainbow25 = eval_data_Rainbow_DQN_day25['operation_cost']
dqn_nstep25 = eval_data_DQN_NStep_Learning_day25['operation_cost']
categorical_dqn25 = eval_data_Categorical_DQN_day25['operation_cost']
dqn_noise25 = eval_data_DQN_NoisyNet_day25['operation_cost']
dqn_duel25 = eval_data_DQN_DuelingNet_day25['operation_cost']
dqn_per25 = eval_data_DQN_PER_day25['operation_cost']
ddqn25 = eval_data_DDQN_day25['operation_cost']
minlp25 = base_result_Day25['step_cost']
# Day 26
dqn26 = eval_data_DQN_2_day26['operation_cost']
rainbow26 = eval_data_Rainbow_DQN_day26['operation_cost']
dqn_nstep26 = eval_data_DQN_NStep_Learning_day26['operation_cost']
categorical_dqn26 = eval_data_Categorical_DQN_day26['operation_cost']
dqn_noise26 = eval_data_DQN_NoisyNet_day26['operation_cost']
dqn_duel26 = eval_data_DQN_DuelingNet_day26['operation_cost']
dqn_per26 = eval_data_DQN_PER_day26['operation_cost']
ddqn26 = eval_data_DDQN_day26['operation_cost']
minlp26 = base_result_Day26['step_cost']
# Day 27
dqn27 = eval_data_DQN_2_day27['operation_cost']
rainbow27 = eval_data_Rainbow_DQN_day27['operation_cost']
dqn_nstep27 = eval_data_DQN_NStep_Learning_day27['operation_cost']
categorical_dqn27 = eval_data_Categorical_DQN_day27['operation_cost']
dqn_noise27 = eval_data_DQN_NoisyNet_day27['operation_cost']
dqn_duel27 = eval_data_DQN_DuelingNet_day27['operation_cost']
dqn_per27 = eval_data_DQN_PER_day27['operation_cost']
ddqn27 = eval_data_DDQN_day27['operation_cost']
minlp27 = base_result_Day27['step_cost']
# Day 28
dqn28 = eval_data_DQN_2_day28['operation_cost']
rainbow28 = eval_data_Rainbow_DQN_day28['operation_cost']
dqn_nstep28 = eval_data_DQN_NStep_Learning_day28['operation_cost']
categorical_dqn28 = eval_data_Categorical_DQN_day28['operation_cost']
dqn_noise28 = eval_data_DQN_NoisyNet_day28['operation_cost']
dqn_duel28 = eval_data_DQN_DuelingNet_day28['operation_cost']
dqn_per28 = eval_data_DQN_PER_day28['operation_cost']
ddqn28 = eval_data_DDQN_day28['operation_cost']
minlp28 = base_result_Day28['step_cost']

# concatenate
dqn = pd.concat([dqn22, dqn23, dqn24, dqn25, dqn26, dqn27, dqn28], axis=0)
rainbow = pd.concat([rainbow22, rainbow23, rainbow24, rainbow25, rainbow26, rainbow27, rainbow28],
                    axis=0)
dqn_nstep = pd.concat([dqn_nstep22, dqn_nstep23, dqn_nstep24, dqn_nstep25, dqn_nstep26, dqn_nstep27, dqn_nstep28],
                      axis=0)
categorical_dqn = pd.concat([categorical_dqn22, categorical_dqn23, categorical_dqn24, categorical_dqn25,
                             categorical_dqn26, categorical_dqn27, categorical_dqn28],
                             axis=0)
dqn_noise = pd.concat([dqn_noise22, dqn_noise23, dqn_noise24, dqn_noise25, dqn_noise26,
                       dqn_noise27, dqn_noise28], axis=0)
dqn_duel = pd.concat([dqn_duel22, dqn_duel23, dqn_duel24, dqn_duel25, dqn_duel26,
                      dqn_duel27, dqn_duel28], axis=0)
dqn_per = pd.concat([dqn_per22, dqn_per23, dqn_per24, dqn_per25, dqn_per26,
                     dqn_per27, dqn_per28], axis=0)
ddqn = pd.concat([ddqn22, ddqn23, ddqn24, ddqn25, ddqn26, ddqn27, ddqn28], axis=0)
minlp = pd.concat([minlp22, minlp23, minlp24, minlp25, minlp26, minlp27,
                   minlp28], axis=0)

# Operation Cost Savings
dqn_savings = dqn - dqn
rainbow_savings = dqn - rainbow
dqn_nstep_savings = dqn - dqn_nstep
categorical_dqn_savings = dqn - categorical_dqn
dqn_noise_savings = dqn - dqn_noise
dqn_duel_savings = dqn - dqn_duel
dqn_per_savings = dqn - dqn_per
ddqn_savings = dqn - ddqn
minlp_savings = dqn - minlp

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (22, 20)
fig, axs = plt.subplots(1, 1)
plt.subplots_adjust(wspace=0.6, hspace=0.4)
plt.autoscale(tight=True)

T = np.array([i for i in range(168)])

axs.set_facecolor("white")
axs.spines[['top', 'right']].set_visible(False)
axs.cla()
axs.set_ylabel('Operation Cost Savings (£)', size=35, fontweight='bold')
axs.set_xlabel('Time (h)', size=35, fontweight='bold')

axs.plot(T, rainbow_savings, label='Rainbow-DQN',
            alpha=1.0, linewidth = 5.0, color = 'olive', drawstyle = 'steps-mid')
axs.plot(T, dqn_nstep_savings, label='MS-DQN',
            alpha=1.0, linewidth = 5.0, color = 'peachpuff', drawstyle = 'steps-mid')
axs.plot(T, categorical_dqn_savings, label='Categorical-DQN',
            alpha=1.0, linewidth = 5.0, color = 'peru', drawstyle = 'steps-mid')
axs.plot(T, dqn_noise_savings, label='NN-DQN',
            alpha=1.0, linewidth = 5.0, color = 'darkseagreen', drawstyle = 'steps-mid')
axs.plot(T, dqn_duel_savings, label='Duel-DQN',
            alpha=1.0, linewidth = 5.0, color = 'dodgerblue', drawstyle = 'steps-mid')
axs.plot(T, dqn_per_savings, label='PER-DQN',
            alpha=1.0, linewidth = 5.0, color = 'darkorange', drawstyle = 'steps-mid')
axs.plot(T, ddqn_savings, label='DDQN',
            alpha=1.0, linewidth = 5.0, color = 'navy', linestyle='-', drawstyle = 'steps-mid')
axs.plot(T, minlp_savings, label='MINLP-Baseline',
            alpha=1.0, linewidth = 5.0, color = 'gold', linestyle='-', drawstyle = 'steps-mid')
axs.plot(T, dqn_savings, label='DQN',
            alpha=1.0, linewidth = 7.0, color = 'black', linestyle='-.', drawstyle = 'steps-mid')

axs.tick_params(axis='x', rotation=30, labelsize=25)
axs.tick_params(axis='y', rotation=0, labelsize=25)
axs.legend(loc='best', ncol=3, frameon=True, fontsize='18',
        fancybox=True, framealpha=1, shadow=True, borderpad=2, labelspacing=0.3)
axs = plt.gca()
for spine in axs.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
axs.xaxis.grid(False)
axs.yaxis.grid(False)
output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Model_Performance_OperationCost_Savings_During_Testing.png',
            format='svg', dpi=600, bbox_inches='tight')
plt.tight_layout()
plt.show()

"""**Compute All Algorithm's Ability to Utilize RES - Total Consumption Rate of RES**

Larger is better!
"""

DQN_cum_pv = sum(eval_data_DQN_2_day22['pv'])
DDQN_cum_pv = sum(eval_data_DDQN_day22['pv'])
DQN_PER_cum_pv = sum(eval_data_DQN_PER_day22['pv'])
DQN_DuelingNet_cum_pv = sum(eval_data_DQN_DuelingNet_day22['pv'])
DQN_NoisyNet_cum_pv = sum(eval_data_DQN_NoisyNet_day22['pv'])
Categorical_DQN_cum_pv = sum(eval_data_Categorical_DQN_day22['pv'])
DQN_NStep_Learning_cum_pv = sum(eval_data_DQN_NStep_Learning_day22['pv'])
Rainbow_DQN_cum_pv = sum(eval_data_Rainbow_DQN_day22['pv'])
MINLP_Baseline_pv = sum(base_result_Day22['pv'])

DQN_cum_onwind = sum(eval_data_DQN_2_day22['onwind'])
DDQN_cum_onwind = sum(eval_data_DDQN_day22['onwind'])
DQN_PER_cum_onwind = sum(eval_data_DQN_PER_day22['onwind'])
DQN_DuelingNet_cum_onwind = sum(eval_data_DQN_DuelingNet_day22['onwind'])
DQN_NoisyNet_cum_onwind = sum(eval_data_DQN_NoisyNet_day22['onwind'])
Categorical_DQN_cum_onwind = sum(eval_data_Categorical_DQN_day22['onwind'])
DQN_NStep_Learning_cum_onwind = sum(eval_data_DQN_NStep_Learning_day22['onwind'])
Rainbow_DQN_cum_onwind = sum(eval_data_Rainbow_DQN_day22['onwind'])
MINLP_Baseline_onwind = sum(base_result_Day22['wind'])

DQN_cum_offwind = sum(eval_data_DQN_2_day22['offwind'])
DDQN_cum_offwind = sum(eval_data_DDQN_day22['offwind'])
DQN_PER_cum_offwind = sum(eval_data_DQN_PER_day22['offwind'])
DQN_DuelingNet_cum_offwind = sum(eval_data_DQN_DuelingNet_day22['offwind'])
DQN_NoisyNet_cum_offwind = sum(eval_data_DQN_NoisyNet_day22['offwind'])
Categorical_DQN_cum_offwind = sum(eval_data_Categorical_DQN_day22['offwind'])
DQN_NStep_Learning_cum_offwind = sum(eval_data_DQN_NStep_Learning_day22['offwind'])
Rainbow_DQN_cum_offwind = sum(eval_data_Rainbow_DQN_day22['offwind'])
MINLP_Baseline_offwind = sum(base_result_Day22['offwind'])

DQN_RESComsumptionRate = (DQN_cum_pv + DQN_cum_onwind + DQN_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DDQN_RESComsumptionRate = (DDQN_cum_pv + DDQN_cum_onwind + DDQN_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DQN_PER_RESComsumptionRate = (DQN_PER_cum_pv + DQN_PER_cum_onwind + DQN_PER_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DQN_DuelingNet_RESComsumptionRate = (DQN_DuelingNet_cum_pv + DQN_DuelingNet_cum_onwind + DQN_DuelingNet_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DQN_NoisyNet_RESComsumptionRate = (DQN_NoisyNet_cum_pv + DQN_NoisyNet_cum_onwind + DQN_NoisyNet_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
Categorical_DQN_RESComsumptionRate = (Categorical_DQN_cum_pv + Categorical_DQN_cum_onwind + Categorical_DQN_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
DQN_NStep_Learning_RESComsumptionRate = (DQN_NStep_Learning_cum_pv + DQN_NStep_Learning_cum_onwind + DQN_NStep_Learning_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
Rainbow_DQN_RESComsumptionRate = (Rainbow_DQN_cum_pv + Rainbow_DQN_cum_onwind + Rainbow_DQN_cum_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)
MINLP_Baseline_RESComsumptionRate = (MINLP_Baseline_pv + MINLP_Baseline_onwind + MINLP_Baseline_offwind) / (solar_max_cap + onwind_max_cap + offwind_max_cap)

RESComsumptionRate = [
    DQN_RESComsumptionRate, DQN_PER_RESComsumptionRate, DDQN_RESComsumptionRate,
    DQN_DuelingNet_RESComsumptionRate, DQN_NoisyNet_RESComsumptionRate,
    Categorical_DQN_RESComsumptionRate,
    DQN_NStep_Learning_RESComsumptionRate,
    Rainbow_DQN_RESComsumptionRate, MINLP_Baseline_RESComsumptionRate,
]

# Define agent names
agent_names = [
    "DQN", "PER-DQN", "DDQN", "Duel-DQN", "NN-DQN",
    "Cat-DQN",
    "MS-DQN",
    "Rainbow-DQN", 'MINLP-Baseline'
]

bar_width = 0.4

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (12, 8)
plt.subplots_adjust(wspace=0.5, hspace=0.5)

# Plotting

plt.subplot(1, 1, 1)
plt.cla()
plt.gca().spines[['top', 'right']].set_visible(False)
bars = plt.bar(agent_names, RESComsumptionRate, color='orange',
               width=bar_width, label='RES Comsumption Rate')
plt.xlabel('DRL Agent', size=35, fontweight='bold')
plt.ylabel('RES Comsumption Rate', size=30, fontweight='bold')
plt.xticks(rotation=45, ha='right', size=15, fontweight='bold')  # Rotate agent names for better readability
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')

plt.legend(loc="best", ncol=1, frameon=True, fontsize='18',
            fancybox=True, framealpha=1, shadow=True, borderpad=1)
ax2 = plt.gca()
for spine in ax2.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax2.xaxis.grid(False)
ax2.yaxis.grid(True)

# Draw line connecting the tops of the bars
max_values_op_costs = [bar.get_height() for bar in bars]
plt.plot(agent_names, max_values_op_costs, marker='o', color='k',
         linewidth=2.5, markersize=8)

output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/Cumulative_RESComsumptionRate_All_Models_2021.png')
plt.tight_layout()
plt.show()

print(RESComsumptionRate)

"""**Cummulative Daily Operational Cost and RES Consumption Rate of All Algorithms**

**WTPV-18%**
"""

cumulative_rescomrate_WTPV_18 = [5.684147734196454, 5.728153317142077, 5.702486654598422,
                                 5.644775322521957, 8.513399320679639, 5.713865273954508,
                                 5.642231513307735, 8.502076553521267, 5.058198141639795]

cumulative_operation_cost_WTPV_18 = [1269.8767563400095, 1314.7651288649863, 1322.6824930330376,
                                     1285.739357029774, 998.7267147217583, 1297.534468711171,
                                     1314.5766032622664, 876.6162862752622, 658.5461162938498]

"""**WTPV-0%**"""

cumulative_rescomrate_WTPV_0 = [0, 0, 0, 0, 0, 0, 0, 0, 0]

cumulative_operation_cost_WTPV_0 = [1495.222159944199, 1484.075674919218, 1538.767531575484,
                                    1496.4521368267413, 1219.2374418109991, 1550.0826979376277,
                                    1609.730123554514, 1227.9738066616342, 580.9776092243336]

"""**WTPV-5%**"""

cumulative_rescomrate_WTPV_5 = [2.132393660957976, 2.201602751410945, 2.1383484275596216,
                                2.181310023231942, 3.0304037458107986, 2.02365554865477,
                                2.156707654931865, 2.936518075199283, 5.058198141639795]

cumulative_operation_cost_WTPV_5 = [2077.820430280784, 2178.9213842397694, 2609.1693155189814,
                                    2570.2058793036827, 1922.6728607873858, 2323.8150613152075,
                                    2395.6750024321454, 1613.5104808435685, 580.8687839999997]

"""**WTPV-10%**"""

cumulative_rescomrate_WTPV_10 = [3.4137606081310734, 3.449702777565593, 3.3744060443448234,
                                 3.250865012106638, 5.0083141069021275, 3.4352732652903257,
                                 3.3827953411427063, 4.970498051030884, 5.058198141639795]

cumulative_operation_cost_WTPV_10 = [1528.3825858674875, 1585.4815309199062, 1593.7796699811731,
                                     1592.8472410539428, 1267.8909487691224, 1795.6027769309273,
                                     1608.4780945919551, 1185.0530810343425, 580.8687839999997]

"""**WTPV-15%**"""

cumulative_rescomrate_WTPV_15 = [4.845055642814755, 4.852556266568535, 4.858823700473259,
                                 4.9171370330328426, 7.220111912431156, 4.90435574560327,
                                 4.8324859655592665, 7.200271354954343, 5.058198141639795]

cumulative_operation_cost_WTPV_15 = [1339.193840899458, 1393.4212227444746,
                                     1408.010534965221, 1358.4073750935856,
                                     1058.9762795894808, 1336.040310733252,
                                     1445.5528679456545, 968.4864518361986,
                                     592.9555457789696]

agent_names = [
    "DQN", "PER-DQN", "DDQN", "Duel-DQN", "NN-DQN",
    "Cat-DQN",
    "MS-DQN",
    "Rainbow-DQN", 'MINLP-Baseline'
]

bar_width = 0.4

sns.set_theme(style='whitegrid')
plt.rcParams["figure.figsize"] = (20, 15)
plt.subplots_adjust(wspace=0.5, hspace=0.5)

# Plotting

plt.subplot(2, 2, 1)
plt.cla()
plt.gca().spines[['top', 'right']].set_visible(False)
plt.plot(agent_names, cumulative_rescomrate_WTPV_18, marker='o', color='k',
         linewidth=2.5, markersize=8, label='WTPV-18%')
plt.plot(agent_names, cumulative_rescomrate_WTPV_15, marker='o', color='red',
         linewidth=2.5, markersize=8, label='WTPV-15%')
plt.plot(agent_names, cumulative_rescomrate_WTPV_10, marker='o', color='blue',
         linewidth=2.5, markersize=8, label='WTPV-10%')
plt.plot(agent_names, cumulative_rescomrate_WTPV_5, marker='o', color='green',
         linewidth=2.5, markersize=8, label='WTPV-5%')
plt.plot(agent_names, cumulative_rescomrate_WTPV_0, marker='o', color='purple',
         linewidth=2.5, markersize=8, label='WTPV-0%')
plt.xlabel('DRL Agent', size=35, fontweight='bold')
plt.ylabel('RES Consumption Rate', size=30, fontweight='bold')
plt.xticks(rotation=45, ha='right', size=15, fontweight='bold')  # Rotate agent names for better readability
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')

plt.legend(loc="best", ncol=1, frameon=True, fontsize='18',
            fancybox=True, framealpha=1, shadow=True, borderpad=1)

ax1 = plt.gca()
for spine in ax1.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax1.xaxis.grid(False)
ax1.yaxis.grid(True)

plt.subplot(2, 2, 2)
plt.cla()
plt.gca().spines[['top', 'right']].set_visible(False)
plt.plot(agent_names, cumulative_operation_cost_WTPV_18, marker='o', color='k',
         linewidth=2.5, markersize=8, label='WTPV-18%')
plt.plot(agent_names, cumulative_operation_cost_WTPV_15, marker='o', color='red',
         linewidth=2.5, markersize=8, label='WTPV-15%')
plt.plot(agent_names, cumulative_operation_cost_WTPV_10, marker='o', color='blue',
         linewidth=2.5, markersize=8, label='WTPV-10%')
plt.plot(agent_names, cumulative_operation_cost_WTPV_5, marker='o', color='green',
         linewidth=2.5, markersize=8, label='WTPV-5%')
plt.plot(agent_names, cumulative_operation_cost_WTPV_0, marker='o', color='purple',
         linewidth=2.5, markersize=8, label='WTPV-0%')
plt.xlabel('DRL Agent', size=35, fontweight='bold')
plt.ylabel('Daily Operation Cost (£)', size=30, fontweight='bold')
plt.xticks(rotation=45, ha='right', size=15, fontweight='bold')  # Rotate agent names for better readability
plt.yticks(rotation=0, ha='right', size=15, fontweight='bold')

plt.legend(loc="best", ncol=1, frameon=True, fontsize='18',
            fancybox=True, framealpha=1, shadow=True, borderpad=1)

ax1 = plt.gca()
for spine in ax1.spines.values():
    spine.set_linewidth(2)
    spine.set_edgecolor('black')
ax1.xaxis.grid(False)
ax1.yaxis.grid(True)

output_dir = '/content/gdrive/MyDrive/Energy_System_RL_Modelling_Plots'
plt.savefig(f'{output_dir}/All_scenarios_Cumulative_rescomrate_Operation_Cost_2021.png')
plt.tight_layout()
plt.show()